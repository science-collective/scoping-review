"","id","submitted","updated","title","abstract","authors","affiliations","link_abstract","link_pdf","link_doi","comment","journal_ref","doi","primary_category","categories"
"1","gr-qc/0003102v1","2000-03-28 16:01:19","2000-03-28 16:01:19","A Class of Einstein-Maxwell Fields Generalizing the Equilibrium
  Solutions","  The Einstein-Maxwell fields of rotating stationary sources are represented by
the SU(2,1) spinor potential $\Psi_A$ satisfying \[ \nabla \cdot [\Theta
^{-1}(\Psi_A\nabla \Psi_B-\Psi_B\nabla \Psi_A)]=-2\Theta ^{-2}\vec{C}\cdot
(\Psi_A\nabla \Psi_B-\Psi_B\nabla \Psi_A) \] where $\Theta =\Psi ^{\dagger
}\cdot \Psi $ is the SU(2,1) norm of $\Psi $% . The Ernst potentials are
expressed in terms of the spinor potential by $% {\cal E}=\frac{\Psi_1-\Psi
_2}{\Psi_1+\Psi_2}$, $\Phi =\frac{\Psi_3}{% \Psi_1+\Psi_2}$ . The group
invariant vector $\vec{C}=-2i\func{Im}\{\Psi ^{\dagger}\cdot \nabla \Psi \}$ is
generated exclusively by the rotation of the source, hence it is appropriate to
refer to $\vec{C}$ as the {\em swirl} of the field. Static fields have no
swirl.
  The fields with no swirl are a class generalizing the equilibrium ($| e| =m$)
class of Einstein-Maxwell fields. We obtain the integrability conditions and a
highly symmetrical set of field equations for this class, as well as exact
solutions and an open research problem.
","Zoltán Perjés","","http://arxiv.org/abs/gr-qc/0003102v1","http://arxiv.org/pdf/gr-qc/0003102v1","","9 pages","","","gr-qc","gr-qc"
"2","math/0103131v1","2001-03-21 15:03:02","2001-03-21 15:03:02","Some classical multiple orthogonal polynomials","  Recently there has been a renewed interest in an extension of the notion of
orthogonal polynomials known as multiple orthogonal polynomials. This notion
comes from simultaneous rational approximation (Hermite-Pade approximation) of
a system of several functions. We describe seven families of multiple
orthogonal polynomials which have he same flavor as the very classical
orthogonal polynomials of Jacobi, Laguerre and Hermite. We also mention some
open research problems and some applications.
","Walter Van Assche|Els Coussement","","http://arxiv.org/abs/math/0103131v1","http://arxiv.org/pdf/math/0103131v1","http://dx.doi.org/10.1016/S0377-0427(00)00503-3","","J. Comput. Appl. Math. 127 (2001), 317-347","10.1016/S0377-0427(00)00503-3","math.CA","math.CA|42C05, 33C45"
"3","quant-ph/0405089v1","2004-05-16 16:51:20","2004-05-16 16:51:20","Combinatorial Approaches in Quantum Information Theory","  We investigate the exploitation of various combinatorial properties of graphs
and set systems to study several issues in quantum information theory. We
characterize the combinatorics of distributed EPR pairs for preparing
multi-partite entanglement in a real communication network. This combinatorics
helps in the study of various problems in multi-party case by just reducing to
the two-party case. Particularly, we use this combinatorics to (1) study
various possible and impossible transformations of multi-partite states under
LOCC, thus presenting an entirely new approach, not based on entropic
criterion, to study such state transformations. (2) present a protocol and
proof of its unconditional security for quantum key distribution amongst
several trusted parties. (3) propose an idea to combine the features of quantum
key distribution and quantum secret sharing. We investigate all the above
issues in great detail and finally conclude briefly with some open research
directions based on our research.
","Sudhir Kumar Singh","","http://arxiv.org/abs/quant-ph/0405089v1","http://arxiv.org/pdf/quant-ph/0405089v1","","MSc Thesis, Dept. of Mathematics, IIT Kharagpur, India; Recommended
  for the ""Best Project Award"" of the dept","","","quant-ph","quant-ph|cs.CR|math.CO"
"4","quant-ph/0506005v3","2005-06-01 03:55:29","2005-10-04 07:09:19","Common Axioms for Inferring Classical Ensemble Dynamics and Quantum
  Theory","  The same set of physically motivated axioms can be used to construct both the
classical ensemble Hamilton-Jacobi equation and Schrodingers equation. Crucial
roles are played by the assumptions of universality and simplicity (Occam's
Razor) which restrict the number and type of of arbitrary constants that appear
in the equations of motion. In this approach, non-relativistic quantum theory
is seen as the unique single parameter extension of the classical ensemble
dynamics. The method is contrasted with other related constructions in the
literature and some consequences of relaxing the axioms are also discussed: for
example, the appearance of nonlinear higher-derivative corrections possibly
related to gravity and spacetime fluctuations. Finally, some open research
problems within this approach are highlighted.
","Rajesh R. Parwani","","http://arxiv.org/abs/quant-ph/0506005v3","http://arxiv.org/pdf/quant-ph/0506005v3","http://dx.doi.org/10.1063/1.2158745","Final proceedings version. 6 pages. Presented at the 3rd QTRF
  conference at Vaxjo, Sweden, June6-11 2005","","10.1063/1.2158745","quant-ph","quant-ph|hep-th"
"5","cs/0612040v1","2006-12-07 07:56:52","2006-12-07 07:56:52","The Workshop on Internet Topology (WIT) Report","  Internet topology analysis has recently experienced a surge of interest in
computer science, physics, and the mathematical sciences. However, researchers
from these different disciplines tend to approach the same problem from
different angles. As a result, the field of Internet topology analysis and
modeling must untangle sets of inconsistent findings, conflicting claims, and
contradicting statements.
  On May 10-12, 2006, CAIDA hosted the Workshop on Internet topology (WIT). By
bringing together a group of researchers spanning the areas of computer
science, physics, and the mathematical sciences, the workshop aimed to improve
communication across these scientific disciplines, enable interdisciplinary
crossfertilization, identify commonalities in the different approaches, promote
synergy where it exists, and utilize the richness that results from exploring
similar problems from multiple perspectives.
  This report describes the findings of the workshop, outlines a set of
relevant open research problems identified by participants, and concludes with
recommendations that can benefit all scientific communities interested in
Internet topology research.
","Dmitri Krioukov|Fan Chung|kc claffy|Marina Fomenkov|Alessandro Vespignani|Walter Willinger","","http://arxiv.org/abs/cs/0612040v1","http://arxiv.org/pdf/cs/0612040v1","http://dx.doi.org/10.1145/1198255.1198267","","ACM SIGCOMM Computer Communication Review (CCR), v.37, n.1,
  p.69-73, 2007","10.1145/1198255.1198267","cs.NI","cs.NI|C.2.5; C.2.1"
"6","0704.1267v1","2007-04-10 16:26:42","2007-04-10 16:26:42","Text Line Segmentation of Historical Documents: a Survey","  There is a huge amount of historical documents in libraries and in various
National Archives that have not been exploited electronically. Although
automatic reading of complete pages remains, in most cases, a long-term
objective, tasks such as word spotting, text/image alignment, authentication
and extraction of specific fields are in use today. For all these tasks, a
major step is document segmentation into text lines. Because of the low quality
and the complexity of these documents (background noise, artifacts due to
aging, interfering lines),automatic text line segmentation remains an open
research field. The objective of this paper is to present a survey of existing
methods, developed during the last decade, and dedicated to documents of
historical interest.
","Laurence Likforman-Sulem|Abderrazak Zahour|Bruno Taconet","","http://arxiv.org/abs/0704.1267v1","http://arxiv.org/pdf/0704.1267v1","http://dx.doi.org/10.1007/s10032-006-0023-z","25 pages, submitted version, To appear in International Journal on
  Document Analysis and Recognition, On line version available at
  http://www.springerlink.com/content/k2813176280456k3/","Vol. 9, no 2-4, April 2007, pp. 123-138","10.1007/s10032-006-0023-z","cs.CV","cs.CV"
"7","0705.2136v1","2007-05-15 13:16:49","2007-05-15 13:16:49","The Variable Star One-shot Project, and its little child: Wikimbad","  The Variable Star One-shot Project (VSOP) aimed at providing to the
world-wide stellar community the necessary one-shot spectrum of unstudied
variable stars, too often classified as such by an analysis of photometric data
only. The VSOP has established an new kind of observational model, where all
steps from observations to spectral analysis, are automatized (or are underway
to be fully automatized). The project is centralized on a collaborative wiki
website. The VSOP operational model is very successful, data is continously
flowing and being analyszed, and VSOP is now a worldwide open collaboration of
people with very different and complementary skills and expertise. The idea of
a central wiki website has been extended by one of us to propose a new service
to the whole astronomical community, called Wikimbad. Wikimbad is an open wiki
website aimed at collecting, organizing and making publicly available all kind
of reduced and published astronomical data. Its strengths and a comparison with
the Virtual Observatory are discussed. See: http://vsop.sc.eso.org and
http://wikimbad.org
","C. Foellmi|T. H. Dall|J. Pritchard|G. Lo Curto|C. Allende Prieto|H. Bruntt|P. J. Amado|T. Arentoft|M. Baes|E. Depagne|M. Fernandez|V. D. Ivanov|L. Koesterke|L. Monaco|K O'Brien|L. M. Sarro|I. Saviane|J. Scharwaechter|L. Schmidtobreick|O. Schuetz|A. Seifahrt|F. Selman|M. Stefanon|M. Sterzik","","http://arxiv.org/abs/0705.2136v1","http://arxiv.org/pdf/0705.2136v1","","4 pages, 3 figures, to appear in the proceedings of the workshop help
  at ESA, in March 2007, entitled ""Astronomical Spectroscopy and Virtual
  Observatory""","","","astro-ph","astro-ph"
"8","0708.0343v1","2007-08-02 13:35:57","2007-08-02 13:35:57","Dynamic Modeling and Statistical Analysis of Event Times","  This review article provides an overview of recent work in the modeling and
analysis of recurrent events arising in engineering, reliability, public
health, biomedicine and other areas. Recurrent event modeling possesses unique
facets making it different and more difficult to handle than single event
settings. For instance, the impact of an increasing number of event occurrences
needs to be taken into account, the effects of covariates should be considered,
potential association among the interevent times within a unit cannot be
ignored, and the effects of performed interventions after each event occurrence
need to be factored in. A recent general class of models for recurrent events
which simultaneously accommodates these aspects is described. Statistical
inference methods for this class of models are presented and illustrated
through applications to real data sets. Some existing open research problems
are described.
","Edsel A. Peña","","http://arxiv.org/abs/0708.0343v1","http://arxiv.org/pdf/0708.0343v1","http://dx.doi.org/10.1214/088342306000000349","Published at http://dx.doi.org/10.1214/088342306000000349 in the
  Statistical Science (http://www.imstat.org/sts/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)","Statistical Science 2006, Vol. 21, No. 4, 487-500","10.1214/088342306000000349","stat.ME","stat.ME"
"9","0710.1559v1","2007-10-08 14:42:30","2007-10-08 14:42:30","Classical and quantum behavior of dynamical systems defined by functions
  of solvable Hamiltonians","  We discuss the classical and quantum mechanical evolution of systems
described by a Hamiltonian that is a function of a solvable one, both
classically and quantum mechanically. The case in which the solvable
Hamiltonian corresponds to the harmonic oscillator is emphasized. We show that,
in spite of the similarities at the classical level, the quantum evolution is
very different. In particular, this difference is important in constructing
coherent states, which is impossible in most cases. The class of Hamiltonians
we consider is interesting due to its pedagogical value and its applicability
to some open research problems in quantum optics and quantum gravity.
","J. Fernando Barbero G.|Iñaki Garay|Eduardo J. S. Villaseñor","","http://arxiv.org/abs/0710.1559v1","http://arxiv.org/pdf/0710.1559v1","http://dx.doi.org/10.1119/1.2805234","Accepted for publication in American Journal of Physics","Am.J.Phys. 76 (2008) 153-157","10.1119/1.2805234","quant-ph","quant-ph"
"10","0711.0685v1","2007-11-05 16:36:04","2007-11-05 16:36:04","NIBLES: an HI census of local SDSS galaxies","  NIBLES is a Key Project proposed for the 100m-class Nancay Radio Telescope
(NRT) in France. Its aim is a census of the HI gas content and dynamics of
4,000 Sloan Digital Sky Survey galaxies in the Local Volume (900<cz<12,000
km/s). The galaxies were selected based on their total stellar mass (absolute
z-band magnitude Mz), and are distributed evenly over the entire range of Mz
covered by local SDSS galaxies (-10 to -24 mag, for H0=70 km/s/Mpc). A pilot
survey is being made of over 600 galaxies. NIBLES will be complementary to the
ALFALFA and EBHIS blind HI surveys, which will detect a different ensemble of
local galaxies, and which our pilot survey results indicate will detect about
40-45% of the NIBLES sample. NIBLES is an open collaboration and anyone
interested in the science and willing to contribute to the project is welcome
to join the score of NIBLErS.
","W. van Driel|S. Schneider|M. Lehnert|the NIBLES Consortium","Paris Observatory, GEPI|UMASS|Paris Observatory, GEPI|","http://arxiv.org/abs/0711.0685v1","http://arxiv.org/pdf/0711.0685v1","http://dx.doi.org/10.1007/978-1-4020-6933-8_94","3 pages, to appear in Proceedings of ""Galaxies in the Local Volume""
  Sydney 8-13 July 2007","","10.1007/978-1-4020-6933-8_94","astro-ph","astro-ph"
"11","0803.2262v7","2008-03-15 00:02:43","2010-03-30 09:49:46","Constant-Rank Codes and Their Connection to Constant-Dimension Codes","  Constant-dimension codes have recently received attention due to their
significance to error control in noncoherent random linear network coding. What
the maximal cardinality of any constant-dimension code with finite dimension
and minimum distance is and how to construct the optimal constant-dimension
code (or codes) that achieves the maximal cardinality both remain open research
problems. In this paper, we introduce a new approach to solving these two
problems. We first establish a connection between constant-rank codes and
constant-dimension codes. Via this connection, we show that optimal
constant-dimension codes correspond to optimal constant-rank codes over
matrices with sufficiently many rows. As such, the two aforementioned problems
are equivalent to determining the maximum cardinality of constant-rank codes
and to constructing optimal constant-rank codes, respectively. To this end, we
then derive bounds on the maximum cardinality of a constant-rank code with a
given minimum rank distance, propose explicit constructions of optimal or
asymptotically optimal constant-rank codes, and establish asymptotic bounds on
the maximum rate of a constant-rank code.
","Maximilien Gadouleau|Zhiyuan Yan","","http://arxiv.org/abs/0803.2262v7","http://arxiv.org/pdf/0803.2262v7","","10 pages, 3 figures, accepted to appear in IEEE Transactions on
  Information Theory","","","cs.IT","cs.IT|math.IT"
"12","0806.0128v1","2008-06-01 07:27:05","2008-06-01 07:27:05","QoS Challenges and Opportunities in Wireless Sensor/Actuator Networks","  A wireless sensor/actuator network (WSAN) is a group of sensors and actuators
that are geographically distributed and interconnected by wireless networks.
Sensors gather information about the state of physical world. Actuators react
to this information by performing appropriate actions. WSANs thus enable cyber
systems to monitor and manipulate the behavior of the physical world. WSANs are
growing at a tremendous pace, just like the exploding evolution of Internet.
Supporting quality of service (QoS) will be of critical importance for
pervasive WSANs that serve as the network infrastructure of diverse
applications. To spark new research and development interests in this field,
this paper examines and discusses the requirements, critical challenges, and
open research issues on QoS management in WSANs. A brief overview of recent
progress is given.
","Feng Xia","","http://arxiv.org/abs/0806.0128v1","http://arxiv.org/pdf/0806.0128v1","","12 pages, 1 figure; review","Sensors 2008, 8(2), 1099-1110","","cs.NI","cs.NI|C.2.1"
"13","0806.1385v1","2008-06-09 07:48:42","2008-06-09 07:48:42","Control-Scheduling Codesign: A Perspective on Integrating Control and
  Computing","  Despite rapid evolution, embedded computing systems increasingly feature
resource constraints and workload uncertainties. To achieve much better system
performance in unpredictable environments than traditional design approaches, a
novel methodology, control-scheduling codesign, is emerging in the context of
integrating feedback control and real-time computing. The aim of this work is
to provide a better understanding of this emerging methodology and to spark new
interests and developments in both the control and computer science
communities. The state of the art of control-scheduling codesign is captured.
Relevant research efforts in the literature are discussed under two categories,
i.e., control of computing systems and codesign for control systems. Critical
open research issues on integrating control and computing are also outlined.
","Feng Xia|Youxian Sun","","http://arxiv.org/abs/0806.1385v1","http://arxiv.org/pdf/0806.1385v1","","7 pages, 2 figures; A review paper","Dynamics of Continuous, Discrete and Impulsive Systems - Series B,
  vol. 13, no. S1, pp. 1352-1358, 2006","","cs.OH","cs.OH|C.3; D.4.1"
"14","0812.0706v1","2008-12-03 12:47:08","2008-12-03 12:47:08","Which notes are Vadi-Samvadi in Raga Rageshree?","  The notes which play the most important and second most important roles in
expressing a raga are called Vadi and Samvadi swars respectively in (North)
Indian Classical music. Like Bageshree, Bhairavi, Shankara, Hamir and Kalingra,
Rageshree is another controversial raga so far as the choice of Vadi-Samvadi
selection is concerned where there are two different opinions. In the present
work, a two minute vocal recording of raga Rageshree is subjected to a careful
statistical analysis. Our analysis is broken into three phases: first half,
middle half and last half. Under a multinomial model set up holding appreciably
in the first two phases, only one opinion is found acceptable. In the last
phase the distribution seems to be quasi multinomial, characterized by an
unstable nature of relative occurrence of pitch of all the notes and although
the note whose relative occurrence of pitch suddenly shoots is the Vadi swar
selected from our analysis of the first two phases, we take it as an outlier
demanding a separate treatment like any other in statistics. Selection of
Vadi-Samvadi notes in a quasi-multinomial set up is still an open research
problem. An interesting musical cocktail is proposed, however, embedding
several ideas like melodic property of notes, note combinations and pitch
movements between notes, using some weighted combination of psychological and
statistical stability of notes along with watching carefully the sudden shoot
of one or more notes whenever there is enough evidence that multinomial model
has broken down.
","Soubhik Chakraborty|Rayalla Ranganayakulu|Shivee Chauhan|Sandeep Singh Solanki|Kartik Mahto","","http://arxiv.org/abs/0812.0706v1","http://arxiv.org/pdf/0812.0706v1","","20 pages;04 figures","","","cs.SD","cs.SD"
"15","0903.4637v1","2009-03-26 17:04:01","2009-03-26 17:04:01","Tarski's plank problem revisited","  In the 1930's, Tarski introduced his plank problem at a time when the field
Discrete Geometry was about to born. It is quite remarkable that Tarski's
question and its variants continue to generate interest in the geometric and
analytic aspects of coverings by planks in the present time as well. The paper
is a survey type with a list of open research problems.
","Karoly Bezdek","","http://arxiv.org/abs/0903.4637v1","http://arxiv.org/pdf/0903.4637v1","","","Bolyai Society Mathematical Studies 24. Berlin: Springer (2013)
  45-64","","math.MG","math.MG|52A10; 52A38; 52A40"
"16","0904.1616v1","2009-04-09 22:30:03","2009-04-09 22:30:03","Mathematical and Statistical Opportunities in Cyber Security","  The role of mathematics in a complex system such as the Internet has yet to
be deeply explored. In this paper, we summarize some of the important and
pressing problems in cyber security from the viewpoint of open science
environments. We start by posing the question ""What fundamental problems exist
within cyber security research that can be helped by advanced mathematics and
statistics?"" Our first and most important assumption is that access to
real-world data is necessary to understand large and complex systems like the
Internet. Our second assumption is that many proposed cyber security solutions
could critically damage both the openness and the productivity of scientific
research. After examining a range of cyber security problems, we come to the
conclusion that the field of cyber security poses a rich set of new and
exciting research opportunities for the mathematical and statistical sciences.
","Juan Meza|Scott Campbell|David Bailey","","http://arxiv.org/abs/0904.1616v1","http://arxiv.org/pdf/0904.1616v1","","","","","cs.CR","cs.CR"
"17","0904.3950v1","2009-04-24 22:35:02","2009-04-24 22:35:02","New Science on the Open Science Grid","  The Open Science Grid (OSG) includes work to enable new science, new
scientists, and new modalities in support of computationally based research.
There are frequently significant sociological and organizational changes
required in transformation from the existing to the new. OSG leverages its
deliverables to the large scale physics experiment member communities to
benefit new communities at all scales through activities in education,
engagement and the distributed facility. As a partner to the poster and
tutorial at SciDAC 2008, this paper gives both a brief general description and
some specific examples of new science enabled on the OSG. More information is
available at the OSG web site: (http://www.opensciencegrid.org).
","The Open Science Grid Executive Board| :|Ruth Pordes|Mine Altunay|Paul Avery|Alina Bejan|Kent Blackburn|Alan Blatecky|Rob Gardner|Bill Kramer|Miron Livny|John McGee|Maxim Potekhin|Rob Quick|Doug Olson|Alain Roy|Chander Sehgal|Torre Wenaus|Mike Wilde|Frank Wuerthwein","on behalf of the OSG Consortium|Fermi National Accelerator Laboratory|Fermi National Accelerator Laboratory|Fermi National Accelerator Laboratory|University of Florida|University of Chicago|California Institute of Technology|Renaissance Computing Institute|University of Chicago|Lawrence Berkeley National Laboratory|University of Wisconsin, Madison|Renaissance Computing Institute|Indiana University|Indiana University|Lawrence Berkeley National Laboratory|Lawrence Berkeley National Laboratory|Fermi National Accelerator Laboratory|Indiana University|University of Chicago|University of California, San Diego","http://arxiv.org/abs/0904.3950v1","http://arxiv.org/pdf/0904.3950v1","http://dx.doi.org/10.1088/1742-6596/125/1/012070","","J.Phys.Conf.Ser.125:012070,2008","10.1088/1742-6596/125/1/012070","physics.comp-ph","physics.comp-ph"
"18","0904.4868v1","2009-04-30 15:54:25","2009-04-30 15:54:25","Deconvolution of Poissonian Images Using Variable Splitting and
  Augmented Lagrangian Optimization","  Although much research has been devoted to the problem of restoring
Poissonian images, namely in the fields of medical and astronomical imaging,
applying the state of the art regularizers (such as those based on wavelets or
total variation) to this class of images is still an open research front. This
paper proposes a new image deconvolution approach for images with Poisson
statistical models, with the following building blocks: (a) a standard
regularization/MAP criterion, combining the Poisson log-likelihood with a
regularizer (log-prior) is adopted; (b) the resulting optimization problem
(which is difficult, since it involves a non-quadratic and non-separable term
plus a non-smooth term) is transformed into an equivalent constrained problem,
via a variable splitting procedure; (c) this constrained problem is addressed
using an augmented Lagrangian framework. The effectiveness of the resulting
algorithm is illustrated in comparison with current state-of-the-art methods.
","Mario A. T. Figueiredo|Jose M. Bioucas-Dias","","http://arxiv.org/abs/0904.4868v1","http://arxiv.org/pdf/0904.4868v1","","Submitted to the 2009 IEEE Workshop on Statistical Signal Processing","","","math.OC","math.OC|math.ST|stat.TH|65K10"
"19","0905.0454v1","2009-05-04 18:53:45","2009-05-04 18:53:45","Tensor Decompositions, State of the Art and Applications","  In this paper, we present a partial survey of the tools borrowed from tensor
algebra, which have been utilized recently in Statistics and Signal Processing.
It is shown why the decompositions well known in linear algebra can hardly be
extended to tensors. The concept of rank is itself difficult to define, and its
calculation raises difficulties. Numerical algorithms have nevertheless been
developed, and some are reported here, but their limitations are emphasized.
These reports hopefully open research perspectives for enterprising readers.
","Pierre Comon","","http://arxiv.org/abs/0905.0454v1","http://arxiv.org/pdf/0905.0454v1","","","Mathematics in Signal Processing V, J. G. McWhirter and I. K.
  Proudler (Ed.) (2002) 1-24","","stat.AP","stat.AP"
"20","0906.0910v1","2009-06-04 13:28:51","2009-06-04 13:28:51","On the Challenges of Collaborative Data Processing","  The last 30 years have seen the creation of a variety of electronic
collaboration tools for science and business. Some of the best-known
collaboration tools support text editing (e.g., wikis). Wikipedia's success
shows that large-scale collaboration can produce highly valuable content.
Meanwhile much structured data is being collected and made publicly available.
We have never had access to more powerful databases and statistical packages.
Is large-scale collaborative data analysis now possible? Using a quantitative
analysis of Web 2.0 data visualization sites, we find evidence that at least
moderate open collaboration occurs. We then explore some of the limiting
factors of collaboration over data.
","Sylvie Noel|Daniel Lemire","","http://arxiv.org/abs/0906.0910v1","http://arxiv.org/pdf/0906.0910v1","","to appear as a chapter in an upcoming book (Collaborative Information
  Behavior)","","","cs.DB","cs.DB|cs.HC"
"21","0910.2140v1","2009-10-12 11:58:21","2009-10-12 11:58:21","A critical look at power law modelling of the Internet","  This paper takes a critical look at the usefulness of power law models of the
Internet. The twin focuses of the paper are Internet traffic and topology
generation. The aim of the paper is twofold. Firstly it summarises the state of
the art in power law modelling particularly giving attention to existing open
research questions. Secondly it provides insight into the failings of such
models and where progress needs to be made for power law research to feed
through to actual improvements in network performance.
","Richard G. Clegg|Carla Di Cairano-Gilfedder|Shi Zhou","","http://arxiv.org/abs/0910.2140v1","http://arxiv.org/pdf/0910.2140v1","http://dx.doi.org/10.1016/j.comcom.2009.09.009","To appear Computer Communications","","10.1016/j.comcom.2009.09.009","cs.NI","cs.NI"
"22","0912.5121v2","2009-12-28 02:55:32","2010-05-06 10:40:33","Control of quantum phenomena: Past, present, and future","  Quantum control is concerned with active manipulation of physical and
chemical processes on the atomic and molecular scale. This work presents a
perspective of progress in the field of control over quantum phenomena, tracing
the evolution of theoretical concepts and experimental methods from early
developments to the most recent advances. The current experimental successes
would be impossible without the development of intense femtosecond laser
sources and pulse shapers. The two most critical theoretical insights were (1)
realizing that ultrafast atomic and molecular dynamics can be controlled via
manipulation of quantum interferences and (2) understanding that optimally
shaped ultrafast laser pulses are the most effective means for producing the
desired quantum interference patterns in the controlled system. Finally, these
theoretical and experimental advances were brought together by the crucial
concept of adaptive feedback control, which is a laboratory procedure employing
measurement-driven, closed-loop optimization to identify the best shapes of
femtosecond laser control pulses for steering quantum dynamics towards the
desired objective. Optimization in adaptive feedback control experiments is
guided by a learning algorithm, with stochastic methods proving to be
especially effective. Adaptive feedback control of quantum phenomena has found
numerous applications in many areas of the physical and chemical sciences, and
this paper reviews the extensive experiments. Other subjects discussed include
quantum optimal control theory, quantum control landscapes, the role of
theoretical control designs in experimental realizations, and real-time quantum
feedback control. The paper concludes with a prospective of open research
directions that are likely to attract significant attention in the future.
","Constantin Brif|Raj Chakrabarti|Herschel Rabitz","","http://arxiv.org/abs/0912.5121v2","http://arxiv.org/pdf/0912.5121v2","http://dx.doi.org/10.1088/1367-2630/12/7/075008","Review article, final version (significantly updated), 76 pages,
  accepted for publication in New J. Phys. (Focus issue: Quantum control)","New J. Phys. 12, 075008 (2010)","10.1088/1367-2630/12/7/075008","quant-ph","quant-ph|physics.atom-ph|physics.chem-ph"
"23","1001.3718v1","2010-01-21 04:47:58","2010-01-21 04:47:58","Severity Prediction of Drought in A Large Geographical Area Using
  Distributed Wireless Sensor Networks","  In this paper, the severity prediction of drought through the implementation
of modern sensor networks is discussed. We describe how to design a drought
prediction system using wireless sensor networks. This paper will describe a
terrestrial interconnected wireless sensor network paradigm for the prediction
of severity of drought over a vast area of 10,000 sq km. The communication
architecture for sensor network is outlined and the protocols developed for
each layer is explored. The data integration model and sensor data analysis at
the central computer is explained. The advantages and limitations are discussed
along with the use of wireless standards. They are analyzed for its relevance.
Finally a conclusion is presented along with open research issues.
","Satish. G. Dappin|M. Vaidehi|G. Nithya Nair|T. R. Gopalakrsihnan Nair","","http://arxiv.org/abs/1001.3718v1","http://arxiv.org/pdf/1001.3718v1","","7 pages, 8 figures","IEEE International Advance Computing Conference, PP 3042-3047,
  2009","","cs.DC","cs.DC"
"24","1010.2770v1","2010-10-13 20:48:30","2010-10-13 20:48:30","Online Multiple Kernel Learning for Structured Prediction","  Despite the recent progress towards efficient multiple kernel learning (MKL),
the structured output case remains an open research front. Current approaches
involve repeatedly solving a batch learning problem, which makes them
inadequate for large scale scenarios. We propose a new family of online
proximal algorithms for MKL (as well as for group-lasso and variants thereof),
which overcomes that drawback. We show regret, convergence, and generalization
bounds for the proposed method. Experiments on handwriting recognition and
dependency parsing testify for the successfulness of the approach.
","Andre F. T. Martins|Mario A. T. Figueiredo|Pedro M. Q. Aguiar|Noah A. Smith|Eric P. Xing","","http://arxiv.org/abs/1010.2770v1","http://arxiv.org/pdf/1010.2770v1","","","","","stat.ML","stat.ML"
"25","1010.2826v1","2010-10-14 05:16:24","2010-10-14 05:16:24","Tau Be or not Tau Be? - A Perspective on Service Compatibility and
  Substitutability","  One of the main open research issues in Service Oriented Computing is to
propose automated techniques to analyse service interfaces. A first problem,
called compatibility, aims at determining whether a set of services (two in
this paper) can be composed together and interact with each other as expected.
Another related problem is to check the substitutability of one service with
another. These problems are especially difficult when behavioural descriptions
(i.e., message calls and their ordering) are taken into account in service
interfaces. Interfaces should capture as faithfully as possible the service
behaviour to make their automated analysis possible while not exhibiting
implementation details. In this position paper, we choose Labelled Transition
Systems to specify the behavioural part of service interfaces. In particular,
we show that internal behaviours (tau transitions) are necessary in these
transition systems in order to detect subtle errors that may occur when
composing a set of services together. We also show that tau transitions should
be handled differently in the compatibility and substitutability problem: the
former problem requires to check if the compatibility is preserved every time a
tau transition is traversed in one interface, whereas the latter requires a
precise analysis of tau branchings in order to make the substitution preserve
the properties (e.g., a compatibility notion) which were ensured before
replacement.
","Meriem Ouederni|Gwen Salaün","University of Malaga, Spain|Grenoble INP, INRIA-Grenoble, LIG","http://arxiv.org/abs/1010.2826v1","http://arxiv.org/pdf/1010.2826v1","http://dx.doi.org/10.4204/EPTCS.37.5","In Proceedings WCSI 2010, arXiv:1010.2337","EPTCS 37, 2010, pp. 57-70","10.4204/EPTCS.37.5","cs.SE","cs.SE|cs.LO"
"26","1011.4874v3","2010-11-22 17:02:45","2011-05-13 16:24:18","Comparing, Optimising and Benchmarking Quantum Control Algorithms in a
  Unifying Programming Framework","  For paving the way to novel applications in quantum simulation, computation,
and technology, increasingly large quantum systems have to be steered with high
precision. It is a typical task amenable to numerical optimal control to turn
the time course of pulses, i.e. piecewise constant control amplitudes,
iteratively into an optimised shape. Here, we present the first comparative
study of optimal control algorithms for a wide range of finite-dimensional
applications. We focus on the most commonly used algorithms: GRAPE methods
which update all controls concurrently, and KROTOV-type methods which do so
sequentially. Guidelines for their use are given and open research questions
are pointed out. --- Moreover we introduce a novel unifying algorithmic
framework, DYNAMO (dynamic optimisation platform) designed to provide the
quantum-technology community with a convenient MATLAB-based toolset for optimal
control. In addition, it gives researchers in optimal-control techniques a
framework for benchmarking and comparing new proposed algorithms to the
state-of-the-art. It allows for a mix-and-match approach with various types of
gradients, update and step-size methods as well as subspace choices.
Open-source code including examples is made available at http://qlib.info.
","S. Machnes|U. Sander|S. J. Glaser|P. de Fouquieres|A. Gruslys|S. Schirmer|T. Schulte-Herbrueggen","","http://arxiv.org/abs/1011.4874v3","http://arxiv.org/pdf/1011.4874v3","http://dx.doi.org/10.1103/PhysRevA.84.022305","update incl. 3 new figures, comments welcome","Phys. Rev. A 84 (2011) 022305","10.1103/PhysRevA.84.022305","quant-ph","quant-ph|math.OC"
"27","1104.2265v1","2011-04-12 16:35:34","2011-04-12 16:35:34","Responsibility Modeling for the Sociotechnical Risk Analysis of
  Coalitions of Systems","  Society is challenging systems engineers by demanding ever more complex and
integrated systems. With the rise of cloud computing and systems-of-systems
(including cyber-physical systems) we are entering an era where mission
critical services and applications will be dependent upon
'coalitions-of-systems'. Coalitions-of-systems (CoS) are a class of system
similar to systems-of-systems but they differ in that they interact to further
overlapping self-interests rather than an overarching mission. Assessing the
sociotechnical risks associated with CoS is an open research question of
societal importance as existing risk analysis techniques typically focus on the
technical aspects of systems and ignore risks associated with coalition
partners reneging on responsibilities or leaving the coalition. We demonstrate
that a responsibility modeling based risk analysis approach enables the
identification of sociotechnical risks associated with CoS. The approach
identifies hazards and associated risks that may arise when relying upon a
coalition of human/organizational/technical agents to provision a service or
application. Through a case study of a proposed cloud IT infrastructure
migration we show how the technique identifies vulnerabilities that may arise
because of human, organizational or technical agents failing to discharge
responsibilities.
","David Greenwood|Ian Sommerville","","http://arxiv.org/abs/1104.2265v1","http://arxiv.org/pdf/1104.2265v1","http://dx.doi.org/10.1109/ICSMC.2011.6083832","Submitted for consideration for the IEEE SMC2011 conference","","10.1109/ICSMC.2011.6083832","cs.SE","cs.SE"
"28","1104.4690v1","2011-04-25 07:06:05","2011-04-25 07:06:05","Secured Message Transmission in Mobile AD HOC Networks through
  Identification and Removal of Byzantine Failures","  The emerging need for mobile ad hoc networks and secured data transmission
phase is of crucial importance depending upon the environments like military.
In this paper, a new way to improve the reliability of message transmission is
presented. In the open collaborative MANET environment, any node can
maliciously or selfishly disrupt and deny communication of other nodes. Dynamic
changing topology makes it hard to determine the adversary nodes that affect
the communication in MANET. An SMT protocol provides a way to secure message
transmission by dispersing the message among several paths with minimal
redundancy. The multiple routes selected are known as APS -Active Path Set.
This paper describes a technique for fault discovery process to identify
Byzantine failures which include nodes that drop, modify, or mis-route packets
in an attempt to disrupt the routing service. An adaptive probing technique
detects a malicious link through binary search and according to the nodes
behavior, these links are avoided in the active path by multiplicatively
increasing their weights. The proposed scheme provides secure communication
even with increased number of adversaries.
","V. Anitha|Dr. J. Akilandeswari","","http://arxiv.org/abs/1104.4690v1","http://arxiv.org/pdf/1104.4690v1","","5 pages, 6 figures","InterJRI Computer Science and Networking Volume 1 Issue 1, pp 14-
  18 August 2010","","cs.NI","cs.NI|cs.PF"
"29","1105.0069v2","2011-04-30 10:23:27","2012-03-30 13:24:21","Context-Oriented Programming: A Programming Paradigm for Autonomic
  Systems","  Dynamic software adaptability is one of the central features leveraged by
autonomic computing. However, developing software that changes its behavior at
run time adapting to the operational conditions is a challenging task. Several
approaches have been proposed in the literature to attack this problem at
different and complementary abstraction levels: software architecture,
middleware, and programming level. We focus on the support that ad-hoc
programming language constructs may provide to support dynamically adaptive
behaviors. We introduce context-oriented programming languages and we present a
framework that positions the supported paradigm in the MAPE-K autonomic loop.
We discuss the advantages of using context-oriented programming languages
instead of other mainstream approaches based on dynamic aspect oriented
programming languages and present a case study that shows how the proposed
programming style naturally fits dynamic adaptation requirements. Finally, we
discuss some known problems and outline a number of open research challenges.
","Guido Salvaneschi|Carlo Ghezzi|Matteo Pradella","","http://arxiv.org/abs/1105.0069v2","http://arxiv.org/pdf/1105.0069v2","","","","","cs.PL","cs.PL"
"30","1105.0141v1","2011-05-01 04:11:01","2011-05-01 04:11:01","Access Control Mechanisms for Semantic Web services-A Discussion on
  Requirements & Future Directions","  Semantic Web is an open, distributed, and dynamic environment where access to
resources cannot be controlled in a safe manner unless the access decision
takes into account during discovery of web services. Security becomes the
crucial factor for the adoption of the semantic based web services. An access
control means that the users must fulfill certain conditions in order to gain
access over web services. Access control is important in both perspectives i.e.
legal and security point of view. This paper discusses important requirements
for effective access control in semantic web services which have been extracted
from the literature surveyed. I have also discussed open research issues in
this context, focusing on access control policies and models in this paper.
","Mandeep Kaur Gondara","","http://arxiv.org/abs/1105.0141v1","http://arxiv.org/pdf/1105.0141v1","","5 Pages,1 Figure","International journal of emerging technologies and applications in
  engineering, technology and sciences (IJ-ETA-ETS)ISSN: 0974-3588 | Jan 2011
  -- June 2011 | Volume 4 : Issue 1 | Pages: 338-342","","cs.OH","cs.OH"
"31","1105.1930v1","2011-05-10 12:36:17","2011-05-10 12:36:17","Emerging multidisciplinary research across database management systems","  The database community is exploring more and more multidisciplinary avenues:
Data semantics overlaps with ontology management; reasoning tasks venture into
the domain of artificial intelligence; and data stream management and
information retrieval shake hands, e.g., when processing Web click-streams.
These new research avenues become evident, for example, in the topics that
doctoral students choose for their dissertations. This paper surveys the
emerging multidisciplinary research by doctoral students in database systems
and related areas. It is based on the PIKM 2010, which is the 3rd Ph.D.
workshop at the International Conference on Information and Knowledge
Management (CIKM). The topics addressed include ontology development, data
streams, natural language processing, medical databases, green energy, cloud
computing, and exploratory search. In addition to core ideas from the workshop,
we list some open research questions in these multidisciplinary areas.
","Anisoara Nica|Fabian Suchanek|Aparna Varde","INRIA Saclay - Ile de France|INRIA Saclay - Ile de France|","http://arxiv.org/abs/1105.1930v1","http://arxiv.org/pdf/1105.1930v1","","","SIGMOD REcords (2011)","","cs.DB","cs.DB"
"32","1105.3753v3","2011-05-18 21:42:00","2011-10-19 00:39:08","CANDELS: The Cosmic Assembly Near-infrared Deep Extragalactic Legacy
  Survey","  The Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS)
is designed to document the first third of galactic evolution, over the
approximate redshift (z) range 8--1.5. It will image >250,000 distant galaxies
using three separate cameras on the Hubble Space Telescope, from the
mid-ultraviolet to the near-infrared, and will find and measure Type Ia
supernovae at z>1.5 to test their accuracy as standardizable candles for
cosmology. Five premier multi-wavelength sky regions are selected, each with
extensive ancillary data. The use of five widely separated fields mitigates
cosmic variance and yields statistically robust and complete samples of
galaxies down to a stellar mass of 10^9 M_\odot to z \approx 2, reaching the
knee of the ultraviolet luminosity function (UVLF) of galaxies to z \approx 8.
The survey covers approximately 800 arcmin^2 and is divided into two parts. The
CANDELS/Deep survey (5\sigma\ point-source limit H=27.7 mag) covers \sim 125
arcmin^2 within GOODS-N and GOODS-S. The CANDELS/Wide survey includes GOODS and
three additional fields (EGS, COSMOS, and UDS) and covers the full area to a
5\sigma\ point-source limit of H \gtrsim 27.0 mag. Together with the Hubble
Ultra Deep Fields, the strategy creates a three-tiered ""wedding cake"" approach
that has proven efficient for extragalactic surveys. Data from the survey are
nonproprietary and are useful for a wide variety of science investigations. In
this paper, we describe the basic motivations for the survey, the CANDELS team
science goals and the resulting observational requirements, the field selection
and geometry, and the observing design. The Hubble data processing and products
are described in a companion paper.
","Norman A. Grogin|Dale D. Kocevski|S. M. Faber|Henry C. Ferguson|Anton M. Koekemoer|Adam G. Riess|Viviana Acquaviva|David M. Alexander|Omar Almaini|Matthew L. N. Ashby|Marco Barden|Eric F. Bell|Frédéric Bournaud|Thomas M. Brown|Karina I. Caputi|Stefano Casertano|Paolo Cassata|Marco Castellano|Peter Challis|Ranga-Ram Chary|Edmond Cheung|Michele Cirasuolo|Christopher J. Conselice|Asantha Roshan Cooray|Darren J. Croton|Emanuele Daddi|Tomas Dahlen|Romeel Davé|Duília F. de Mello|Avishai Dekel|Mark Dickinson|Timothy Dolch|Jennifer L. Donley|James S. Dunlop|Aaron A. Dutton|David Elbaz|Giovanni G. Fazio|Alexei V. Filippenko|Steven L. Finkelstein|Adriano Fontana|Jonathan P. Gardner|Peter M. Garnavich|Eric Gawiser|Mauro Giavalisco|Andrea Grazian|Yicheng Guo|Nimish P. Hathi|Boris Häussler|Philip F. Hopkins|Jia-Sheng Huang|Kuang-Han Huang|Saurabh W. Jha|Jeyhan S. Kartaltepe|Robert P. Kirshner|David C. Koo|Kamson Lai|Kyoung-Soo Lee|Weidong Li|Jennifer M. Lotz|Ray A. Lucas|Piero Madau|Patrick J. McCarthy|Elizabeth J. McGrath|Daniel H. McIntosh|Ross J. McLure|Bahram Mobasher|Leonidas A. Moustakas|Mark Mozena|Kirpal Nandra|Jeffrey A. Newman|Sami-Matias Niemi|Kai G. Noeske|Casey J. Papovich|Laura Pentericci|Alexandra Pope|Joel R. Primack|Abhijith Rajan|Swara Ravindranath|Naveen A. Reddy|Alvio Renzini|Hans-Walter Rix|Aday R. Robaina|Steven A. Rodney|David J. Rosario|Piero Rosati|Sara Salimbeni|Claudia Scarlata|Brian Siana|Luc Simard|Joseph Smidt|Rachel S. Somerville|Hyron Spinrad|Amber N. Straughn|Louis-Gregory Strolger|Olivia Telford|Harry I. Teplitz|Jonathan R. Trump|Arjen van der Wel|Carolin Villforth|Risa H. Wechsler|Benjamin J. Weiner|Tommy Wiklind|Vivienne Wild|Grant Wilson|Stijn Wuyts|Hao-Jing Yan|Min S. Yun","","http://arxiv.org/abs/1105.3753v3","http://arxiv.org/pdf/1105.3753v3","http://dx.doi.org/10.1088/0067-0049/197/2/35","Submitted to Astrophysical Journal Supplement Series; Revised
  version, subsequent to referee report","","10.1088/0067-0049/197/2/35","astro-ph.CO","astro-ph.CO"
"33","1107.3225v1","2011-07-16 12:47:54","2011-07-16 12:47:54","An Agent-based Strategy for Deploying Analysis Models into Specification
  and Design for Distributed APS Systems","  Despite the extensive use of the agent technology in the Supply Chain
Management field, its integration with Advanced Planning and Scheduling (APS)
tools still represents a promising field with several open research questions.
Specifically, the literature falls short in providing an integrated framework
to analyze, specify, design and implement simulation experiments covering the
whole simulation cycle. Thus, this paper proposes an agent-based strategy to
convert the 'analysis' models into 'specification' and 'design' models
combining two existing methodologies proposed in the literature. The first one
is a recent and unique approach dedicated to the 'analysis' of agent-based APS
systems. The second one is a well-established methodological framework to
'specify' and 'design' agent-based supply chain systems. The proposed
conversion strategy is original and is the first one allowing simulation
analysts to integrate the whole simulation development process in the domain of
distributed APS.
","Luis Antonio de Santa-Eulalia|Sophie D'Amours|Jean-Marc Frayret","","http://arxiv.org/abs/1107.3225v1","http://arxiv.org/pdf/1107.3225v1","","In: International Journal of Computer Science Issues, Volume 8, Issue
  3, May 2011, p.7-18, ISSN 1694-0814","","","cs.MA","cs.MA"
"34","1111.3220v1","2011-11-14 14:09:41","2011-11-14 14:09:41","Weyl geometry in late 20th century physics","  Weyl's original scale geometry of 1918 (""purely infinitesimal geometry"") was
withdrawn from physical theory in the early 1920s. It had a comeback in the
last third of the 20th century in different contexts: scalar tensor theories of
gravity, foundations of physics (gravity, quantum mechanics), elementary
particle physics, and cosmology. Here we survey the last two segments. It seems
that Weyl geometry continues to have an open research potential for the
foundations of physics after the turn of the century.
","Erhard Scholz","","http://arxiv.org/abs/1111.3220v1","http://arxiv.org/pdf/1111.3220v1","","Draft paper to appear in V. Bach, D. Rowe (eds.) Beyond Einstein.
  Proceedings Mainz Conference September 2008. Einstein Studies. Basel:
  Birkh\""auser","","","math.HO","math.HO|gr-qc|physics.hist-ph|01A60"
"35","1111.4545v1","2011-11-19 09:40:04","2011-11-19 09:40:04","Grid Security and Integration with Minimal Performance Degradation","  Computational grids are believed to be the ultimate framework to meet the
growing computational needs of the scientific community. Here, the processing
power of geographically distributed resources working under different
ownerships, having their own access policy, cost structure and the likes, is
logically coupled to make them perform as a unified resource. The continuous
increase of availability of high-bandwidth communication as well as powerful
computers built of low-cost components further enhance chances of computational
grids becoming a reality. However, the question of grid security remains one of
the important open research issues. Here, we present some novel ideas about how
to implement grid security, without appreciable performance degradation in
grids. A suitable alternative to the computationally expensive encryption is
suggested, which uses a key for message authentication. Methods of secure
transfer and exchange of the required key(s) are also discussed.
","Sugata Sanyal|Rangarajan A. Vasudevan|Ajith Abraham|Marcin Paprzycki","","http://arxiv.org/abs/1111.4545v1","http://arxiv.org/pdf/1111.4545v1","","8 Pages, 1 Figure","Journal of Digital Information Management, Vol. 2, Issue 2,
  September, 2004","","cs.CR","cs.CR"
"36","1202.1163v2","2012-02-06 15:10:34","2012-02-27 13:04:55","D-iteration method or how to improve Gauss-Seidel method","  The aim of this paper is to present the recently proposed fluid diffusion
based algorithm in the general context of the matrix inversion problem
associated to the Gauss-Seidel method. We explain the simple intuitions that
are behind this diffusion method and how it can outperform existing methods.
Then we present some theoretical problems that are associated to this
representation as open research problems. We also illustrate some connected
problems such as the graph transformation and the PageRank problem.
","Dohy Hong","","http://arxiv.org/abs/1202.1163v2","http://arxiv.org/pdf/1202.1163v2","","7 pages","","","math.NA","math.NA|cs.DM|G.1.3; G.2.2"
"37","1206.5144v1","2012-06-22 13:26:02","2012-06-22 13:26:02","Signal Processing and Optimal Resource Allocation for the Interference
  Channel","  In this article, we examine several design and complexity aspects of the
optimal physical layer resource allocation problem for a generic interference
channel (IC). The latter is a natural model for multi-user communication
networks. In particular, we characterize the computational complexity, the
convexity as well as the duality of the optimal resource allocation problem.
Moreover, we summarize various existing algorithms for resource allocation and
discuss their complexity and performance tradeoff. We also mention various open
research problems throughout the article.
","Mingyi Hong|Zhi-Quan Luo","","http://arxiv.org/abs/1206.5144v1","http://arxiv.org/pdf/1206.5144v1","","To appear in E-Reference Signal Processing, R. Chellapa and S.
  Theodoridis, Eds., Elsevier, 2013","","","cs.IT","cs.IT|math.IT"
"38","1207.1383v1","2012-07-04 16:12:21","2012-07-04 16:12:21","Bounding the Uncertainty of Graphical Games: The Complexity of Simple
  Requirements, Pareto and Strong Nash Equilibria","  We investigate the complexity of bounding the uncertainty of graphical games,
and we provide new insight into the intrinsic difficulty of computing Nash
equilibria. In particular, we show that, if one adds very simple and natural
additional requirements to a graphical game, the existence of Nash equilibria
is no longer guaranteed, and computing an equilibrium is an intractable
problem. Moreover, if stronger equilibrium conditions are required for the
game, we get hardness results for the second level of the polynomial hierarchy.
Our results offer a clear picture of the complexity of mixed Nash equilibria in
graphical games, and answer some open research questions posed by Conitzer and
Sandholm (2003).
","Gianluigi Greco|Francesco Scarcello","","http://arxiv.org/abs/1207.1383v1","http://arxiv.org/pdf/1207.1383v1","","Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)","","","cs.GT","cs.GT"
"39","1207.2037v1","2012-07-09 13:19:20","2012-07-09 13:19:20","Seamless Infrastructure independent Multi Homed NEMO Handoff Using
  Effective and Timely IEEE 802.21 MIH triggers","  Handoff performance of NEMO BS protocol with existent improvement proposals
is still not sufficient for real time and QoS-sensitive applications and
further optimizations are needed. When dealing with single homed NEMO, handoff
latency and packet loss become irreducible all optimizations included, so that
it is impossible to meet requirements of the above applications. Then, How to
combine the different Fast handoff approaches remains an open research issue
and needs more investigation. In this paper, we propose a new Infrastructure
independent handoff approach combining multihoming and intelligent
Make-Before-Break Handoff. Based on required Handoff time estimation, L2 and L3
handoffs are initiated using effective and timely MIH triggers, reducing so the
anticipation time and increasing the probability of prediction. We extend MIH
services to provide tunnel establishment and switching before link break. Thus,
the handoff is performed in background with no latency and no packet loss while
pingpong scenario is almost avoided. In addition, our proposal saves cost and
power consumption by optimizing the time of simultaneous use of multiple
interfaces. We provide also NS2 simulation experiments identifying suitable
parameter values used for estimation and validating the proposed model
","Zohra Slimane|Mohamed Feham|Abdelhafid Abdelmalek","","http://arxiv.org/abs/1207.2037v1","http://arxiv.org/pdf/1207.2037v1","http://dx.doi.org/10.5121/ijwmn.2012.4308","","International Journal of Wireless & Mobile Networks (IJWMN)Vol. 4,
  No. 3, June 2012, 119-139","10.5121/ijwmn.2012.4308","cs.NI","cs.NI"
"40","1207.3812v1","2012-07-16 20:06:52","2012-07-16 20:06:52","How to Nurture Scientific Discoveries Despite Their Unpredictable Nature","  The history of science reveals that major discoveries are not predictable.
Naively, one might conclude therefore that it is not possible to artificially
cultivate an environment that promotes discoveries. I suggest instead that open
research without a programmatic agenda establishes a fertile ground for
unexpected breakthroughs. Contrary to current practice, funding agencies should
allocate a small fraction of their funds to support research in centers of
excellence without programmatic reins tied to specific goals.
","Abraham Loeb","Harvard","http://arxiv.org/abs/1207.3812v1","http://arxiv.org/pdf/1207.3812v1","","4 pages, submitted for publication","","","astro-ph.IM","astro-ph.IM|physics.hist-ph"
"41","1208.2080v1","2012-08-10 02:43:53","2012-08-10 02:43:53","Multi-GPU-based Swendsen-Wang multi-cluster algorithm for the simulation
  of two-dimensional q-state Potts model","  We present the multiple GPU computing with the common unified device
architecture (CUDA) for the Swendsen-Wang multi-cluster algorithm of
two-dimensional (2D) q-state Potts model. Extending our algorithm for single
GPU computing [Comp. Phys. Comm. 183 (2012) 1155], we realize the GPU
computation of the Swendsen-Wang multi-cluster algorithm for multiple GPUs. We
implement our code on the large-scale open science supercomputer TSUBAME 2.0,
and test the performance and the scalability of the simulation of the 2D Potts
model. The performance on Tesla M2050 using 256 GPUs is obtained as 37.3 spin
flips per a nano second for the q=2 Potts model (Ising model) at the critical
temperature with the linear system size L=65536.
","Yukihiro Komura|Yutaka Okabe","","http://arxiv.org/abs/1208.2080v1","http://arxiv.org/pdf/1208.2080v1","http://dx.doi.org/10.1016/j.cpc.2012.08.006","accepted for publication in Comp. Phys. Commun. arXiv admin note:
  substantial text overlap with arXiv:1202.0635","Computer Physics Communications 184 (2013) 40","10.1016/j.cpc.2012.08.006","physics.comp-ph","physics.comp-ph|cond-mat.stat-mech"
"42","1208.2351v1","2012-08-11 14:42:48","2012-08-11 14:42:48","A Comprehensive Survey of MAC Protocols for Wireless Body Area Networks","  In this paper, we present a comprehensive study of Medium Access Control
(MAC) protocols developed for Wireless Body Area Networks (WBANs). In WBANs,
small batteryoperated on-body or implanted biomedical sensor nodes are used to
monitor physiological signs such as temperature, blood pressure,
ElectroCardioGram (ECG), ElectroEncephaloGraphy (EEG) etc. We discuss design
requirements for WBANs with major sources of energy dissipation. Then, we
further investigate the existing designed protocols for WBANs with focus on
their strengths and weaknesses. Paper ends up with concluding remarks and open
research issues for future work.
","A. Rahim|N. Javaid|M. Aslam|Z. Rahman|U. Qasim|Z. A. Khan","","http://arxiv.org/abs/1208.2351v1","http://arxiv.org/pdf/1208.2351v1","http://dx.doi.org/10.1109/BWCCA.2012.77","BioSPAN-2012 with 7th IEEE International Conference on Broadband and
  Wireless Computing, Communication and Applications (BWCCA 2012), Victoria,
  Canada, 2012","","10.1109/BWCCA.2012.77","cs.NI","cs.NI"
"43","1208.4439v2","2012-08-22 07:53:28","2012-09-04 07:00:53","Radio Frequency Energy Harvesting and Management for Wireless Sensor
  Networks","  Radio Frequency (RF) Energy Harvesting holds a promising future for
generating a small amount of electrical power to drive partial circuits in
wirelessly communicating electronics devices. Reducing power consumption has
become a major challenge in wireless sensor networks. As a vital factor
affecting system cost and lifetime, energy consumption in wireless sensor
networks is an emerging and active research area. This chapter presents a
practical approach for RF Energy harvesting and management of the harvested and
available energy for wireless sensor networks using the Improved Energy
Efficient Ant Based Routing Algorithm (IEEABR) as our proposed algorithm. The
chapter looks at measurement of the RF power density, calculation of the
received power, storage of the harvested power, and management of the power in
wireless sensor networks. The routing uses IEEABR technique for energy
management. Practical and real-time implementations of the RF Energy using
Powercast harvesters and simulations using the energy model of our Libelium
Waspmote to verify the approach were performed. The chapter concludes with
performance analysis of the harvested energy, comparison of IEEABR and other
traditional energy management techniques, while also looking at open research
areas of energy harvesting and management for wireless sensor networks.
","A. M. Zungeru|Li-Minn Ang|S. R. S. Prabaharan|Kah Phooi Seng","","http://arxiv.org/abs/1208.4439v2","http://arxiv.org/pdf/1208.4439v2","http://dx.doi.org/10.1201/b10081-16","40 pages, 9 figures, 5 tables, Book chapter","Green Mobile Devices and Networks: Energy Optimization and
  Scavenging Techniques (CRC Press, Taylor and Francis Group, 2011) pp. 341-368","10.1201/b10081-16","cs.NI","cs.NI"
"44","1209.5654v2","2012-09-25 15:57:04","2016-09-30 09:59:59","Nonasymptotic analysis of adaptive and annealed Feynman-Kac particle
  models","  Sequential and quantum Monte Carlo methods, as well as genetic type search
algorithms can be interpreted as a mean field and interacting particle
approximations of Feynman-Kac models in distribution spaces. The performance of
these population Monte Carlo algorithms is strongly related to the stability
properties of nonlinear Feynman-Kac semigroups. In this paper, we analyze these
models in terms of Dobrushin ergodic coefficients of the reference Markov
transitions and the oscillations of the potential functions. Sufficient
conditions for uniform concentration inequalities w.r.t. time are expressed
explicitly in terms of these two quantities. We provide an original
perturbation analysis that applies to annealed and adaptive Feynman-Kac models,
yielding what seems to be the first results of this kind for these types of
models. Special attention is devoted to the particular case of Boltzmann-Gibbs
measures' sampling. In this context, we design an explicit way of tuning the
number of Markov chain Monte Carlo iterations with temperature schedule. We
also design an alternative interacting particle method based on an adaptive
strategy to define the temperature increments. The theoretical analysis of the
performance of this adaptive model is much more involved as both the potential
functions and the reference Markov transitions now depend on the random
evolution on the particle model. The nonasymptotic analysis of these complex
adaptive models is an open research problem. We initiate this study with the
concentration analysis of a simplified adaptive models based on reference
Markov transitions that coincide with the limiting quantities, as the number of
particles tends to infinity.
","François Giraud|Pierre Del Moral","","http://arxiv.org/abs/1209.5654v2","http://arxiv.org/pdf/1209.5654v2","http://dx.doi.org/10.3150/14-BEJ680","Published at http://dx.doi.org/10.3150/14-BEJ680 in the Bernoulli
  (http://isi.cbs.nl/bernoulli/) by the International Statistical
  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)","Bernoulli 2017, Vol. 23, No. 1, 670-709","10.3150/14-BEJ680","math.PR","math.PR|math.ST|stat.TH"
"45","1210.0713v1","2012-10-02 09:32:54","2012-10-02 09:32:54","Open Science Project in White Dwarf Research","  I will propose a new way of advancing white dwarf research. Open science is a
method of doing research that lets everyone who has something to say about the
subject take part in the problem solving process.
  Already now, the amount of information we gather from observations, theory
and modelling is too vast for any one individual to comprehend and turn into
knowledge. And the amount of information just keeps growing in the future. A
platform that promotes sharing of thoughts and ideas allows us to pool our
collective knowledge of white dwarfs and get a clear picture of our research
field. It will also make it possible for researchers in fields closely related
to ours (AGB stars, planetary nebulae etc.) to join the scientific discourse.
  In the first stage this project would allow us to summarize what we know and
what we don't, and what we should search for next. Later, it could grow into a
large collaboration that would have the impact to, for example, suggest
instrument requirements for future telescopes to satisfy the needs of the white
dwarf community, or propose large surveys.
  A simple implementation would be a wiki page for collecting knowledge
combined with a forum for more extensive discussions. These would be simple and
cheap to maintain. A large community effort on the whole would be needed for
the project to succeed, but individual workload should stay at a low level.
","Tommi Vornanen","","http://arxiv.org/abs/1210.0713v1","http://arxiv.org/pdf/1210.0713v1","","To be published in the proceedings of the 18th European White Dwarf
  Workshop. 4 pages","","","astro-ph.IM","astro-ph.IM|astro-ph.SR|cs.DL"
"46","1210.4820v6","2012-10-17 18:56:28","2015-02-16 17:21:48","Whole Genome Sequencing: Innovation Dream or Privacy Nightmare?","  Over the past several years, DNA sequencing has emerged as one of the driving
forces in life-sciences, paving the way for affordable and accurate whole
genome sequencing. As genomes represent the entirety of an organism's
hereditary information, the availability of complete human genomes prompts a
wide range of revolutionary applications. The hope for improving modern
healthcare and better understanding the human genome propels many interesting
and challenging research frontiers. Unfortunately, however, the proliferation
of human genomes amplifies worrisome privacy concerns, since a genome
represents a treasure trove of highly personal and sensitive information. In
this article, we provide an overview of positive results and biomedical
advances in the field, and discuss privacy issues associated with human genomic
information. Finally, we survey available privacy-enhancing technologies and
list a number of open research challenges.
","Emiliano De Cristofaro","","http://arxiv.org/abs/1210.4820v6","http://arxiv.org/pdf/1210.4820v6","","This version is superseded by arXiv:1306.1264","","","cs.CR","cs.CR|cs.ET|q-bio.GN"
"47","1210.4981v1","2012-10-17 22:44:07","2012-10-17 22:44:07","Foundations and Tools for End-User Architecting","  Within an increasing number of domains an important emerging need is the
ability for technically naive users to compose computational elements into
novel configurations. Examples include astronomers who create new analysis
pipelines to process telescopic data, intelligence analysts who must process
diverse sources of unstructured text to discover socio-technical trends, and
medical researchers who have to process brain image data in new ways to
understand disease pathways. Creating such compositions today typically
requires low-level technical expertise, limiting the use of computational
methods and increasing the cost of using them. In this paper we describe an
approach - which we term end-user architecting - that exploits the similarity
between such compositional activities and those of software architects. Drawing
on the rich heritage of software architecture languages, methods, and tools, we
show how those techniques can be adapted to support end users in composing rich
computational systems through domain-specific compositional paradigms and
component repositories, without requiring that they have knowledge of the
low-level implementation details of the components or the compositional
infrastructure. Further, we outline a set of open research challenges that the
area of end-user architecting raises.
","David Garlan|Vishal Dwivedi|Ivan Ruchkin|Bradley Schmerl","","http://arxiv.org/abs/1210.4981v1","http://arxiv.org/pdf/1210.4981v1","http://dx.doi.org/10.1007/978-3-642-34059-8_9","","Large-Scale Complex IT Systems. Development, Operation and
  Management. Lecture Notes in Computer Science, 2012, Volume 7539/2012,
  157-182","10.1007/978-3-642-34059-8_9","cs.SE","cs.SE|cs.HC|cs.SI|D.2.11; H.5.2"
"48","1210.6116v1","2012-10-23 03:24:48","2012-10-23 03:24:48","Large-scale Monte Carlo simulation of two-dimensional classical XY model
  using multiple GPUs","  We study the two-dimensional classical XY model by the large-scale Monte
Carlo simulation of the Swendsen-Wang multi-cluster algorithm using multiple
GPUs on the open science supercomputer TSUBAME 2.0. Simulating systems up to
the linear system size L=65536, we investigate the Kosterlitz-Thouless (KT)
transition. Using the generalized version of the probability-changing cluster
algorithm based on the helicity modulus, we locate the KT transition
temperature in a self-adapted way. The obtained inverse KT temperature
\beta_{KT} is 1.11996(6). We estimate the exponent to specify the
multiplicative logarithmic correction, -2r, and precisely reproduce the
theoretical prediction -2r=1/8.
","Yukihiro Komura|Yutaka Okabe","","http://arxiv.org/abs/1210.6116v1","http://arxiv.org/pdf/1210.6116v1","http://dx.doi.org/10.1143/JPSJ.81.113001","","J. Phys. Soc. Jpn. 81 (2012) 113001","10.1143/JPSJ.81.113001","cond-mat.stat-mech","cond-mat.stat-mech"
"49","1211.6675v1","2012-11-28 17:39:16","2012-11-28 17:39:16","Nonlinear Dynamic Field Embedding: On Hyperspectral Scene Visualization","  Graph embedding techniques are useful to characterize spectral signature
relations for hyperspectral images. However, such images consists of disjoint
classes due to spatial details that are often ignored by existing graph
computing tools. Robust parameter estimation is a challenge for kernel
functions that compute such graphs. Finding a corresponding high quality
coordinate system to map signature relations remains an open research question.
We answer positively on these challenges by first proposing a kernel function
of spatial and spectral information in computing neighborhood graphs. Secondly,
the study exploits the force field interpretation from mechanics and devise a
unifying nonlinear graph embedding framework. The generalized framework leads
to novel unsupervised multidimensional artificial field embedding techniques
that rely on the simple additive assumption of pair-dependent attraction and
repulsion functions. The formulations capture long range and short range
distance related effects often associated with living organisms and help to
establish algorithmic properties that mimic mutual behavior for the purpose of
dimensionality reduction. The main benefits from the proposed models includes
the ability to preserve the local topology of data and produce quality
visualizations i.e. maintaining disjoint meaningful neighborhoods. As part of
evaluation, visualization, gradient field trajectories, and semisupervised
classification experiments are conducted for image scenes acquired by multiple
sensors at various spatial resolutions over different types of objects. The
results demonstrate the superiority of the proposed embedding framework over
various widely used methods.
","Dalton Lunga 'and' Okan Ersoy","","http://arxiv.org/abs/1211.6675v1","http://arxiv.org/pdf/1211.6675v1","","49 pages, 18 figures","","","cs.CV","cs.CV|cs.CE|stat.ML"
"50","1211.7102v1","2012-11-29 21:52:00","2012-11-29 21:52:00","SVD Based Image Processing Applications: State of The Art, Contributions
  and Research Challenges","  Singular Value Decomposition (SVD) has recently emerged as a new paradigm for
processing different types of images. SVD is an attractive algebraic transform
for image processing applications. The paper proposes an experimental survey
for the SVD as an efficient transform in image processing applications. Despite
the well-known fact that SVD offers attractive properties in imaging, the
exploring of using its properties in various image applications is currently at
its infancy. Since the SVD has many attractive properties have not been
utilized, this paper contributes in using these generous properties in newly
image applications and gives a highly recommendation for more research
challenges. In this paper, the SVD properties for images are experimentally
presented to be utilized in developing new SVD-based image processing
applications. The paper offers survey on the developed SVD based image
applications. The paper also proposes some new contributions that were
originated from SVD properties analysis in different image processing. The aim
of this paper is to provide a better understanding of the SVD in image
processing and identify important various applications and open research
directions in this increasingly important area; SVD based image processing in
the future research.
","Rowayda A. Sadek","","http://arxiv.org/abs/1211.7102v1","http://arxiv.org/pdf/1211.7102v1","","","(IJACSA) International Journal of Advanced Computer Science and
  Applications, Vol. 3, No. 7, 2012 26-34","","cs.CV","cs.CV|cs.MM"
"51","1301.7190v1","2013-01-30 10:40:21","2013-01-30 10:40:21","A Domain Specific Language for kinematic models and fast implementations
  of robot dynamics algorithms","  Rigid body dynamics algorithms play a crucial role in several components of a
robot controller and simulations. Real time constraints in high frequency
control loops and time requirements of specific applications demand these
functions to be very efficient. Despite the availability of established
algorithms, their efficient implementation for a specific robot still is a
tedious and error-prone task. However, these components are simply necessary to
get high performance controllers.
  To achieve efficient yet well maintainable implementations of dynamics
algorithms we propose to use a domain specific language to describe the
kinematics/dynamics model of a robot. Since the algorithms are parameterized on
this model, executable code tailored for a specific robot can be generated,
thanks to the facilities available for \dsls. This approach allows the users to
deal only with the high level description of their robot and relieves them from
problematic hand-crafted development; resources and efforts can then be focused
on open research questions.
  Preliminary results about the generation of efficient code for inverse
dynamics will be presented as a proof of concept of this approach.
","Marco Frigerio|Jonas Buchli|Darwin G. Caldwell","","http://arxiv.org/abs/1301.7190v1","http://arxiv.org/pdf/1301.7190v1","","Presented at DSLRob 2011 (arXiv:1212.3308)","","","cs.RO","cs.RO|cs.PL"
"52","1302.0446v1","2013-02-03 02:40:29","2013-02-03 02:40:29","Sparse Camera Network for Visual Surveillance -- A Comprehensive Survey","  Technological advances in sensor manufacture, communication, and computing
are stimulating the development of new applications that are transforming
traditional vision systems into pervasive intelligent camera networks. The
analysis of visual cues in multi-camera networks enables a wide range of
applications, from smart home and office automation to large area surveillance
and traffic surveillance. While dense camera networks - in which most cameras
have large overlapping fields of view - are well studied, we are mainly
concerned with sparse camera networks. A sparse camera network undertakes large
area surveillance using as few cameras as possible, and most cameras have
non-overlapping fields of view with one another. The task is challenging due to
the lack of knowledge about the topological structure of the network,
variations in the appearance and motion of specific tracking targets in
different views, and the difficulties of understanding composite events in the
network. In this review paper, we present a comprehensive survey of recent
research results to address the problems of intra-camera tracking, topological
structure learning, target appearance modeling, and global activity
understanding in sparse camera networks. A number of current open research
issues are discussed.
","Mingli Song|Dachent Tao|Stephen J. Maybank","","http://arxiv.org/abs/1302.0446v1","http://arxiv.org/pdf/1302.0446v1","","41 pages, 5 figures, journal submission","","","cs.CV","cs.CV"
"53","1303.5234v3","2013-03-21 11:53:37","2014-03-16 22:30:10","How to perform research in Hadoop environment not losing mental
  equilibrium - case study","  Conducting a research in an efficient, repetitive, evaluable, but also
convenient (in terms of development) way has always been a challenge. To
satisfy those requirements in a long term and simultaneously minimize costs of
the software engineering process, one has to follow a certain set of
guidelines. This article describes such guidelines based on the research
environment called Content Analysis System (CoAnSys) created in the Center for
Open Science (CeON). Best practices and tools for working in the Apache Hadoop
environment, as well as the process of establishing these rules are portrayed.
","Piotr Jan Dendek|Artur Czeczko|Mateusz Fedoryszak|Adam Kawa|Piotr Wendykier|Lukasz Bolikowski","","http://arxiv.org/abs/1303.5234v3","http://arxiv.org/pdf/1303.5234v3","","This paper (with changed content) appeared under the title ""Chrum:
  The Tool for Convenient Generation of Apache Oozie Workflows"" in ""Intelligent
  Tools for Building a Scientific Information Platform: From Research to
  Implementation"", ""Studies in Computational Intelligence"", Volume 541, 2014,
  http://link.springer.com/book/10.1007/978-3-319-04714-0","","","cs.SE","cs.SE|cs.DC|H.3.7"
"54","1304.2031v1","2013-04-07 17:43:26","2013-04-07 17:43:26","Temporal Analysis of Activity Patterns of Editors in Collaborative
  Mapping Project of OpenStreetMap","  In the recent years Wikis have become an attractive platform for social
studies of the human behaviour. Containing millions records of edits across the
globe, collaborative systems such as Wikipedia have allowed researchers to gain
a better understanding of editors participation and their activity patterns.
However, contributions made to Geo-wikis_wiki-based collaborative mapping
projects_ differ from systems such as Wikipedia in a fundamental way due to
spatial dimension of the content that limits the contributors to a set of those
who posses local knowledge about a specific area and therefore cross-platform
studies and comparisons are required to build a comprehensive image of online
open collaboration phenomena. In this work, we study the temporal behavioural
pattern of OpenStreetMap editors, a successful example of geo-wiki, for two
European capital cities. We categorise different type of temporal patterns and
report on the historical trend within a period of 7 years of the project age.
We also draw a comparison with the previously observed editing activity
patterns of Wikipedia.
","Taha Yasseri|Giovanni Quattrone|Afra Mashhadi","","http://arxiv.org/abs/1304.2031v1","http://arxiv.org/pdf/1304.2031v1","","Submitted","","","cs.CY","cs.CY|cs.HC|cs.SI|physics.data-an|physics.soc-ph"
"55","1304.5545v1","2013-04-19 21:00:37","2013-04-19 21:00:37","Designing Electronic Markets for Defeasible-based Contractual Agents","  The design of punishment policies applied to specific domains linking agents
actions to material penalties is an open research issue. The proposed framework
applies principles of contract law to set penalties: expectation damages,
opportunity cost, reliance damages, and party design remedies. In order to
decide which remedy provides maximum welfare within an electronic market, a
simulation environment called DEMCA (Designing Electronic Markets for
Contractual Agents) was developed. Knowledge representation and the reasoning
capabilities of the agents are based on an extended version of temporal
defeasible logic.
","Adrian Groza","","http://arxiv.org/abs/1304.5545v1","http://arxiv.org/pdf/1304.5545v1","","LAF Workshop 2008","","","cs.MA","cs.MA"
"56","1305.3532v1","2013-05-15 16:18:24","2013-05-15 16:18:24","Temporal networks of face-to-face human interactions","  The ever increasing adoption of mobile technologies and ubiquitous services
allows to sense human behavior at unprecedented levels of details and scale.
Wearable sensors are opening up a new window on human mobility and proximity at
the finest resolution of face-to-face proximity. As a consequence, empirical
data describing social and behavioral networks are acquiring a longitudinal
dimension that brings forth new challenges for analysis and modeling. Here we
review recent work on the representation and analysis of temporal networks of
face-to-face human proximity, based on large-scale datasets collected in the
context of the SocioPatterns collaboration. We show that the raw behavioral
data can be studied at various levels of coarse-graining, which turn out to be
complementary to one another, with each level exposing different features of
the underlying system. We briefly review a generative model of temporal contact
networks that reproduces some statistical observables. Then, we shift our focus
from surface statistical features to dynamical processes on empirical temporal
networks. We discuss how simple dynamical processes can be used as probes to
expose important features of the interaction patterns, such as burstiness and
causal constraints. We show that simulating dynamical processes on empirical
temporal networks can unveil differences between datasets that would otherwise
look statistically similar. Moreover, we argue that, due to the temporal
heterogeneity of human dynamics, in order to investigate the temporal
properties of spreading processes it may be necessary to abandon the notion of
wall-clock time in favour of an intrinsic notion of time for each individual
node, defined in terms of its activity level. We conclude highlighting several
open research questions raised by the nature of the data at hand.
","Alain Barrat|Ciro Cattuto","","http://arxiv.org/abs/1305.3532v1","http://arxiv.org/pdf/1305.3532v1","http://dx.doi.org/10.1007/978-3-642-36461-7_10","Chapter of the book ""Temporal Networks"", Springer, 2013. Series:
  Understanding Complex Systems. Holme, Petter; Saram\""aki, Jari (Eds.)","","10.1007/978-3-642-36461-7_10","physics.soc-ph","physics.soc-ph|cs.SI"
"57","1306.3543v2","2013-06-15 03:19:51","2013-06-18 15:58:27","The Open Connectome Project Data Cluster: Scalable Analysis and Vision
  for High-Throughput Neuroscience","  We describe a scalable database cluster for the spatial analysis and
annotation of high-throughput brain imaging data, initially for 3-d electron
microscopy image stacks, but for time-series and multi-channel data as well.
The system was designed primarily for workloads that build connectomes---neural
connectivity maps of the brain---using the parallel execution of computer
vision algorithms on high-performance compute clusters. These services and
open-science data sets are publicly available at http://openconnecto.me.
  The system design inherits much from NoSQL scale-out and data-intensive
computing architectures. We distribute data to cluster nodes by partitioning a
spatial index. We direct I/O to different systems---reads to parallel disk
arrays and writes to solid-state storage---to avoid I/O interference and
maximize throughput. All programming interfaces are RESTful Web services, which
are simple and stateless, improving scalability and usability. We include a
performance evaluation of the production system, highlighting the effectiveness
of spatial data organization.
","Randal Burns|William Gray Roncal|Dean Kleissas|Kunal Lillaney|Priya Manavalan|Eric Perlman|Daniel R. Berger|Davi D. Bock|Kwanghun Chung|Logan Grosenick|Narayanan Kasthuri|Nicholas C. Weiler|Karl Deisseroth|Michael Kazhdan|Jeff Lichtman|R. Clay Reid|Stephen J. Smith|Alexander S. Szalay|Joshua T. Vogelstein|R. Jacob Vogelstein","","http://arxiv.org/abs/1306.3543v2","http://arxiv.org/pdf/1306.3543v2","","11 pages, 13 figures","","","cs.DC","cs.DC|cs.CE|q-bio.NC"
"58","1308.0843v2","2013-08-04 19:30:19","2013-10-02 00:17:49","Snowmass Energy Frontier Simulations using the Open Science Grid (A
  Snowmass 2013 whitepaper)","  Snowmass is a US long-term planning study for the high-energy community by
the American Physical Society's Division of Particles and Fields. For its
simulation studies, opportunistic resources are harnessed using the Open
Science Grid infrastructure. Late binding grid technology, GlideinWMS, was used
for distributed scheduling of the simulation jobs across many sites mainly in
the US. The pilot infrastructure also uses the Parrot mechanism to dynamically
access CvmFS in order to ascertain a homogeneous environment across the nodes.
This report presents the resource usage and the storage model used for
simulating large statistics Standard Model backgrounds needed for Snowmass
Energy Frontier studies.
","A. Avetisyan|S. Bhattacharya|M. Narain|S. Padhi|J. Hirschauer|T. Levshina|P. McBride|C. Sehgal|M. Slyz|M. Rynge|S. Malik|J. Stupak III","Boston University, Boston, USA|Brown University, Providence, USA|Brown University, Providence, USA|University of California, San Diego, USA|Fermi National Accelerator Lab, Batavia, USA|Fermi National Accelerator Lab, Batavia, USA|Fermi National Accelerator Lab, Batavia, USA|Fermi National Accelerator Lab, Batavia, USA|Fermi National Accelerator Lab, Batavia, USA|Information Sciences Institute, Marina del Rey, USA|University of Nebraska, Lincoln, USA|Purdue University Calumet, Hammond, USA","http://arxiv.org/abs/1308.0843v2","http://arxiv.org/pdf/1308.0843v2","","","","","hep-ex","hep-ex|cs.DC"
"59","1308.1168v1","2013-08-06 03:13:36","2013-08-06 03:13:36","Role and Discipline Relationships in a Transdisciplinary Biomedical
  Team: Structuration, Values Override and Context Scaffolding","  Though accepted that ""team science"" is needed to tackle and conquer the
health problems that are plaguing our society significant empirical evidence of
team mechanisms and functional dynamics is still lacking in abundance. Through
grounded methods the relationship between scientific disciplines and team roles
was observed in a United States National Institutes of Health-funded (NIH)
research consortium. Interviews and the Organizational Culture Assessment
Instrument (OCAI) were employed.. Findings show strong role and discipline
idiosyncrasies that when viewed separately provide different insights into team
functioning and change receptivity. When considered simultaneously,
value-latent characteristics emerged showing self-perceived contributions to
the team. This micro/meso analysis suggests that individual participation in
team level interactions can inform the structuration of roles and disciplines
in an attempt to tackle macro level problems.
","Gaetano R. Lotrecchiano","","http://arxiv.org/abs/1308.1168v1","http://arxiv.org/pdf/1308.1168v1","","Presented at COINs13 Conference, Chile, 2013 (arxiv:1308.1028)","","","cs.CY","cs.CY|cs.SI|physics.soc-ph"
"60","1310.8125v1","2013-08-23 07:55:54","2013-08-23 07:55:54","Finding Alternate Paths in the Internet:A Survey of Techniques for
  End-to-End Path Discovery","  The Internet provides physical path diversity between a large number of
hosts, making it possible for networks to use alternative paths when one path
fails to deliver the required Quality of Service. However, for various reasons,
many established protocols (e.g. de facto Internet inter-domain routing
protocol, Border-Gateway Protocol - BGP) do not fully exploit such alternate
paths. This paper surveys research into techniques for discovering end-to-end
alternate paths, including those based on monitoring path performance, choosing
paths that are maximally disjoint, and in routing across multiple paths. It
surveys proposals for making BGP better able to exploit multiple paths and how
multi-homing can create alternate paths. It also describes how alternate paths
can be realized through detour routing (application layer mechanisms) and
routing deflections (network layer mechanisms). It also discusses Fast Re-Route
techniques for construction of backup routes. It concludes by surveying open
research issues into the discovery and use of alternate paths in the Internet.
","Sameer Qazi|Tim Moors","","http://arxiv.org/abs/1310.8125v1","http://arxiv.org/pdf/1310.8125v1","","13 pages, 10 figures","International Journal of Current Engineering and Technology, Vol
  2, No 4, ISSN 2277 - 4106, December 2012","","cs.NI","cs.NI|B.8.0"
"61","1309.0085v1","2013-08-31 09:34:48","2013-08-31 09:34:48","Artificial Intelligence Based Cognitive Routing for Cognitive Radio
  Networks","  Cognitive radio networks (CRNs) are networks of nodes equipped with cognitive
radios that can optimize performance by adapting to network conditions. While
cognitive radio networks (CRN) are envisioned as intelligent networks,
relatively little research has focused on the network level functionality of
CRNs. Although various routing protocols, incorporating varying degrees of
adaptiveness, have been proposed for CRNs, it is imperative for the long term
success of CRNs that the design of cognitive routing protocols be pursued by
the research community. Cognitive routing protocols are envisioned as routing
protocols that fully and seamless incorporate AI-based techniques into their
design. In this paper, we provide a self-contained tutorial on various AI and
machine-learning techniques that have been, or can be, used for developing
cognitive routing protocols. We also survey the application of various classes
of AI techniques to CRNs in general, and to the problem of routing in
particular. We discuss various decision making techniques and learning
techniques from AI and document their current and potential applications to the
problem of routing in CRNs. We also highlight the various inference, reasoning,
modeling, and learning sub tasks that a cognitive routing protocol must solve.
Finally, open research issues and future directions of work are identified.
","Junaid Qadir","","http://arxiv.org/abs/1309.0085v1","http://arxiv.org/pdf/1309.0085v1","http://dx.doi.org/10.1007/s10462-015-9438-6","28 pages, submitted to IEEE Communications Surveys and Tutorials","Artificial Intelligence Review pp 1-72 First online: 03 September
  2015","10.1007/s10462-015-9438-6","cs.NI","cs.NI|cs.AI"
"62","1309.2690v1","2013-09-10 23:20:26","2013-09-10 23:20:26","Energt Efficient MAC Protocols for Wireless Sensor Network: A Survey","  Wireless Sensor Network (WSN) is an attractive choice for a variety of
applications as no wired infrastructure is needed. Other wireless networks are
not as energy constrained as WSNs, because they may be plugged into the mains
supply or equipped with batteries that are rechargeable and replaceable. Among
others, one of the main sources of energy depletion in WSN is communications
controlled by the Medium Access Control (MAC) protocols. An extensive survey of
energy efficient MAC protocols is presented in this article. We categorise WSN
MAC protocols in the following categories: controlled access (CA), random
access (RA), slotted protocols (SP) and hybrid protocols (HP). We further
discuss how energy efficient MAC protocols have developed from fixed sleep/wake
cycles through adaptive to dynamic cycles, thus becoming more responsive to
traffic load variations. Finally we present open research questions on MAC
layer design for WSNs in terms of energy efficiency
","Eleazar Chukwuka|Kamran Arshad","","http://arxiv.org/abs/1309.2690v1","http://arxiv.org/pdf/1309.2690v1","http://dx.doi.org/10.5121/ijwmn.2013.5406","16 pages","","10.5121/ijwmn.2013.5406","cs.IT","cs.IT|cs.NI|math.IT"
"63","1309.3949v1","2013-09-16 13:27:04","2013-09-16 13:27:04","Performance Investigation of Feature Selection Methods","  Sentiment analysis or opinion mining has become an open research domain after
proliferation of Internet and Web 2.0 social media. People express their
attitudes and opinions on social media including blogs, discussion forums,
tweets, etc. and, sentiment analysis concerns about detecting and extracting
sentiment or opinion from online text. Sentiment based text classification is
different from topical text classification since it involves discrimination
based on expressed opinion on a topic. Feature selection is significant for
sentiment analysis as the opinionated text may have high dimensions, which can
adversely affect the performance of sentiment analysis classifier. This paper
explores applicability of feature selection methods for sentiment analysis and
investigates their performance for classification in term of recall, precision
and accuracy. Five feature selection methods (Document Frequency, Information
Gain, Gain Ratio, Chi Squared, and Relief-F) and three popular sentiment
feature lexicons (HM, GI and Opinion Lexicon) are investigated on movie reviews
corpus with a size of 2000 documents. The experimental results show that
Information Gain gave consistent results and Gain Ratio performs overall best
for sentimental feature selection while sentiment lexicons gave poor
performance. Furthermore, we found that performance of the classifier depends
on appropriate number of representative feature selected from text.
","Anuj sharma|Shubhamoy Dey","","http://arxiv.org/abs/1309.3949v1","http://arxiv.org/pdf/1309.3949v1","","6 pages","","","cs.IR","cs.IR|cs.CL|cs.LG"
"64","1310.0251v2","2013-10-01 11:38:32","2014-01-28 10:52:58","Building Programmable Wireless Networks: An Architectural Survey","  In recent times, there have been a lot of efforts for improving the ossified
Internet architecture in a bid to sustain unstinted growth and innovation. A
major reason for the perceived architectural ossification is the lack of
ability to program the network as a system. This situation has resulted partly
from historical decisions in the original Internet design which emphasized
decentralized network operations through co-located data and control planes on
each network device. The situation for wireless networks is no different
resulting in a lot of complexity and a plethora of largely incompatible
wireless technologies. The emergence of ""programmable wireless networks"", that
allow greater flexibility, ease of management and configurability, is a step in
the right direction to overcome the aforementioned shortcomings of the wireless
networks. In this paper, we provide a broad overview of the architectures
proposed in literature for building programmable wireless networks focusing
primarily on three popular techniques, i.e., software defined networks,
cognitive radio networks, and virtualized networks. This survey is a
self-contained tutorial on these techniques and its applications. We also
discuss the opportunities and challenges in building next-generation
programmable wireless networks and identify open research issues and future
research directions.
","Junaid Qadir|Nadeem Ahmed|Nauman Ahad","","http://arxiv.org/abs/1310.0251v2","http://arxiv.org/pdf/1310.0251v2","http://dx.doi.org/10.1186/1687-1499-2014-172","19 pages","EURASIP JWCN, October, 2014","10.1186/1687-1499-2014-172","cs.NI","cs.NI"
"65","1310.0720v6","2013-10-02 14:45:44","2014-04-29 09:59:07","A Survey on Device-to-Device Communication in Cellular Networks","  Device-to-Device (D2D) communication was initially proposed in cellular
networks as a new paradigm to enhance network performance. The emergence of new
applications such as content distribution and location-aware advertisement
introduced new use-cases for D2D communications in cellular networks. The
initial studies showed that D2D communication has advantages such as increased
spectral efficiency and reduced communication delay. However, this
communication mode introduces complications in terms of interference control
overhead and protocols that are still open research problems. The feasibility
of D2D communications in LTE-A is being studied by academia, industry, and the
standardization bodies. To date, there are more than 100 papers available on
D2D communications in cellular networks and, there is no survey on this field.
In this article, we provide a taxonomy based on the D2D communicating spectrum
and review the available literature extensively under the proposed taxonomy.
Moreover, we provide new insights to the over-explored and under-explored areas
which lead us to identify open research problems of D2D communication in
cellular networks.
","Arash Asadi|Qing Wang|Vincenzo Mancuso","","http://arxiv.org/abs/1310.0720v6","http://arxiv.org/pdf/1310.0720v6","http://dx.doi.org/10.1109/COMST.2014.2319555","18 pages; 8 figures; Accepted for publication in IEEE Communications
  Surveys and Tutorials","","10.1109/COMST.2014.2319555","cs.GT","cs.GT|cs.IT|cs.NI|math.IT"
"66","1310.5949v2","2013-10-22 15:10:56","2013-11-04 23:01:47","Safety Challenges and Solutions in Mobile Social Networks","  Mobile social networks (MSNs) are specific types of social media which
consolidate the ability of omnipresent connection for mobile users/devices to
share user-centric data objects among interested users. Taking advantage of the
characteristics of both social networks and opportunistic networks, MSNs are
capable of providing an efficient and effective mobile environment for users to
access, share, and distribute data. However, lack of a protective
infrastructure in these networks has turned them in to convenient targets for
various perils. This is the main impulse why MSNs carry disparate and intricate
safety concerns and embrace divergent safety challenging problems. In this
paper, we aim to provide a clear categorization on safety challenges and a deep
exploration over some recent solutions in MSNs. This work narrows the safety
challenges and solution techniques down from opportunistic networks (OppNets)
and delay tolerant networks (DTNs) to MSNs with the hope of covering all the
work proposed around security, privacy and trust in MSNs. To conclude, several
major open research issues are discussed and future research directions are
outlined.
","Yashar Najaflou|Behrouz Jedari|Feng Xia|Laurence T. Yang|Mohammad S. Obaidat","","http://arxiv.org/abs/1310.5949v2","http://arxiv.org/pdf/1310.5949v2","http://dx.doi.org/10.1109/JSYST.2013.2284696","accepted, 21 pages, 13 figures, 3 tables. IEEE System Journal, 2013","","10.1109/JSYST.2013.2284696","cs.NI","cs.NI|cs.CR"
"67","1311.6932v1","2013-11-27 11:06:05","2013-11-27 11:06:05","A novel framework for image forgery localization","  Image forgery localization is a very active and open research field for the
difficulty to handle the large variety of manipulations a malicious user can
perform by means of more and more sophisticated image editing tools. Here, we
propose a localization framework based on the fusion of three very different
tools, based, respectively, on sensor noise, patch-matching, and machine
learning. The binary masks provided by these tools are finally fused based on
some suitable reliability indexes. According to preliminary experiments on the
training set, the proposed framework provides often a very good localization
accuracy and sometimes valuable clues for visual scrutiny.
","Davide Cozzolino|Diego Gragnaniello|Luisa Verdoliva","","http://arxiv.org/abs/1311.6932v1","http://arxiv.org/pdf/1311.6932v1","","4 pages","","","cs.CV","cs.CV"
"68","1312.0049v1","2013-11-30 01:52:36","2013-11-30 01:52:36","One-Class Classification: Taxonomy of Study and Review of Techniques","  One-class classification (OCC) algorithms aim to build classification models
when the negative class is either absent, poorly sampled or not well defined.
This unique situation constrains the learning of efficient classifiers by
defining class boundary just with the knowledge of positive class. The OCC
problem has been considered and applied under many research themes, such as
outlier/novelty detection and concept learning. In this paper we present a
unified view of the general problem of OCC by presenting a taxonomy of study
for OCC problems, which is based on the availability of training data,
algorithms used and the application domains applied. We further delve into each
of the categories of the proposed taxonomy and present a comprehensive
literature review of the OCC algorithms, techniques and methodologies with a
focus on their significance, limitations and applications. We conclude our
paper by discussing some open research problems in the field of OCC and present
our vision for future research.
","Shehroz S. Khan|Michael G. Madden","","http://arxiv.org/abs/1312.0049v1","http://arxiv.org/pdf/1312.0049v1","http://dx.doi.org/10.1017/S026988891300043X","24 pages + 11 pages of references, 8 figures","The Knowledge Engineering Review, pp 1-30, 2014","10.1017/S026988891300043X","cs.LG","cs.LG|cs.AI"
"69","1401.4254v1","2014-01-17 07:05:23","2014-01-17 07:05:23","Goal-oriented Composition of Software Process Patterns","  The development of high-quality software or software-intensive systems
requires custom-tailored process models that fit the organizational and project
goals as well as the development contexts. These models are a necessary
prerequisite for creating project plans that are expected to fulfill business
goals. Although project planners require individual process models
custom-tailored to their constraints, software or system developing
organizations also require generic processes (i.e., reference processes) that
capture project-independent knowledge for similar development contexts. The
latter is emphazised by assessment approaches (such as CMMI, SPICE) that
require explicit process descriptions in order to reach a certain capability or
maturity level. Among other concepts such as polymorphism, templates, or
generator-based descriptions, software process patterns are used to describe
generic process knowledge. Several approaches for describing the architecture
of process patterns have already been published (e.g., [7]). However, there is
a lack of descriptions on how to compose process patterns for a specific
decelopment context in order to gain a custom-tailored process model for a
project. This paper focuses on the composition of process patterns in a
goal-oriented way. First, the paper describes which information a process
pattern should contain so that it can be used for systematic composition.
Second, a composition method is sketched. Afterwards, the results of a
proof-of-concept evaluation of the method are described. Finally, the paper is
summarized and open research questions are sketched.
","Jürgen Münch","","http://arxiv.org/abs/1401.4254v1","http://arxiv.org/pdf/1401.4254v1","","5 pages","Proceedings of the 6th International Workshop on Software Process
  Simulation and Modeling (ProSim 2005), pages 164-168, St. Louis, Missouri,
  USA, May 14-15 2005","","cs.SE","cs.SE"
"70","1402.2297v1","2014-02-10 21:02:14","2014-02-10 21:02:14","Connecting Dream Networks Across Cultures","  Many species dream, yet there remain many open research questions in the
study of dreams. The symbolism of dreams and their interpretation is present in
cultures throughout history. Analysis of online data sources for dream
interpretation using network science leads to understanding symbolism in dreams
and their associated meaning. In this study, we introduce dream interpretation
networks for English, Chinese and Arabic that represent different cultures from
various parts of the world. We analyze communities in these networks, finding
that symbols within a community are semantically related. The central nodes in
communities give insight about cultures and symbols in dreams. The community
structure of different networks highlights cultural similarities and
differences. Interconnections between different networks are also identified by
translating symbols from different languages into English. Structural
correlations across networks point out relationships between cultures.
Similarities between network communities are also investigated by analysis of
sentiment in symbol interpretations. We find that interpretations within a
community tend to have similar sentiment. Furthermore, we cluster communities
based on their sentiment, yielding three main categories of positive, negative,
and neutral dream symbols.
","Onur Varol|Filippo Menczer","","http://arxiv.org/abs/1402.2297v1","http://arxiv.org/pdf/1402.2297v1","http://dx.doi.org/10.1145/2567948.2579697","6 pages, 3 figures","","10.1145/2567948.2579697","cs.SI","cs.SI|physics.soc-ph"
"71","1402.5090v4","2014-02-20 18:15:56","2014-12-02 23:56:49","MAD Bayes for Tumor Heterogeneity Feature Allocation with Non-Normal
  Sampling","  We propose small-variance asymptotic approximations for the inference of
tumor heterogeneity (TH) using next-generation sequencing data. Understanding
TH is an important and open research problem in biology. The lack of
appropriate statistical inference is a critical gap in existing methods that
the proposed approach aims to fill. We build on a hierarchical model with an
exponential family likelihood and a feature allocation prior. The proposed
approach generalizes similar small-variance approximations proposed by Kulis
and Jordan (2012) and Broderick et.al (2012) for inference with Dirichlet
process mixture and Indian buffet prior models under normal sampling. We show
that the new algorithm can successfully recover latent structures of different
subclones and is also magnitude faster than available Markov chain Monte Carlo
samplers, the latter often practically infeasible for high-dimensional genomics
data. The proposed approach is scalable, simple to implement and benefits from
the flexibility of Bayesian nonparametric models. More importantly, it provides
a useful tool for the biological community for estimating cell subtypes in
tumor samples.
","Yanxun Xu|Peter Mueller|Yuan Yuan|Kamalakar Gulukota|Yuan Ji","","http://arxiv.org/abs/1402.5090v4","http://arxiv.org/pdf/1402.5090v4","http://dx.doi.org/10.1080/01621459.2014.995794","","","10.1080/01621459.2014.995794","stat.ME","stat.ME"
"72","1402.6013v1","2014-02-24 23:12:42","2014-02-24 23:12:42","Open science in machine learning","  We present OpenML and mldata, open science platforms that provides easy
access to machine learning data, software and results to encourage further
study and application. They go beyond the more traditional repositories for
data sets and software packages in that they allow researchers to also easily
share the results they obtained in experiments and to compare their solutions
with those of others.
","Joaquin Vanschoren|Mikio L. Braun|Cheng Soon Ong","","http://arxiv.org/abs/1402.6013v1","http://arxiv.org/pdf/1402.6013v1","","","","","cs.LG","cs.LG|cs.DL"
"73","1403.5723v1","2014-03-23 05:36:48","2014-03-23 05:36:48","Game-theoretic Resource Allocation Methods for Device-to-Device (D2D)
  Communication","  Device-to-device (D2D) communication underlaying cellular networks allows
mobile devices such as smartphones and tablets to use the licensed spectrum
allocated to cellular services for direct peer-to-peer transmission. D2D
communication can use either one-hop transmission (i.e., in D2D direct
communication) or multi-hop cluster-based transmission (i.e., in D2D local area
networks). The D2D devices can compete or cooperate with each other to reuse
the radio resources in D2D networks. Therefore, resource allocation and access
for D2D communication can be treated as games. The theories behind these games
provide a variety of mathematical tools to effectively model and analyze the
individual or group behaviors of D2D users. In addition, game models can
provide distributed solutions to the resource allocation problems for D2D
communication. The aim of this article is to demonstrate the applications of
game-theoretic models to study the radio resource allocation issues in D2D
communication. The article also outlines several key open research directions.
","Lingyang Song|Dusit Niyato|Zhu Han|Ekram Hossain","","http://arxiv.org/abs/1403.5723v1","http://arxiv.org/pdf/1403.5723v1","","Accepted. IEEE Wireless Comms Mag. 2014","","","cs.NI","cs.NI"
"74","1404.0191v2","2014-04-01 10:43:36","2014-07-02 09:43:18","A quantitative perspective on ethics in large team science","  The gradual crowding out of singleton and small team science by large team
endeavors is challenging key features of research culture. It is therefore
important for the future of scientific practice to reflect upon the individual
scientist's ethical responsibilities within teams. To facilitate this
reflection we show labor force trends in the US revealing a skewed growth in
academic ranks and increased levels of competition for promotion within the
system; we analyze teaming trends across disciplines and national borders
demonstrating why it is becoming difficult to distribute credit and to avoid
conflicts of interest; and we use more than a century of Nobel prize data to
show how science is outgrowing its old institutions of singleton awards. Of
particular concern within the large team environment is the weakening of the
mentor-mentee relation, which undermines the cultivation of virtue ethics
across scientific generations. These trends and emerging organizational
complexities call for a universal set of behavioral norms that transcend team
heterogeneity and hierarchy. To this end, our expository analysis provides a
survey of ethical issues in team settings to inform science ethics education
and science policy.
","Alexander M. Petersen|Ioannis Pavlidis|Ioanna Semendeferi","","http://arxiv.org/abs/1404.0191v2","http://arxiv.org/pdf/1404.0191v2","http://dx.doi.org/10.1007/s11948-014-9562-8","13 pages, 5 figures, 1 table. Keywords: team ethics; team management;
  team evaluation; science of science","Science & Engineering Ethics 20, 923-945 (2014)","10.1007/s11948-014-9562-8","physics.soc-ph","physics.soc-ph|cs.CY|cs.DL"
"75","1405.1965v1","2014-04-16 20:57:19","2014-04-16 20:57:19","Automatic Annotation of Axoplasmic Reticula in Pursuit of Connectomes
  using High-Resolution Neural EM Data","  Accurately estimating the wiring diagram of a brain, known as a connectome,
at an ultrastructure level is an open research problem. Specifically, precisely
tracking neural processes is difficult, especially across many image slices.
Here, we propose a novel method to automatically identify and annotate small
subcellular structures present in axons, known as axoplasmic reticula, through
a 3D volume of high-resolution neural electron microscopy data. Our method
produces high precision annotations, which can help improve automatic
segmentation by using our results as seeds for segmentation, and as cues to aid
segment merging.
","Ayushi Sinha|William Gray Roncal|Narayanan Kasthuri|Jeff W. Lichtman|Randal Burns|Michael Kazhdan","Department of Computer Science, The Johns Hopkins University, Baltimore, MD|Department of Computer Science, The Johns Hopkins University, Baltimore, MD|Department of Molecular and Cellular Biology, Harvard University, Cambridge, MA|Department of Molecular and Cellular Biology, Harvard University, Cambridge, MA|Department of Computer Science, The Johns Hopkins University, Baltimore, MD|Department of Computer Science, The Johns Hopkins University, Baltimore, MD","http://arxiv.org/abs/1405.1965v1","http://arxiv.org/pdf/1405.1965v1","","2 pages, 1 figure; The 3rd Annual Hopkins Imaging Conference, The
  Johns Hopkins University, Baltimore, MD","","","cs.CV","cs.CV"
"76","1404.6267v3","2014-04-24 21:00:14","2014-06-12 16:28:56","Social Evolution: New Horizons","  Cooperation is a widespread natural phenomenon yet current evolutionary
thinking is dominated by the paradigm of selfish competition. Recent advanced
in many fronts of Biology and Non-linear Physics are helping to bring
cooperation to its proper place. In this contribution, the most important
controversies and open research avenues in the field of social evolution are
reviewed. It is argued that a novel theory of social evolution must integrate
the concepts of the science of Complex Systems with those of the Darwinian
tradition. Current gene-centric approaches should be reviewed and com-
plemented with evidence from multilevel phenomena (group selection), the
constrains given by the non-linear nature of biological dynamical systems and
the emergent nature of dissipative phenomena.
","Octavio Miramontes|Og DeSouza","","http://arxiv.org/abs/1404.6267v3","http://arxiv.org/pdf/1404.6267v3","","16 pages 5 figures, chapter in forthcoming open access book
  ""Frontiers in Ecology, Evolution and Complexity"" CopIt-arXives 2014, Mexico","","","q-bio.PE","q-bio.PE"
"77","1405.5630v1","2014-05-22 04:50:12","2014-05-22 04:50:12","Resource Allocation in Wireless Networks with RF Energy Harvesting and
  Transfer","  Radio frequency (RF) energy harvesting and transfer techniques have recently
become alternative methods to power the next generation of wireless networks.
As this emerging technology enables proactive replenishment of wireless
devices, it is advantageous in supporting applications with quality-of-service
(QoS) requirement. This article focuses on the resource allocation issues in
wireless networks with RF energy harvesting capability, referred to as RF
energy harvesting networks (RF-EHNs). First, we present an overview of the
RF-EHNs, followed by a review of a variety of issues regarding resource
allocation. Then, we present a case study of designing in the receiver
operation policy, which is of paramount importance in the RF-EHNs. We focus on
QoS support and service differentiation, which have not been addressed by
previous literatures. Furthermore, we outline some open research directions.
","Xiao Lu|Ping Wang|Dusit Niyato|Zhu Han","","http://arxiv.org/abs/1405.5630v1","http://arxiv.org/pdf/1405.5630v1","http://dx.doi.org/10.1109/MNET.2015.7340427","To appear in IEEE Network","","10.1109/MNET.2015.7340427","cs.NI","cs.NI"
"78","1406.3194v1","2014-06-12 11:26:05","2014-06-12 11:26:05","Multicasting in Cognitive Radio Networks: Algorithms, Techniques and
  Protocols","  Multicasting is a fundamental networking primitive utilized by numerous
applications. This also holds true for cognitive radio networks (CRNs) which
have been proposed as a solution to the problems that emanate from the static
non-adaptive features of classical wireless networks. A prime application of
CRNs is dynamic spectrum access (DSA), which improves the efficiency of
spectrum allocation by allowing a secondary network, comprising of secondary
users (SUs), to share spectrum licensed to a primary licensed networks
comprising of primary users (PUs). Multicasting in CRNs is a challenging
problem due to the dynamic nature of spectrum opportunities available to the
SUs. Various approaches, including those based in optimization theory, network
coding, algorithms, have been proposed for performing efficient multicast in
CRNs. In this paper, we provide a self-contained tutorial on algorithms and
techniques useful for solving the multicast problem, and then provide a
comprehensive survey of protocols that have been proposed for multicasting in
CRNs. We conclude this paper by identifying open research questions and future
research directions.
","Junaid Qadir|Adeel Baig|Asad Ali|Quratulain Shafi","","http://arxiv.org/abs/1406.3194v1","http://arxiv.org/pdf/1406.3194v1","http://dx.doi.org/10.1016/j.jnca.2014.07.024","","Elsevier Journal of Network and Computer Applications, October,
  2014","10.1016/j.jnca.2014.07.024","cs.NI","cs.NI"
"79","1406.6470v6","2014-06-25 06:27:37","2014-09-05 09:09:39","Wireless Networks with RF Energy Harvesting: A Contemporary Survey","  Radio frequency (RF) energy transfer and harvesting techniques have recently
become alternative methods to power the next generation wireless networks. As
this emerging technology enables proactive energy replenishment of wireless
devices, it is advantageous in supporting applications with quality of service
(QoS) requirement. In this paper, we present an extensive literature review on
the research progresses in wireless networks with RF energy harvesting
capability, referred to as RF energy harvesting networks (RF-EHNs). First, we
present an overview of the RF-EHNs including system architecture, RF energy
harvesting techniques and existing applications. Then, we present the
background in circuit design as well as the state-of-the-art circuitry
implementations, and review the communication protocols specially designed for
RF-EHNs. We also explore various key design issues in the development of
RF-EHNs according to the network types, i.e., single-hop network, multi-antenna
network, relay network and cognitive radio network. Finally, we envision some
open research directions.
","Xiao Lu|Ping Wang|Dusit Niyato|Dong In Kim|Zhu Han","","http://arxiv.org/abs/1406.6470v6","http://arxiv.org/pdf/1406.6470v6","","Any comment(s) would be highly welcomed. Please send email to
  luxiao@ntu.edu.sg","","","cs.NI","cs.NI|cs.IT|math.IT"
"80","1406.7541v1","2014-06-29 19:31:57","2014-06-29 19:31:57","Open Collaboration for Innovation: Principles and Performance","  The principles of open collaboration for innovation (and production), once
distinctive to open source software, are now found in many other ventures. Some
of these ventures are internet-based: Wikipedia, online forums and communities.
Others are off-line: in medicine, science, and everyday life. Such ventures
have been affecting traditional firms, and may represent a new organizational
form. Despite the impact of such ventures, questions remain about their
operating principles and performance. Here we define open collaboration (OC),
the underlying set of principles, and propose that it is a robust engine for
innovation and production. First, we review multiple OC ventures and identify
four defining principles. In all instances, participants create goods and
services of economic value, they exchange and reuse each other's work, they
labor purposefully with just loose coordination, and they permit anyone to
contribute and consume. These principles distinguish OC from other
organizational forms, such as firms or cooperatives. Next, we turn to
performance. To understand the performance of OC, we develop a computational
model, combining innovation theory with recent evidence on human cooperation.
We identify and investigate three elements that affect performance: the
cooperativeness of participants, the diversity of their needs, and the degree
to which the goods are rival (subtractable). Through computational experiments,
we find that OC performs well even in seemingly harsh environments: when
cooperators are a minority, free riders are present, diversity is lacking, or
goods are rival. We conclude that OC is viable and likely to expand into new
domains. The findings also inform the discussion on new organizational forms,
collaborative and communal.
","Sheen Levine|Michael Prietula","","http://arxiv.org/abs/1406.7541v1","http://arxiv.org/pdf/1406.7541v1","","","","","cs.CY","cs.CY"
"81","1407.2704v2","2014-07-10 06:19:58","2014-07-21 01:44:13","When Things Matter: A Data-Centric View of the Internet of Things","  With the recent advances in radio-frequency identification (RFID), low-cost
wireless sensor devices, and Web technologies, the Internet of Things (IoT)
approach has gained momentum in connecting everyday objects to the Internet and
facilitating machine-to-human and machine-to-machine communication with the
physical world. While IoT offers the capability to connect and integrate both
digital and physical entities, enabling a whole new class of applications and
services, several significant challenges need to be addressed before these
applications and services can be fully realized. A fundamental challenge
centers around managing IoT data, typically produced in dynamic and volatile
environments, which is not only extremely large in scale and volume, but also
noisy, and continuous. This article surveys the main techniques and
state-of-the-art research efforts in IoT from data-centric perspectives,
including data stream processing, data storage models, complex event
processing, and searching in IoT. Open research issues for IoT data management
are also discussed.
","Yongrui Qin|Quan Z. Sheng|Nickolas J. G. Falkner|Schahram Dustdar|Hua Wang|Athanasios V. Vasilakos","","http://arxiv.org/abs/1407.2704v2","http://arxiv.org/pdf/1407.2704v2","","","","","cs.DB","cs.DB|cs.NI"
"82","1407.3682v2","2014-07-14 14:58:20","2014-07-15 10:15:12","When data sharing gets close to 100%: what ancient human DNA studies can
  teach the Open Science movement","  This study analyzes rates and ways of data sharing regarding mitochondrial, Y
chromosomal and autosomal polymorphisms in a total of 162 papers on human
ancient DNA published between 1988 and 2013. For the most part, data are
available in such a way as to make their scrutiny and reuse possible. The
estimated sharing rate is not far from totality (97.6% +/- 2.1%) and
substantially higher than observed in other fields of genetic research
(Evolutionary, Medical and Forensic Genetics). A questionnaire-based survey
suggests that the authors awareness of the importance of openness and
transparency for scientific progress is a fundamental factor for the
achievement of such a high sharing rate. Most data were made available through
body text, but the use of primary databases increased with the application of
complete mitochondrial and next generation sequencing methods. Our study
highlights three important aspects. First, we provide evidence that researchers
motivations are as necessary as stakeholders policies and norms to achieve very
high sharing rates. Second, careful analyses of the ways in which data are made
available are an important first step to maximize data findability,
accessibility, useability and preservation. Third and finally, the case of
human ancient DNA studies demonstrates how Open Science can foster scientific
advancements, showing that openness and transparency can help build rigorous
and reliable scientific practices even in the presence of complex experimental
challenges.
","Paolo Anagnostou|Marco Capocasa|Nicola Milia|Emanuele Sanna|Daniela Luzi|Giovanni Destro Bisol","","http://arxiv.org/abs/1407.3682v2","http://arxiv.org/pdf/1407.3682v2","http://dx.doi.org/10.1371/journal.pone.0121409","26 pages, 7 figures (1 supplementary), 6 Tables (5 supplementary of
  which 2 are available only upon request)","","10.1371/journal.pone.0121409","q-bio.PE","q-bio.PE|cs.DL"
"83","1410.4422v2","2014-10-11 18:30:49","2017-06-30 20:09:22","Should We Train Scientific Generalists?","  I examine the topic of training scientific generalists. To focus the
discussion, I propose the creation of a new graduate program, analogous in
structure to existing MD/PhD programs, aimed at training a critical mass of
scientific researchers with substantial intellectual breadth. In addition to
completing the normal requirements for a PhD, students would undergo an
intense, several year training period designed to expose them to the core
vocabulary of multiple subjects at the graduate level. After providing some
historical and philosophical context for this proposal, I outline how such a
program could be implemented with little institutional overhead by existing
research universities. Finally, I discuss alternative possibilities for
training generalists by taking advantage of contemporary developments in online
learning and open science.
","Gopal Sarma","","http://arxiv.org/abs/1410.4422v2","http://arxiv.org/pdf/1410.4422v2","http://dx.doi.org/10.15200/winn.145264.45703","5 pages","The Winnower 2016 (01)","10.15200/winn.145264.45703","cs.CY","cs.CY|physics.ed-ph"
"84","1410.4839v2","2014-10-17 20:00:00","2015-01-01 23:29:52","The LIGO Open Science Center","  The LIGO Open Science Center (LOSC) fulfills LIGO's commitment to release,
archive, and serve LIGO data in a broadly accessible way to the scientific
community and to the public, and to provide the information and tools necessary
to understand and use the data. In August 2014, the LOSC published the full
dataset from Initial LIGO's ""S5"" run at design sensitivity, the first such
large-scale release and a valuable testbed to explore the use of LIGO data by
non-LIGO researchers and by the public, and to help teach gravitational-wave
data analysis to students across the world. In addition to serving the S5 data,
the LOSC web portal (losc.ligo.org) now offers documentation, data-location and
data-quality queries, tutorials and example code, and more. We review the
mission and plans of the LOSC, focusing on the S5 data release.
","Michele Vallisneri|Jonah Kanner|Roy Williams|Alan Weinstein|Branson Stephens","","http://arxiv.org/abs/1410.4839v2","http://arxiv.org/pdf/1410.4839v2","http://dx.doi.org/10.1088/1742-6596/610/1/012021","8 pages, 1 figure, proceedings of the 10th LISA Symposium, University
  of Florida, Gainesville, May 18-23, 2014; final published version; see
  losc.ligo.org for the S5 data release and more information about the LIGO
  Open Science Center","","10.1088/1742-6596/610/1/012021","gr-qc","gr-qc|astro-ph.HE|astro-ph.IM"
"85","1410.7326v3","2014-10-27 17:46:28","2015-11-03 21:21:41","Neuroevolution in Games: State of the Art and Open Challenges","  This paper surveys research on applying neuroevolution (NE) to games. In
neuroevolution, artificial neural networks are trained through evolutionary
algorithms, taking inspiration from the way biological brains evolved. We
analyse the application of NE in games along five different axes, which are the
role NE is chosen to play in a game, the different types of neural networks
used, the way these networks are evolved, how the fitness is determined and
what type of input the network receives. The article also highlights important
open research challenges in the field.
","Sebastian Risi|Julian Togelius","","http://arxiv.org/abs/1410.7326v3","http://arxiv.org/pdf/1410.7326v3","","- Added more references - Corrected typos - Added an overview table
  (Table 1)","","","cs.NE","cs.NE"
"86","1410.7882v1","2014-10-29 05:54:57","2014-10-29 05:54:57","Simulated Performance of Timescale Metrics for Aperiodic Light Curves","  Aperiodic variability is a characteristic feature of young stars, massive
stars, and active galactic nuclei. With the recent proliferation of time domain
surveys, it is increasingly essential to develop methods to quantify and
analyze aperiodic variability. We develop three timescale metrics that have
been little used in astronomy -- {\Delta}m-{\Delta}t plots, peak-finding, and
Gaussian process regression -- and present simulations comparing their
effectiveness across a range of aperiodic light curve shapes, characteristic
timescales, observing cadences, and signal to noise ratios. We find that
Gaussian process regression is easily confused by noise and by irregular
sampling, even when the model being fit reflects the process underlying the
light curve, but that {\Delta}m-{\Delta}t plots and peak-finding can coarsely
characterize timescales across a broad region of parameter space. We make
public the software we used for our simulations, both in the spirit of open
research and to allow others to carry out analogous simulations for their own
observing programs.
","Krzysztof Findeisen|Ann Marie Cody|Lynne Hillenbrand","","http://arxiv.org/abs/1410.7882v1","http://arxiv.org/pdf/1410.7882v1","http://dx.doi.org/10.1088/0004-637X/798/2/89","39 pages, 16 figures, 3 tables. To be published in The Astrophysical
  Journal. Simulation software is available online at http://ascl.net/1408.012","","10.1088/0004-637X/798/2/89","astro-ph.IM","astro-ph.IM|astro-ph.SR|physics.data-an"
"87","1411.2852v1","2014-11-11 15:29:28","2014-11-11 15:29:28","QoS in IEEE 802.11-based Wireless Networks: A Contemporary Survey","  Apart from mobile cellular networks, IEEE 802.11-based wireless local area
networks (WLANs) represent the most widely deployed wireless networking
technology. With the migration of critical applications onto data networks, and
the emergence of multimedia applications such as digital audio/video and
multimedia games, the success of IEEE 802.11 depends critically on its ability
to provide quality of service (QoS). A lot of research has focused on equipping
IEEE 802.11 WLANs with features to support QoS. In this survey, we provide an
overview of these techniques. We discuss the QoS features incorporated by the
IEEE 802.11 standard at both physical (PHY) and media access control (MAC)
layers, as well as other higher-layer proposals. We also focus on how the new
architectural developments of software-defined networking (SDN) and cloud
networking can be used to facilitate QoS provisioning in IEEE 802.11-based
networks. We conclude this paper by identifying some open research issues for
future consideration.
","Aqsa Malik|Junaid Qadir|Basharat Ahmad|Kok-Lim Alvin Yau|Ubaid Ullah","","http://arxiv.org/abs/1411.2852v1","http://arxiv.org/pdf/1411.2852v1","http://dx.doi.org/10.1016/j.jnca.2015.04.016","","","10.1016/j.jnca.2015.04.016","cs.NI","cs.NI"
"88","1411.5323v1","2014-11-19 19:18:27","2014-11-19 19:18:27","Genetic Algorithms in Wireless Networking: Techniques, Applications, and
  Issues","  In recent times, wireless access technology is becoming increasingly
commonplace due to the ease of operation and installation of untethered
wireless media. The design of wireless networking is challenging due to the
highly dynamic environmental condition that makes parameter optimization a
complex task. Due to the dynamic, and often unknown, operating conditions,
modern wireless networking standards increasingly rely on machine learning and
artificial intelligence algorithms. Genetic algorithms (GAs) provide a
well-established framework for implementing artificial intelligence tasks such
as classification, learning, and optimization. GAs are well-known for their
remarkable generality and versatility, and have been applied in a wide variety
of settings in wireless networks. In this paper, we provide a comprehensive
survey of the applications of GAs in wireless networks. We provide both an
exposition of common GA models and configuration and provide a broad ranging
survey of GA techniques in wireless networks. We also point out open research
issues and define potential future work. While various surveys on GAs exist in
literature, our paper is the first paper, to the best of our knowledge, which
focuses on their application in wireless networks.
","Usama Mehboob|Junaid Qadir|Salman Ali|Athanasios Vasilakos","","http://arxiv.org/abs/1411.5323v1","http://arxiv.org/pdf/1411.5323v1","","","","","cs.NI","cs.NI"
"89","1412.2013v1","2014-12-05 14:44:06","2014-12-05 14:44:06","Towards Defeating the Crossfire Attack using SDN","  In this work, we propose online traffic engineering as a novel approach to
detect and mitigate an emerging class of stealthy Denial of Service (DoS)
link-flooding attacks. Our approach exploits the Software Defined Networking
(SDN) paradigm, which renders the management of network traffic more flexible
through centralised flow-level control and monitoring. We implement a full
prototype of our solution on an emulated SDN environment using OpenFlow to
interface with the network devices. We further discuss useful insights gained
from our preliminary experiments as well as a number of open research questions
which constitute work in progress.
","Dimitrios Gkounis|Vasileios Kotronis|Xenofontas Dimitropoulos","Foundation for Research and Technology - Hellas|ETH Zurich, Switzerland|Foundation for Research and Technology - Hellas","http://arxiv.org/abs/1412.2013v1","http://arxiv.org/pdf/1412.2013v1","","","","","cs.NI","cs.NI"
"90","1412.2158v1","2014-12-05 21:48:12","2014-12-05 21:48:12","A Two-layer Architecture of Mobile Sinks and Static Sensors","  We propose a two-layer mobile sink and static sensor network (MSSSN)
architecture for large scale wireless sensor networks. The top layer is a
mobile ad hoc network of resource-rich sink nodes while the bottom layer is a
network of static resource-constrained sensor nodes. The MSSSN architecture can
be implemented at a lower cost with the currently available IEEE 802.11 devices
that only use a single halfduplex transceiver. Each sink node is assigned a
particular region to monitor and collect data. A sink node moves to the
vicinity of the sensor nodes (within a few hops) to collect data. The collected
data is exchanged with peer mobile sinks. Thus, the MSSSN architecture provides
scalability, extends sensor lifetime by letting them operate with limited
transmission range and provides connectivity between isolated regions of sensor
nodes. In order to provide fault tolerance, more than one mobile sink could be
collecting data from a given region or a mobile sink could collect data from
more than one region. In the later half of the paper, we discuss several open
research issues that need to be addressed while implementing the MSSSN
architecture.
","Natarajan Meghanathan|Gordon Skelton","","http://arxiv.org/abs/1412.2158v1","http://arxiv.org/pdf/1412.2158v1","","11 pages, 1 figure","Proceedings of the 15th International Conference on Advanced
  Computing and Communication, pp. 249-254, Guwahathi, India, December 2007","","cs.NI","cs.NI"
"91","1412.3695v1","2014-12-10 16:08:07","2014-12-10 16:08:07","Evaluating arbitration and conflict resolution mechanisms in the Spanish
  Wikipedia","  In open collaborative projects like Wikipedia, interactions among users can
produce tension and misunderstandings. Complex disputes require more
sophisticated mechanisms of conflict resolution. In this paper, we examine the
case of the Spanish Wikipedia and its Arbitration Committee, known as CRC, over
its two years of activity. We postulate that the high percentage of rejections
of cases presented by non-administrators, the lack of diversity inside the
committee (composed only by administrators), and the high number of cases
involving administrators played a central role in its eventual downfall. We
conclude that mechanisms that fail to acknowledge the ecosystem they are part
of cannot succceed. Therefore, further research is needed to determine if
granting more decision-making power to non-administrators may lead to more
effective conflict resolution mechanisms.
","Maria Sefidari|Felipe Ortega","","http://arxiv.org/abs/1412.3695v1","http://arxiv.org/pdf/1412.3695v1","","4 pages, 4 tables","","","cs.CY","cs.CY|H.5.3"
"92","1412.3637v1","2014-12-11 12:56:30","2014-12-11 12:56:30","Handover Management in Highly Dense Femtocellular Networks","  For dense femtocells, intelligent integrated femtocell/macrocell network
architecture, a neighbor cell list with a minimum number of femtocells,
effective call admission control (CAC), and handover processes with proper
signaling are the open research issues. An appropriate traffic model for the
integrated femtocell/macrocell network is also not yet developed. In this
paper, we present the major issue of mobility management for the integrated
femtocell/macrocell network. We propose a novel algorithm to create a neighbor
cell list with a minimum, but appropriate, number of cells for handover. We
also propose detailed handover procedures and a novel traffic model for the
integrated femtocell/macrocell network. The proposed CAC effectively handles
various calls. The numerical and simulation results show the importance of the
integrated femtocell/macrocell network and the performance improvement of the
proposed schemes. Our proposed schemes for dense femtocells will be very
effective for those in research and industry to implement.
","Mostafa Zaman Chowdhury|Yeong Min Jang","","http://arxiv.org/abs/1412.3637v1","http://arxiv.org/pdf/1412.3637v1","http://dx.doi.org/10.1186/1687-1499-2013-6","","EURASIP Journal on Wireless Communications and Networking, pp.
  1-21, Jan. 2013","10.1186/1687-1499-2013-6","cs.NI","cs.NI"
"93","1501.01367v1","2015-01-07 04:29:17","2015-01-07 04:29:17","Device Fingerprinting in Wireless Networks: Challenges and Opportunities","  Node forgery or impersonation, in which legitimate cryptographic credentials
are captured by an adversary, constitutes one major security threat facing
wireless networks. The fact that mobile devices are prone to be compromised and
reverse engineered significantly increases the risk of such attacks in which
adversaries can obtain secret keys on trusted nodes and impersonate the
legitimate node. One promising approach toward thwarting these attacks is
through the extraction of unique fingerprints that can provide a reliable and
robust means for device identification. These fingerprints can be extracted
from transmitted signal by analyzing information across the protocol stack. In
this paper, the first unified and comprehensive tutorial in the area of
wireless device fingerprinting for security applications is presented. In
particular, we aim to provide a detailed treatment on developing novel wireless
security solutions using device fingerprinting techniques. The objectives are
three-fold: (i) to introduce a comprehensive taxonomy of wireless features that
can be used in fingerprinting, (ii) to provide a systematic review on
fingerprint algorithms including both white-list based and unsupervised
learning approaches, and (iii) to identify key open research problems in the
area of device fingerprinting and feature extraction, as applied to wireless
security.
","Qiang Xu|Rong Zheng|Walid Saad|Zhu Han","","http://arxiv.org/abs/1501.01367v1","http://arxiv.org/pdf/1501.01367v1","","","","","cs.NI","cs.NI"
"94","1502.03561v2","2015-02-12 08:27:03","2015-05-13 16:29:55","Concepts and evolution of research in the field of wireless sensor
  networks","  The field of Wireless Sensor Networks (WSNs) is experiencing a resurgence of
interest and a continuous evolution in the scientific and industrial community.
The use of this particular type of ad hoc network is becoming increasingly
important in many contexts, regardless of geographical position and so,
according to a set of possible application. WSNs offer interesting low cost and
easily deployable solutions to perform a remote real time monitoring, target
tracking and recognition of physical phenomenon. The uses of these sensors
organized into a network continue to reveal a set of research questions
according to particularities target applications. Despite difficulties
introduced by sensor resources constraints, research contributions in this
field are growing day by day. In this paper, we present a comprehensive review
of most recent literature of WSNs and outline open research issues in this
field.
","Ado Adamou Abba Ari|Abdelhak Gueroui|Nabila Labraoui|Blaise Omer Yenke","PRiSM, University of Versailles St-Quentin-en-Yvelines France|PRiSM, University of Versailles St-Quentin-en-Yvelines France|STIC University of Tlemcen Algeria|LASE University of Ngaoundere Cameroon","http://arxiv.org/abs/1502.03561v2","http://arxiv.org/pdf/1502.03561v2","http://dx.doi.org/10.5121/ijcnc.2015.7106","","International Journal of Computer Networks & Communications. 7.1
  (2015) 81-98","10.5121/ijcnc.2015.7106","cs.NI","cs.NI"
"95","1502.04727v1","2015-02-16 21:19:15","2015-02-16 21:19:15","Wireless Power Transfer: Survey and Roadmap","  Wireless power transfer (WPT) technologies have been widely used in many
areas, e.g., the charging of electric toothbrush, mobile phones, and electric
vehicles. This paper introduces fundamental principles of three WPT
technologies, i.e., inductive coupling-based WPT, magnetic resonant
coupling-based WPT, and electromagnetic radiation-based WPT, together with
discussions of their strengths and weaknesses. Main research themes are then
presented, i.e., improving the transmission efficiency and distance, and
designing multiple transmitters/receivers. The state-of-the-art techniques are
reviewed and categorised. Several WPT applications are described. Open research
challenges are then presented with a brief discussion of potential roadmap.
","Xiaolin Mou|Hongjian Sun","","http://arxiv.org/abs/1502.04727v1","http://arxiv.org/pdf/1502.04727v1","http://dx.doi.org/10.1109/VTCSpring.2015.7146165","To appear in Proceedings of IEEE VTC 2015 Spring, First International
  Workshop on Integrating Communications, Control, Computing Technologies for
  Smart Grid (ICT4SG)","2015 IEEE 81st Vehicular Technology Conference: VTC2015-Spring.
  Glasgow, UK, IEEE, Glasgow","10.1109/VTCSpring.2015.7146165","cs.IT","cs.IT|math.IT"
"96","1502.06274v1","2015-02-22 21:36:01","2015-02-22 21:36:01","Persistent, Global Identity for Scientists via ORCID","  Scientists have an inherent interest in claiming their contributions to the
scholarly record, but the fragmented state of identity management across the
landscape of astronomy, physics, and other fields makes highlighting the
contributions of any single individual a formidable and often frustratingly
complex task. The problem is exacerbated by the expanding variety of academic
research products and the growing footprints of large collaborations and
interdisciplinary teams. In this essay, we outline the benefits of a unique
scholarly identifier with persistent value on a global scale and we review
astronomy and physics engagement with the Open Researcher and Contributor iD
(ORCID) service as a solution.
","August E. Evrard|Christopher Erdmann|Jane Holmquist|James Damon|Dianne Dietrich","","http://arxiv.org/abs/1502.06274v1","http://arxiv.org/pdf/1502.06274v1","","13 pages, 1 figure. The authors of this paper include members of the
  ORCID Ambassadors program","","","cs.DL","cs.DL|astro-ph.IM|physics.soc-ph"
"97","1502.07228v1","2015-02-25 16:25:45","2015-02-25 16:25:45","A Survey of Millimeter Wave (mmWave) Communications for 5G:
  Opportunities and Challenges","  With the explosive growth of mobile data demand, the fifth generation (5G)
mobile network would exploit the enormous amount of spectrum in the millimeter
wave (mmWave) bands to greatly increase communication capacity. There are
fundamental differences between mmWave communications and existing other
communication systems, in terms of high propagation loss, directivity, and
sensitivity to blockage. These characteristics of mmWave communications pose
several challenges to fully exploit the potential of mmWave communications,
including integrated circuits and system design, interference management,
spatial reuse, anti-blockage, and dynamics control. To address these
challenges, we carry out a survey of existing solutions and standards, and
propose design guidelines in architectures and protocols for mmWave
communications. We also discuss the potential applications of mmWave
communications in the 5G network, including the small cell access, the cellular
access, and the wireless backhaul. Finally, we discuss relevant open research
issues including the new physical layer technology, software-defined network
architecture, measurements of network state information, efficient control
mechanisms, and heterogeneous networking, which should be further investigated
to facilitate the deployment of mmWave communication systems in the future 5G
networks.
","Yong Niu|Yong Li|Depeng Jin|Li Su|Athanasios V. Vasilakos","","http://arxiv.org/abs/1502.07228v1","http://arxiv.org/pdf/1502.07228v1","","17 pages, 8 figures, 7 tables, Journal paper","","","cs.NI","cs.NI"
"98","1502.07687v3","2015-02-26 19:25:26","2015-04-27 16:14:11","Incentive Mechanisms for Participatory Sensing: Survey and Research
  Challenges","  Participatory sensing is a powerful paradigm which takes advantage of
smartphones to collect and analyze data beyond the scale of what was previously
possible. Given that participatory sensing systems rely completely on the
users' willingness to submit up-to-date and accurate information, it is
paramount to effectively incentivize users' active and reliable participation.
In this paper, we survey existing literature on incentive mechanisms for
participatory sensing systems. In particular, we present a taxonomy of existing
incentive mechanisms for participatory sensing systems, which are subsequently
discussed in depth by comparing and contrasting different approaches. Finally,
we discuss an agenda of open research challenges in incentivizing users in
participatory sensing.
","Francesco Restuccia|Sajal K. Das|Jamie Payton","","http://arxiv.org/abs/1502.07687v3","http://arxiv.org/pdf/1502.07687v3","","Updated version, 4/25/2015","","","cs.GT","cs.GT"
"99","1503.00102v2","2015-02-28 09:06:57","2018-12-30 13:58:59","CARP: Context-Aware Reliability Prediction of Black-Box Web Services","  Reliability prediction is an important task in software reliability
engineering, which has been widely studied in the last decades. However,
modelling and predicting user-perceived reliability of black-box services
remain an open research problem. Software services, such as Web services and
Web APIs, generally provide black-box functionalities to users through the
Internet, thus leading to a lack of their internal information for reliability
analysis. Furthermore, the user-perceived service reliability depends not only
on the service itself, but also heavily on the invocation context (e.g.,
service workloads, network conditions), whereby traditional reliability models
become ineffective and inappropriate. To address these new challenges posed by
blackbox services, in this paper, we propose CARP, a new contextaware
reliability prediction approach, which leverages historical usage data from
users to construct context-aware reliability models and further provides online
reliability prediction results to users. Through context-aware reliability
modelling, CARP is able to alleviate the data sparsity problem that heavily
limits the prediction accuracy of other existing approaches. The preliminary
evaluation results show that CARP can make a significant improvement in
reliability prediction accuracy, e.g., about 41% in MAE and 38% in RMSE when
only 5% of the data are available.
","Jieming Zhu|Pinjia He|Qi Xie|Zibin Zheng|Michael R. Lyu","","http://arxiv.org/abs/1503.00102v2","http://arxiv.org/pdf/1503.00102v2","","This paper has been published at International Conference on Web
  Services (ICWS'17)","","","cs.SE","cs.SE"
"100","1503.03082v2","2015-03-10 20:09:13","2015-09-15 19:40:46","Learning the Structure for Structured Sparsity","  Structured sparsity has recently emerged in statistics, machine learning and
signal processing as a promising paradigm for learning in high-dimensional
settings. All existing methods for learning under the assumption of structured
sparsity rely on prior knowledge on how to weight (or how to penalize)
individual subsets of variables during the subset selection process, which is
not available in general. Inferring group weights from data is a key open
research problem in structured sparsity.In this paper, we propose a Bayesian
approach to the problem of group weight learning. We model the group weights as
hyperparameters of heavy-tailed priors on groups of variables and derive an
approximate inference scheme to infer these hyperparameters. We empirically
show that we are able to recover the model hyperparameters when the data are
generated from the model, and we demonstrate the utility of learning weights in
synthetic and real denoising problems.
","Nino Shervashidze|Francis Bach","SIERRA, LIENS|SIERRA, LIENS","http://arxiv.org/abs/1503.03082v2","http://arxiv.org/pdf/1503.03082v2","http://dx.doi.org/10.1109/TSP.2015.2446432","","IEEE Transactions on Signal Processing, Institute of Electrical
  and Electronics Engineers (IEEE), 2015, 63 (18), pp.4894 - 4902.
  \&lt;10.1109/TSP.2015.2446432\&gt;","10.1109/TSP.2015.2446432","stat.ML","stat.ML"
"101","1503.03954v1","2015-03-13 05:07:39","2015-03-13 05:07:39","Full-Duplex Cognitive Radio: A New Design Paradigm for Enhancing
  Spectrum Usage","  With the rapid growth of demand for ever-increasing data rate, spectrum
resources have become more and more scarce. As a promising technique to
increase the efficiency of the spectrum utilization, cognitive radio (CR)
technique has the great potential to meet such a requirement by allowing
un-licensed users to coexist in licensed bands. In conventional CR systems, the
spectrum sensing is performed at the beginning of each time slot before the
data transmission. This unfortunately results in two major problems: 1)
transmission time reduction due to sensing, and 2) sensing accuracy impairment
due to data transmission. To tackle these problems, in this paper we present a
new design paradigm for future CR by exploring the full-duplex (FD) techniques
to achieve the simultaneous spectrum sensing and data transmission. With FD
radios equipped at the secondary users (SUs), SUs can simultaneously sense and
access the vacant spectrum, and thus, significantly improve sensing
performances and meanwhile increase data transmission efficiency. The aim of
this article is to transform the promising conceptual framework into the
practical wireless network design by addressing a diverse set of challenges
such as protocol design and theoretical analysis. Several application scenarios
with FD enabled CR are elaborated, and key open research directions and novel
algorithms in these systems are discussed.
","Yun Liao|Lingyang Song|Zhu Han|Yonghui Li","","http://arxiv.org/abs/1503.03954v1","http://arxiv.org/pdf/1503.03954v1","","","","","cs.NI","cs.NI"
"102","1503.06934v1","2015-03-24 07:35:16","2015-03-24 07:35:16","Measuring Software Quality in Use: State-of-the-Art and Research
  Challenges","  Software quality in use comprises quality from the user's perspective. It has
gained its importance in e-government applications, mobile-based applications,
embedded systems, and even business process development. User's decisions on
software acquisitions are often ad hoc or based on preference due to difficulty
in quantitatively measuring software quality in use. But, why is quality-in-use
measurement difficult? Although there are many software quality models, to the
authors' knowledge no works survey the challenges related to software
quality-in-use measurement. This article has two main contributions: 1) it
identifies and explains major issues and challenges in measuring software
quality in use in the context of the ISO SQuaRE series and related software
quality models and highlights open research areas; and 2) it sheds light on a
research direction that can be used to predict software quality in use. In
short, the quality-in-use measurement issues are related to the complexity of
the current standard models and the limitations and incompleteness of the
customized software quality models. A sentiment analysis of software reviews is
proposed to deal with these issues.
","Issa Atoum|Chih How Bong","","http://arxiv.org/abs/1503.06934v1","http://arxiv.org/pdf/1503.06934v1","","4 Figures","ASQ.Software Quality Professional, 17(2), 2015","","cs.SE","cs.SE|cs.CL"
"103","1504.07154v1","2015-04-27 16:45:17","2015-04-27 16:45:17","Physical Layer Security for Massive MIMO: An Overview on Passive
  Eavesdropping and Active Attacks","  This article discusses opportunities and challenges of physical layer
security integration in massive multiple-input multiple-output (MaMIMO)
systems. Specifically, we first show that MaMIMO itself is robust against
passive eavesdropping attacks. We then review a pilot contamination scheme
which actively attacks the channel estimation process. This pilot contamination
attack is not only dramatically reducing the achievable secrecy capacity but is
also difficult to detect. We proceed by reviewing some methods from literature
that detect active attacks on MaMIMO. The last part of the paper surveys the
open research problems that we believe are the most important to address in the
future and give a few promising directions of research to solve them.
","Dzevdan Kapetanovic|Gan Zheng|Fredrik Rusek","","http://arxiv.org/abs/1504.07154v1","http://arxiv.org/pdf/1504.07154v1","http://dx.doi.org/10.1109/MCOM.2015.7120012","5 figures, to appear in IEEE Communications Magazine 2015, special
  issue on Wireless Physical Layer Security","","10.1109/MCOM.2015.7120012","cs.IT","cs.IT|math.IT"
"104","1505.00589v1","2015-05-04 10:50:26","2015-05-04 10:50:26","Danger is My Middle Name: Experimenting with SSL Vulnerabilities in
  Android Apps","  This paper presents a measurement study of information leakage and SSL
vulnerabilities in popular Android apps. We perform static and dynamic analysis
on 100 apps, downloaded at least 10M times, that request full network access.
Our experiments show that, although prior work has drawn a lot of attention to
SSL implementations on mobile platforms, several popular apps (32/100) accept
all certificates and all hostnames, and four actually transmit sensitive data
unencrypted. We set up an experimental testbed simulating man-in-the-middle
attacks and find that many apps (up to 91% when the adversary has a certificate
installed on the victim's device) are vulnerable, allowing the attacker to
access sensitive information, including credentials, files, personal details,
and credit card numbers. Finally, we provide a few recommendations to app
developers and highlight several open research problems.
","Lucky Onwuzurike|Emiliano De Cristofaro","","http://arxiv.org/abs/1505.00589v1","http://arxiv.org/pdf/1505.00589v1","","A preliminary version of this paper appears in the Proceedings of ACM
  WiSec 2015. This is the full version","","","cs.CR","cs.CR|cs.SE"
"105","1505.02911v1","2015-05-12 08:54:14","2015-05-12 08:54:14","Resource Allocation in Full-Duplex Communications for Future Wireless
  Networks","  The recent significant progress in realizing full-duplex~(FD) systems has
opened up a promising avenue for improving quality of service (QoS) and quality
of experience (QoE) in future wireless networks. There is an urgent need to
address the diverse set of challenges regarding different aspects of FD network
design, theory, and development. In addition to the self-interference
cancelation signal processing algorithms, network protocols such as resource
management are also essential in the practical design and implementation of FD
wireless networks. This article aims to present the latest development and
future directions of resource allocation in different full duplex systems by
exploring the network resources in different domains, including power, space,
frequency, and device dimensions. Four representative application scenarios are
considered: FD MIMO networks, FD cooperative networks, FD OFDMA cellular
networks, and FD heterogeneous networks. Resource management problems and novel
algorithms in these systems are presented, and key open research directions are
discussed.
","Lingyang Song|Yonghui Li|Zhu Han","","http://arxiv.org/abs/1505.02911v1","http://arxiv.org/pdf/1505.02911v1","http://dx.doi.org/10.1109/MWC.2015.7224732","20 pages, 7 figures, accepated in IEEE Wireless Communications, 2015","","10.1109/MWC.2015.7224732","cs.IT","cs.IT|math.IT"
"106","1505.04901v3","2015-05-19 08:09:13","2016-01-11 11:15:02","Algorithm Engineering in Robust Optimization","  Robust optimization is a young and emerging field of research having received
a considerable increase of interest over the last decade. In this paper, we
argue that the the algorithm engineering methodology fits very well to the
field of robust optimization and yields a rewarding new perspective on both the
current state of research and open research directions.
  To this end we go through the algorithm engineering cycle of design and
analysis of concepts, development and implementation of algorithms, and
theoretical and experimental evaluation. We show that many ideas of algorithm
engineering have already been applied in publications on robust optimization.
Most work on robust optimization is devoted to analysis of the concepts and the
development of algorithms, some papers deal with the evaluation of a particular
concept in case studies, and work on comparison of concepts just starts. What
is still a drawback in many papers on robustness is the missing link to include
the results of the experiments again in the design.
","Marc Goerigk|Anita Schöbel","","http://arxiv.org/abs/1505.04901v3","http://arxiv.org/pdf/1505.04901v3","","","","","math.OC","math.OC|cs.DS|G.1.6; G.4"
"107","1506.00128v1","2015-05-30 15:27:53","2015-05-30 15:27:53","A Web Environment for Geometry","  The Web Geometry Laboratory, (WGL), is a blended-learning, collaborative and
adaptive, Web environment for geometry. It integrates a well known dynamic
geometry system. In a collaborative session, exchange of geometrical and
textual information between the user engaged in the session is possible. In a
normal work session (stand-alone mode), all the geometric steps done by the
students are recorded, alongside the navigation information, allowing, in a
latter stage, their teachers to ""play back"" the students sessions, using that
info to assert the students level and adjust the teaching strategies to each
individual student. Teachers can register and begin using one of the public
servers, defining students, preparing materials to be released to the students,
open collaborative sessions, etc. Using an action research methodology the WGL
system is being developed, validated through case-studies, and further
improved, in a cycle where the implementation steps are intertwined with case
studies.
","Pedro Quaresma|Vanda Santos|Milena Marić","","http://arxiv.org/abs/1506.00128v1","http://arxiv.org/pdf/1506.00128v1","","CICM 2015, Conference on Intelligent Computer Mathematics
  (Work-in-Progress track), July 13-17, 2015, Washington DC, USA","","","cs.CY","cs.CY|97G40|K.3.1, K.3.2, I.3.5"
"108","1506.01911v3","2015-06-05 13:43:01","2016-02-10 16:50:29","Beyond Temporal Pooling: Recurrence and Temporal Convolutions for
  Gesture Recognition in Video","  Recent studies have demonstrated the power of recurrent neural networks for
machine translation, image captioning and speech recognition. For the task of
capturing temporal structure in video, however, there still remain numerous
open research questions. Current research suggests using a simple temporal
feature pooling strategy to take into account the temporal aspect of video. We
demonstrate that this method is not sufficient for gesture recognition, where
temporal information is more discriminative compared to general video
classification tasks. We explore deep architectures for gesture recognition in
video and propose a new end-to-end trainable neural network architecture
incorporating temporal convolutions and bidirectional recurrence. Our main
contributions are twofold; first, we show that recurrence is crucial for this
task; second, we show that adding temporal convolutions leads to significant
improvements. We evaluate the different approaches on the Montalbano gesture
recognition dataset, where we achieve state-of-the-art results.
","Lionel Pigou|Aäron van den Oord|Sander Dieleman|Mieke Van Herreweghe|Joni Dambre","","http://arxiv.org/abs/1506.01911v3","http://arxiv.org/pdf/1506.01911v3","","","","","cs.CV","cs.CV|cs.AI|cs.LG|cs.NE|stat.ML"
"109","1506.02211v1","2015-06-07 02:29:45","2015-06-07 02:29:45","Boosting Optical Character Recognition: A Super-Resolution Approach","  Text image super-resolution is a challenging yet open research problem in the
computer vision community. In particular, low-resolution images hamper the
performance of typical optical character recognition (OCR) systems. In this
article, we summarize our entry to the ICDAR2015 Competition on Text Image
Super-Resolution. Experiments are based on the provided ICDAR2015 TextSR
dataset and the released Tesseract-OCR 3.02 system. We report that our winning
entry of text image super-resolution framework has largely improved the OCR
performance with low-resolution images used as input, reaching an OCR accuracy
score of 77.19%, which is comparable with that of using the original
high-resolution images 78.80%.
","Chao Dong|Ximei Zhu|Yubin Deng|Chen Change Loy|Yu Qiao","","http://arxiv.org/abs/1506.02211v1","http://arxiv.org/pdf/1506.02211v1","","5 pages, 8 figures","","","cs.CV","cs.CV|I.4.3; I.4.9"
"110","1506.05632v1","2015-06-18 11:31:55","2015-06-18 11:31:55","An Open Science Platform for the Next Generation of Data","  Imagine an online work environment where researchers have direct and
immediate access to myriad data sources and tools and data management
resources, useful throughout the research lifecycle. This is our vision for the
next generation of the Dataverse Network: an Open Science Platform (OSP). For
the first time, researchers would be able to seamlessly access and create
primary and derived data from a variety of sources: prior research results,
public data sets, harvested online data, physical instruments, private data
collections, and even data from other standalone repositories. Researchers
could recruit research participants and conduct research directly on the OSP,
if desired, using readily available tools. Researchers could create private or
shared workspaces to house data, access tools, and computation and could
publish data directly on the platform or publish elsewhere with persistent,
data citations on the OSP. This manuscript describes the details of an Open
Science Platform and its construction. Having an Open Science Platform will
especially impact the rate of new scientific discoveries and make scientific
findings more credible and accountable.
","Latanya Sweeney|Merce Crosas","","http://arxiv.org/abs/1506.05632v1","http://arxiv.org/pdf/1506.05632v1","","32 pages, 8 figures","","","cs.CY","cs.CY|cs.DL|H.3.1; H.3.2; H.3.3; H.3.5; H.3.6; H.3.7; H.2.7; H.2.8"
"111","1506.09118v1","2015-06-30 15:31:42","2015-06-30 15:31:42","City Data Fusion: Sensor Data Fusion in the Internet of Things","  Internet of Things (IoT) has gained substantial attention recently and play a
significant role in smart city application deployments. A number of such smart
city applications depend on sensor fusion capabilities in the cloud from
diverse data sources. We introduce the concept of IoT and present in detail ten
different parameters that govern our sensor data fusion evaluation framework.
We then evaluate the current state-of-the art in sensor data fusion against our
sensor data fusion framework. Our main goal is to examine and survey different
sensor data fusion research efforts based on our evaluation framework. The
major open research issues related to sensor data fusion are also presented.
","Meisong Wang|Charith Perera|Prem Prakash Jayaraman|Miranda Zhang|Peter Strazdins|Rajiv Ranjan","","http://arxiv.org/abs/1506.09118v1","http://arxiv.org/pdf/1506.09118v1","","Accepted to be published in International Journal of Distributed
  Systems and Technologies (IJDST), 2015","","","cs.CY","cs.CY|cs.NI"
"112","1507.01295v1","2015-07-05 23:19:19","2015-07-05 23:19:19","The Remixing Dilemma: The Trade-off Between Generativity and Originality","  In this paper we argue that there is a trade-off between generativity and
originality in online communities that support open collaboration. We build on
foundational theoretical work in peer production to formulate and test a series
of hypotheses suggesting that the generativity of creative works is associated
with moderate complexity, prominent authors, and cumulativeness. We also
formulate and test three hypotheses that these qualities are associated with
decreased originality in resulting derivatives. Our analysis uses a rich data
set from the Scratch Online Community --a large web-site where young people
openly share and remix animations and video games. We discuss the implications
of this trade-off for the design of peer production systems that support
amateur creativity.
","Benjamin Mako Hill|Andrés Monroy-Hernández","","http://arxiv.org/abs/1507.01295v1","http://arxiv.org/pdf/1507.01295v1","http://dx.doi.org/10.1177/0002764212469359","American Behavioral Scientist (2012)","","10.1177/0002764212469359","cs.CY","cs.CY|cs.HC|cs.SI"
"113","1507.07909v4","2015-07-28 19:31:44","2017-10-16 12:56:24","Offline Handwritten Signature Verification - Literature Review","  The area of Handwritten Signature Verification has been broadly researched in
the last decades, but remains an open research problem. The objective of
signature verification systems is to discriminate if a given signature is
genuine (produced by the claimed individual), or a forgery (produced by an
impostor). This has demonstrated to be a challenging task, in particular in the
offline (static) scenario, that uses images of scanned signatures, where the
dynamic information about the signing process is not available. Many
advancements have been proposed in the literature in the last 5-10 years, most
notably the application of Deep Learning methods to learn feature
representations from signature images. In this paper, we present how the
problem has been handled in the past few decades, analyze the recent
advancements in the field, and the potential directions for future research.
","Luiz G. Hafemann|Robert Sabourin|Luiz S. Oliveira","","http://arxiv.org/abs/1507.07909v4","http://arxiv.org/pdf/1507.07909v4","http://dx.doi.org/10.1109/IPTA.2017.8310112","Accepted to the International Conference on Image Processing Theory,
  Tools and Applications (IPTA 2017)","","10.1109/IPTA.2017.8310112","cs.CV","cs.CV|stat.ML|I.5.4"
"114","1508.02766v6","2015-08-11 22:39:32","2016-09-07 08:11:19","FFT-Based Fast Computation of Multivariate Kernel Estimators with
  Unconstrained Bandwidth Matrices","  The problem of fast computation of multivariate kernel density estimation
(KDE) is still an open research problem. In our view, the existing solutions do
not resolve this matter in a satisfactory way. One of the most elegant and
efficient approach utilizes the fast Fourier transform. Unfortunately, the
existing FFT-based solution suffers from a serious limitation, as it can
accurately operate only with the constrained (i.e., diagonal) multivariate
bandwidth matrices. In this paper we describe the problem and give a
satisfactory solution. The proposed solution may be successfully used also in
other research problems, for example for the fast computation of the optimal
bandwidth for KDE.
","Artur Gramacki|Jarosław Gramacki","","http://arxiv.org/abs/1508.02766v6","http://arxiv.org/pdf/1508.02766v6","","10 pages, 1 figure, R source codes","","","stat.CO","stat.CO"
"115","1508.04180v3","2015-08-17 23:53:51","2016-03-05 13:34:27","A Comprehensive Perspective on Pilot-Job Systems","  Pilot-Job systems play an important role in supporting distributed scientific
computing. They are used to consume more than 700 million CPU hours a year by
the Open Science Grid communities, and by processing up to 1 million jobs a day
for the ATLAS experiment on the Worldwide LHC Computing Grid. With the
increasing importance of task-level parallelism in high-performance computing,
Pilot-Job systems are also witnessing an adoption beyond traditional domains.
Notwithstanding the growing impact on scientific research, there is no
agreement upon a definition of Pilot-Job system and no clear understanding of
the underlying abstraction and paradigm. Pilot-Job implementations have
proliferated with no shared best practices or open interfaces and little
interoperability. Ultimately, this is hindering the realization of the full
impact of Pilot-Jobs by limiting their robustness, portability, and
maintainability. This paper offers a comprehensive analysis of Pilot-Job
systems critically assessing their motivations, evolution, properties, and
implementation. The three main contributions of this paper are: (i) an analysis
of the motivations and evolution of Pilot-Job systems; (ii) an outline of the
Pilot abstraction, its distinguishing logical components and functionalities,
its terminology, and its architecture pattern; and (iii) the description of
core and auxiliary properties of Pilot-Jobs systems and the analysis of seven
exemplar Pilot-Job implementations. Together, these contributions illustrate
the Pilot paradigm, its generality, and how it helps to address some challenges
in distributed scientific computing.
","Matteo Turilli|Mark Santcroos|Shantenu Jha","","http://arxiv.org/abs/1508.04180v3","http://arxiv.org/pdf/1508.04180v3","","","","","cs.DC","cs.DC|cs.SE|68Nxx"
"116","1508.04752v1","2015-08-18 12:39:05","2015-08-18 12:39:05","Performance-oriented DevOps: A Research Agenda","  DevOps is a trend towards a tighter integration between development (Dev) and
operations (Ops) teams. The need for such an integration is driven by the
requirement to continuously adapt enterprise applications (EAs) to changes in
the business environment. As of today, DevOps concepts have been primarily
introduced to ensure a constant flow of features and bug fixes into new
releases from a functional perspective. In order to integrate a non-functional
perspective into these DevOps concepts this report focuses on tools,
activities, and processes to ensure one of the most important quality
attributes of a software system, namely performance.
  Performance describes system properties concerning its timeliness and use of
resources. Common metrics are response time, throughput, and resource
utilization. Performance goals for EAs are typically defined by setting upper
and/or lower bounds for these metrics and specific business transactions. In
order to ensure that such performance goals can be met, several activities are
required during development and operation of these systems as well as during
the transition from Dev to Ops. Activities during development are typically
summarized by the term Software Performance Engineering (SPE), whereas
activities during operations are called Application Performance Management
(APM). SPE and APM were historically tackled independently from each other, but
the newly emerging DevOps concepts require and enable a tighter integration
between both activity streams. This report presents existing solutions to
support this integration as well as open research challenges in this area.
","Andreas Brunnert|Andre van Hoorn|Felix Willnecker|Alexandru Danciu|Wilhelm Hasselbring|Christoph Heger|Nikolas Herbst|Pooyan Jamshidi|Reiner Jung|Joakim von Kistowski|Anne Koziolek|Johannes Kroß|Simon Spinner|Christian Vögele|Jürgen Walter|Alexander Wert","","http://arxiv.org/abs/1508.04752v1","http://arxiv.org/pdf/1508.04752v1","","","","","cs.SE","cs.SE|cs.PF"
"117","1508.04635v2","2015-08-19 13:18:43","2017-03-05 16:09:35","Unit Testing, Model Validation, and Biological Simulation","  The growth of the software industry has gone hand in hand with the
development of tools and cultural practices for ensuring the reliability of
complex pieces of software. These tools and practices are now acknowledged to
be essential to the management of modern software. As computational models and
methods have become increasingly common in the biological sciences, it is
important to examine how these practices can accelerate biological software
development and improve research quality. In this article, we give a focused
case study of our experience with the practices of unit testing and test-driven
development in OpenWorm, an open-science project aimed at modeling
Caenorhabditis elegans. We identify and discuss the challenges of incorporating
test-driven development into a heterogeneous, data-driven project, as well as
the role of model validation tests, a category of tests unique to software
which expresses scientific models.
","Gopal P. Sarma|Travis W. Jacobs|Mark D. Watts|Vahid Ghayoomi|Richard C. Gerkin|Stephen D. Larson","","http://arxiv.org/abs/1508.04635v2","http://arxiv.org/pdf/1508.04635v2","http://dx.doi.org/10.12688/f1000research.9315.1","13 pages, 8 figures","F1000Research 2016, 5:1946","10.12688/f1000research.9315.1","q-bio.QM","q-bio.QM|cs.SE"
"118","1508.05973v2","2015-08-24 21:05:29","2015-11-04 23:25:37","A Review of Nonparametric Hypothesis Tests of Isotropy Properties in
  Spatial Data","  An important aspect of modeling spatially-referenced data is appropriately
specifying the covariance function of the random field. A practitioner working
with spatial data is presented a number of choices regarding the structure of
the dependence between observations. One of these choices is determining
whether or not an isotropic covariance function is appropriate. Isotropy
implies that spatial dependence does not depend on the direction of the spatial
separation between sampling locations. Misspecification of isotropy properties
(directional dependence) can lead to misleading inferences, e.g., inaccurate
predictions and parameter estimates. A researcher may use graphical
diagnostics, such as directional sample variograms, to decide whether the
assumption of isotropy is reasonable. These graphical techniques can be
difficult to assess, open to subjective interpretations, and misleading.
Hypothesis tests of the assumption of isotropy may be more desirable. To this
end, a number of tests of directional dependence have been developed using both
the spatial and spectral representations of random fields. We provide an
overview of nonparametric methods available to test the hypotheses of isotropy
and symmetry in spatial data. We summarize test properties, discuss important
considerations and recommendations in choosing and implementing a test, compare
several of the methods via a simulation study, and propose a number of open
research questions. Several of the reviewed methods can be implemented in R
using our package spTest, available on CRAN.
","Zachary D. Weller|Jennifer A. Hoeting","","http://arxiv.org/abs/1508.05973v2","http://arxiv.org/pdf/1508.05973v2","","22 pages, 6 figures, 9 tables, appendix","","","stat.ME","stat.ME|stat.OT"
"119","1509.02783v2","2015-09-09 14:05:18","2015-09-19 12:19:25","Accelerating News Integration in Automatic Knowledge Extraction
  Ecosystems: an API-first Outlook","  Leveraging Application Programming Interfaces (APIs) has been widely
acknowledged as a valuable approach to software and system design that have
promoted the acceleration of products and services development by allowing the
decoupling of interface design from service implementation details. Many
organizations in the news and journalism industry have adopted and promoted
this API oriented approach. In the first part of this paper, we provide a
survey of the most significant recent work around traditional news and
journalistic open APIs and how these have been influenced by and impacted the
news product landscape. In the second part of the paper, we identify two
disruptive technology trends that we believe will impact the role and value of
news/journalism products in the future: API-first development methodologies,
and the increased role of news-supported automatic knowledge extraction and
analytic services. We anticipate that these two driving forces will create a
new wave of adoption, open collaboration, standardization and overall progress
in news content adoption in knowledge platforms. We provide a brief overview of
our experience in this area at Dow Jones.
","Juan M. Huerta|Clancy Childs","","http://arxiv.org/abs/1509.02783v2","http://arxiv.org/pdf/1509.02783v2","","","","","cs.CY","cs.CY|cs.SE"
"120","1509.04076v1","2015-09-14 13:09:22","2015-09-14 13:09:22","A systematic literature review on process model testing: Approaches,
  challenges, and research directions","  Testing is a key concern when developing process-oriented solutions as it
supports modeling experts who have to deal with increasingly complex models and
scenarios such as cross-organizational processes. However, the complexity of
the research landscape and the diverse set of approaches and goals impedes the
analysis and advancement of research and the identification of promising
research areas, challenges, and research directions. Hence, a systematic
literature review is conducted to identify interesting areas for future
research and to provide an overview of existing work. Over 6300 potentially
matching publications were determined during the search (literature databases,
selected conferences\journals, and snowballing). Finally, 153 publications from
2002 to 2013 were selected, analyzed, and classified. It was found that the
software engineering domain has influenced process model testing approaches
(e.g., regarding terminology and concepts), but recent publications are
presenting independent approaches. Additionally, historical data sources are
not exploited to their full potential and current testing related publications
frequently contain evaluations of relatively weak quality. Overall, the
publication landscape is unevenly distributed so that over 31 publications
concentrate on test-case generation but only 4 publications conduct performance
test. Hence, the full potential of such insufficiently covered testing areas is
not exploited. This systematic review provides a comprehensive overview of the
interdisciplinary topic of process model testing. Several open research
questions are identified, for example, how to apply testing to
cross-organizational or legacy processes and how to adequately include users
into the testing methods.
","Kristof Böhmer|Stefanie Rinderle-Ma","","http://arxiv.org/abs/1509.04076v1","http://arxiv.org/pdf/1509.04076v1","","","","","cs.SE","cs.SE"
"121","1604.08159v1","2015-09-26 02:03:35","2015-09-26 02:03:35","Fujiwhara interaction of tropical cyclone scale vortices using a
  weighted residual collocation method","  The fundamental interaction between tropical cyclones was investigated
through a series of water tank experiements by Fujiwhara [20, 21, 22]. However,
a complete understanding of tropical cyclones remains an open research
challenge although there have been numerous investigations through measurments
with aircrafts/satellites, as well as with numerical simulations. This article
presents a computational model for simulating the interaction between cyclones.
The proposed numerical method is presented briefly, where the time integration
is performed by projecting the discrete system onto a Krylov subspace. The
method filters the large scale fluid dynamics using a multiresolution
approximation, and the unresolved dynamics is modeled with a Smagorinsky type
subgrid scale parameterization scheme. Numerical experiments with Fujiwhara
interactions are considered to verify modeling accuracy. An excellent agreement
between the present simulation and a reference simulation at Re = 5000 has been
demonstrated. At Re = 37440, the kinetic energy of cyclones is seen
consolidated into larger scales with concurrent enstrophy cascade, suggesting a
steady increase of energy containing scales, a phenomena that is typical in
two-dimensional turbulence theory. The primary results of this article suggest
a novel avenue for addressing some of the computational challenges of mesoscale
atmospheric circulations.
","Raymond P Walsh|Jahrul M Alam","","http://arxiv.org/abs/1604.08159v1","http://arxiv.org/pdf/1604.08159v1","http://dx.doi.org/10.1002/fld.4209","24 pages, 11 figures, submitted","","10.1002/fld.4209","physics.flu-dyn","physics.flu-dyn"
"122","1511.04109v1","2015-11-12 22:06:58","2015-11-12 22:06:58","Software Analytics to Software Domains: A Systematic Literature Review","  Software Analytics (SA) is a new branch of big data analytics that has
recently emerged (2011). What distinguishes SA from direct software analysis is
that it links data mined from many different software artifacts to obtain
valuable insights. These insights are useful for the decision-making process
throughout the different phases of the software lifecycle. Since SA is
currently a hot and promising topic, we have conducted a systematic literature
review, presented in this paper, to identify gaps in knowledge and open
research areas in SA. Because many researchers are still confused about the
true potential of SA, we had to filter out available research papers to obtain
the most SA-relevant work for our review. This filtration yielded 19 studies
out of 135. We have based our systematic review on four main factors: which
software practitioners SA targets, which domains are covered by SA, which
artifacts are extracted by SA, and whether these artifacts are linked or not.
The results of our review have shown that much of the available SA research
only serves the needs of developers. Also, much of the available research uses
only one artifact which, in turn, means fewer links between artifacts and fewer
insights. This shows that the available SA research work is still embryonic
leaving plenty of room for future research in the SA field.
","Tamer Mohamed Abdelltif|Luiz Fernando Capretz|Danny Ho","","http://arxiv.org/abs/1511.04109v1","http://arxiv.org/pdf/1511.04109v1","http://dx.doi.org/10.1109/BIGDSE.2015.14","pp. 30-36","37th IEEE International Conference on Software Engineering -
  Workshop on BIGDSE, 2015","10.1109/BIGDSE.2015.14","cs.SE","cs.SE"
"123","1511.06252v1","2015-11-19 16:51:44","2015-11-19 16:51:44","Network-based recommendation algorithms: A review","  Recommender systems are a vital tool that helps us to overcome the
information overload problem. They are being used by most e-commerce web sites
and attract the interest of a broad scientific community. A recommender system
uses data on users' past preferences to choose new items that might be
appreciated by a given individual user. While many approaches to recommendation
exist, the approach based on a network representation of the input data has
gained considerable attention in the past. We review here a broad range of
network-based recommendation algorithms and for the first time compare their
performance on three distinct real datasets. We present recommendation topics
that go beyond the mere question of which algorithm to use - such as the
possible influence of recommendation on the evolution of systems that use it -
and finally discuss open research directions and challenges.
","Fei Yu|An Zeng|Sebastien Gillard|Matus Medo","","http://arxiv.org/abs/1511.06252v1","http://arxiv.org/pdf/1511.06252v1","http://dx.doi.org/10.1016/j.physa.2016.02.021","review article; 16 pages, 4 figures, 4 tables","Physica A 452, 192 (2016)","10.1016/j.physa.2016.02.021","cs.IR","cs.IR|physics.soc-ph"
"124","1512.04467v1","2015-11-20 15:24:22","2015-11-20 15:24:22","A Model for Safety Case Confidence Assessment","  Building a safety case is a common approach to make expert judgement explicit
about safety of a system. The issue of confidence in such argumentation is
still an open research field. Providing quantitative estimation of confidence
is an interesting approach to manage complexity of arguments. This paper
explores the main current approaches, and proposes a new model for quantitative
confidence estimation based on Belief Theory for its definition, and on
Bayesian Belief Networks for its propagation in safety case networks.
","Jérémie Guiochet|Quynh Anh Do Hoang|Mohamed Kaaniche","LAAS-TSF|LAAS-TSF|LAAS-TSF","http://arxiv.org/abs/1512.04467v1","http://arxiv.org/pdf/1512.04467v1","http://dx.doi.org/10.1007/978-3-319-24255-2_23","","34th International Conference on Computer Safety, Reliability and
  Security, Sep 2015, Delft, Netherlands. Springer, Lecture Notes in Computer
  Science, Vol. 9337, Programming and Software Engineering, Springer, 2015,
  http://safecomp2015.tudelft.nl/","10.1007/978-3-319-24255-2_23","cs.AI","cs.AI"
"125","1511.08689v1","2015-11-27 14:45:14","2015-11-27 14:45:14","Energy Efficiency in Massive MIMO-Based 5G Networks: Opportunities and
  Challenges","  As we make progress towards the era of fifth generation (5G) communication
networks, energy efficiency (EE) becomes an important design criterion because
it guarantees sustainable evolution. In this regard, the massive multiple-input
multiple-output (MIMO) technology, where the base stations (BSs) are equipped
with a large number of antennas so as to achieve multiple orders of spectral
and energy efficiency gains, will be a key technology enabler for 5G. In this
article, we present a comprehensive discussion on state-of-the-art techniques
which further enhance the EE gains offered by massive MIMO (MM). We begin with
an overview of MM systems and discuss how realistic power consumption models
can be developed for these systems. Thereby, we discuss and identify few
shortcomings of some of the most prominent EE-maximization techniques present
in the current literature. Then, we discuss ""hybrid MM systems"" operating in a
5G architecture, where MM operates in conjunction with other potential
technology enablers, such as millimetre wave, heterogenous networks, and energy
harvesting networks. Multiple opportunities and challenges arise in such a 5G
architecture because these technologies benefit mutually from each other and
their coexistence introduces several new constraints on the design of
energy-efficient systems. Despite clear evidence that hybrid MM systems can
achieve significantly higher EE gains than conventional MM systems, several
open research problems continue to roadblock system designers from fully
harnessing the EE gains offered by hybrid MM systems. Our discussions lead to
the conclusion that hybrid MM systems offer a sustainable evolution towards 5G
networks and are therefore an important research topic for future work.
","K. N. R. Surya Vara Prasad|Ekram Hossain|Vijay K. Bhargava","","http://arxiv.org/abs/1511.08689v1","http://arxiv.org/pdf/1511.08689v1","","IEEE Wireless Communications, under review","","","cs.NI","cs.NI|cs.IT|math.IT"
"126","1512.03565v1","2015-12-11 09:51:58","2015-12-11 09:51:58","A Survey of multimedia streaming in wireless sensor networks: progress,
  issues and design challenges","  Advancements in Complementary Metal Oxide Semiconductor (CMOS) technology
have enabled Wireless Sensor Networks (WSN) to gather, process and transport
multimedia (MM) data as well and not just limited to handling ordinary scalar
data anymore. This new generation of WSN type is called Wireless Multimedia
Sensor Networks (WMSNs). Better and yet relatively cheaper sensors that are
able to sense both scalar data and multimedia data with more advanced
functionalities such as being able to handle rather intense computations easily
have sprung up. In this paper, the applications, architectures, challenges and
issues faced in the design of WMSNs are explored. Security and privacy issues,
over all requirements, proposed and implemented solutions so far, some of the
successful achievements and other related works in the field are also
highlighted. Open research areas are pointed out and a few solution suggestions
to the still persistent problems are made, which, to the best of my knowledge,
so far have not been explored yet.
","Taner Cevik|Alex Gunagwera|Nazife Cevik","","http://arxiv.org/abs/1512.03565v1","http://arxiv.org/pdf/1512.03565v1","http://dx.doi.org/10.5121/ijcnc.2015.7508","","","10.5121/ijcnc.2015.7508","cs.NI","cs.NI"
"127","1512.04817v1","2015-12-15 15:29:36","2015-12-15 15:29:36","Principled Evaluation of Differentially Private Algorithms using DPBench","  Differential privacy has become the dominant standard in the research
community for strong privacy protection. There has been a flood of research
into query answering algorithms that meet this standard. Algorithms are
becoming increasingly complex, and in particular, the performance of many
emerging algorithms is {\em data dependent}, meaning the distribution of the
noise added to query answers may change depending on the input data.
Theoretical analysis typically only considers the worst case, making empirical
study of average case performance increasingly important.
  In this paper we propose a set of evaluation principles which we argue are
essential for sound evaluation. Based on these principles we propose DPBench, a
novel evaluation framework for standardized evaluation of privacy algorithms.
We then apply our benchmark to evaluate algorithms for answering 1- and
2-dimensional range queries. The result is a thorough empirical study of 15
published algorithms on a total of 27 datasets that offers new insights into
algorithm behavior---in particular the influence of dataset scale and
shape---and a more complete characterization of the state of the art. Our
methodology is able to resolve inconsistencies in prior empirical studies and
place algorithm performance in context through comparison to simple baselines.
Finally, we pose open research questions which we hope will guide future
algorithm design.
","Michael Hay|Ashwin Machanavajjhala|Gerome Miklau|Yan Chen|Dan Zhang","","http://arxiv.org/abs/1512.04817v1","http://arxiv.org/pdf/1512.04817v1","","","","","cs.DB","cs.DB|cs.CR"
"128","1512.05075v1","2015-12-16 07:41:55","2015-12-16 07:41:55","Smart Data Pricing Models for Internet-of-Things (IoT): A Bundling
  Strategy Approach","  Internet of things (IoT) has emerged as a new paradigm for the future
Internet. In IoT, enormous devices are connected to the Internet and thereby
being a huge data source for numerous applications. In this article, we focus
on addressing data management in IoT through using a smart data pricing (SDP)
approach. With SDP, data can be managed flexibly and efficiently through
intelligent and adaptive incentive mechanisms. Moreover, it is a major source
of revenue for providers and partners. We propose a new pricing scheme for IoT
service providers to determine the sensing data buying price and IoT service
subscription fee offered to sensor owners and service users, respectively.
Additionally, we adopt the bundling strategy that allows multiple providers to
form a coalition and bid their services as a bundle, attracting more users and
achieving higher revenue. Finally, we outline some important open research
issues for SDP and IoT.
","Dusit Niyato|Dinh Thai Hoang|Nguyen Cong Luong|Ping Wang|Dong In Kim|Zhu Han","","http://arxiv.org/abs/1512.05075v1","http://arxiv.org/pdf/1512.05075v1","","17 pages, 6 figures, 1 table, IEEE Network Magazine, 2015","","","cs.GT","cs.GT"
"129","1512.05619v1","2015-12-17 15:02:36","2015-12-17 15:02:36","Modeling Joint Improvisation between Human and Virtual Players in the
  Mirror Game","  Joint improvisation is observed to emerge spontaneously among humans
performing joint action tasks, and has been associated with high levels of
movement synchrony and enhanced sense of social bonding. Exploring the
underlying cognitive and neural mechanisms behind the emergence of joint
improvisation is an open research challenge. This paper investigates the
emergence of jointly improvised movements between two participants in the
mirror game, a paradigmatic joint task example. A theoretical model based on
observations and analysis of experimental data is proposed to capture the main
features of their interaction. A set of experiments is carried out to test and
validate the model ability to reproduce the experimental observations. Then,
the model is used to drive a computer avatar able to improvise joint motion
with a human participant in real time. Finally, a convergence analysis of the
proposed model is carried out to confirm its ability to reproduce the emergence
of joint movement between the participants.
","Chao Zhai|Francesco Alderisio|Piotr Slowinski|Krasimira Tsaneva-Atanasova|Mario di Bernardo","","http://arxiv.org/abs/1512.05619v1","http://arxiv.org/pdf/1512.05619v1","","","","","math.OC","math.OC|math.DS|q-bio.NC"
"130","1512.07919v1","2015-12-24 21:01:08","2015-12-24 21:01:08","Improving Software Citation and Credit","  The past year has seen movement on several fronts for improving software
citation, including the Center for Open Science's Transparency and Openness
Promotion (TOP) Guidelines, the Software Publishing Special Interest Group that
was started at January's AAS meeting in Seattle at the request of that
organization's Working Group on Astronomical Software, a Sloan-sponsored
meeting at GitHub in San Francisco to begin work on a cohesive research
software citation-enabling platform, the work of Force11 to ""transform and
improve"" research communication, and WSSSPE's ongoing efforts that include
software publication, citation, credit, and sustainability.
  Brief reports on these efforts were shared at the BoF, after which
participants discussed ideas for improving software citation, generating a list
of recommendations to the community of software authors, journal publishers,
ADS, and research authors. The discussion, recommendations, and feedback will
help form recommendations for software citation to those publishers represented
in the Software Publishing Special Interest Group and the broader community.
","Alice Allen|G. Bruce Berriman|Kimberly DuPrie|Jessica Mink|Robert Nemiroff|Thomas Robitaille|Lior Shamir|Keith Shortridge|Mark Taylor|Peter Teuben|John Wallin","","http://arxiv.org/abs/1512.07919v1","http://arxiv.org/pdf/1512.07919v1","","Birds of a Feather session organized by the Astrophysics Source Code
  Library (ASCL, http://ascl.net/ ); to be published in Proceedings of ADASS
  XXV (Sydney, Australia; October, 2015). 4 pages","","","cs.DL","cs.DL|astro-ph.IM"
"131","1601.00199v1","2016-01-02 17:50:13","2016-01-02 17:50:13","A Unified Framework for Compositional Fitting of Active Appearance
  Models","  Active Appearance Models (AAMs) are one of the most popular and
well-established techniques for modeling deformable objects in computer vision.
In this paper, we study the problem of fitting AAMs using Compositional
Gradient Descent (CGD) algorithms. We present a unified and complete view of
these algorithms and classify them with respect to three main characteristics:
i) cost function; ii) type of composition; and iii) optimization method.
Furthermore, we extend the previous view by: a) proposing a novel Bayesian cost
function that can be interpreted as a general probabilistic formulation of the
well-known project-out loss; b) introducing two new types of composition,
asymmetric and bidirectional, that combine the gradients of both image and
appearance model to derive better conver- gent and more robust CGD algorithms;
and c) providing new valuable insights into existent CGD algorithms by
reinterpreting them as direct applications of the Schur complement and the
Wiberg method. Finally, in order to encourage open research and facilitate
future comparisons with our work, we make the implementa- tion of the
algorithms studied in this paper publicly available as part of the Menpo
Project.
","Joan Alabort-i-Medina|Stefanos Zafeiriou","","http://arxiv.org/abs/1601.00199v1","http://arxiv.org/pdf/1601.00199v1","","39 pages","","","cs.CV","cs.CV"
"132","1601.00323v1","2016-01-03 19:06:43","2016-01-03 19:06:43","The Design of a Community Science Cloud: The Open Science Data Cloud
  Perspective","  In this paper we describe the design, and implementation of the Open Science
Data Cloud, or OSDC. The goal of the OSDC is to provide petabyte-scale data
cloud infrastructure and related services for scientists working with large
quantities of data. Currently, the OSDC consists of more than 2000 cores and 2
PB of storage distributed across four data centers connected by 10G networks.
We discuss some of the lessons learned during the past three years of operation
and describe the software stacks used in the OSDC. We also describe some of the
research projects in biology, the earth sciences, and social sciences enabled
by the OSDC.
","Robert L. Grossman|Matthew Greenway|Allison P. Heath|Ray Powell|Rafael D. Suarez|Walt Wells|Kevin White|Malcolm Atkinson|Iraklis Klampanos|Heidi L. Alvarez|Christine Harvey|Joe J. Mambretti","","http://arxiv.org/abs/1601.00323v1","http://arxiv.org/pdf/1601.00323v1","","12 pages, 3 figures","","","cs.CE","cs.CE"
"133","1601.03854v1","2016-01-15 09:36:25","2016-01-15 09:36:25","Virtual Machine Migration Enabled Cloud Resource Management: A
  Challenging Task","  Virtualization technology reduces cloud operational cost by increasing cloud
resource utilization level. The incorporation of virtualization within cloud
data centers can severely degrade cloud performance if not properly managed.
Virtual machine (VM) migration is a method that assists cloud service providers
to efficiently manage cloud resources while eliminating the need of human
supervision. VM migration methodology migrates current-hosted workload from one
server to another by either employing live or non-live migration pattern. In
comparison to non-live migration, live migration does not suspend application
services prior to VM migration process. VM migration enables cloud operators to
achieve various resource management goals, such as, green computing, load
balancing, fault management, and real time server maintenance. In this paper,
we have thoroughly surveyed VM migration methods and applications. We have
briefly discussed VM migration applications. Some open research issues have
been highlighted to represent future challenges in this domain. A queue based
migration model has been proposed and discussed to efficiently migrate VM
memory pages.
","Misbah Liaqat|Shalini Ninoriya|Junaid Shuja|Raja Wasim Ahmad|Abdullah Gani","","http://arxiv.org/abs/1601.03854v1","http://arxiv.org/pdf/1601.03854v1","","7 pages, 3 figures","","","cs.DC","cs.DC"
"134","1602.06994v1","2016-02-22 23:17:37","2016-02-22 23:17:37","Spatio-Temporal Analysis of Team Sports -- A Survey","  Team-based invasion sports such as football, basketball and hockey are
similar in the sense that the players are able to move freely around the
playing area; and that player and team performance cannot be fully analysed
without considering the movements and interactions of all players as a group.
State of the art object tracking systems now produce spatio-temporal traces of
player trajectories with high definition and high frequency, and this, in turn,
has facilitated a variety of research efforts, across many disciplines, to
extract insight from the trajectories. We survey recent research efforts that
use spatio-temporal data from team sports as input, and involve non-trivial
computation. This article categorises the research efforts in a coherent
framework and identifies a number of open research questions.
","Joachim Gudmundsson|Michael Horton","","http://arxiv.org/abs/1602.06994v1","http://arxiv.org/pdf/1602.06994v1","http://dx.doi.org/10.1145/3054132","42 pages, 11 figures","","10.1145/3054132","cs.OH","cs.OH|A.1; H.2.8"
"135","1603.09537v1","2016-03-31 11:41:47","2016-03-31 11:41:47","Will 5G See its Blind Side? Evolving 5G for Universal Internet Access","  Internet has shown itself to be a catalyst for economic growth and social
equity but its potency is thwarted by the fact that the Internet is off limits
for the vast majority of human beings. Mobile phones---the fastest growing
technology in the world that now reaches around 80\% of humanity---can enable
universal Internet access if it can resolve coverage problems that have
historically plagued previous cellular architectures (2G, 3G, and 4G). These
conventional architectures have not been able to sustain universal service
provisioning since these architectures depend on having enough users per cell
for their economic viability and thus are not well suited to rural areas (which
are by definition sparsely populated). The new generation of mobile cellular
technology (5G), currently in a formative phase and expected to be finalized
around 2020, is aimed at orders of magnitude performance enhancement. 5G offers
a clean slate to network designers and can be molded into an architecture also
amenable to universal Internet provisioning. Keeping in mind the great social
benefits of democratizing Internet and connectivity, we believe that the time
is ripe for emphasizing universal Internet provisioning as an important goal on
the 5G research agenda. In this paper, we investigate the opportunities and
challenges in utilizing 5G for global access to the Internet for all (GAIA). We
have also identified the major technical issues involved in a 5G-based GAIA
solution and have set up a future research agenda by defining open research
problems.
","Oluwakayode Onireti|Muhammad Ali Imran|Junaid Qadir|Arjuna Sathiaseelan","","http://arxiv.org/abs/1603.09537v1","http://arxiv.org/pdf/1603.09537v1","","","","","cs.NI","cs.NI"
"136","1604.03605v2","2016-04-12 22:16:20","2017-04-06 23:46:40","What do different evaluation metrics tell us about saliency models?","  How best to evaluate a saliency model's ability to predict where humans look
in images is an open research question. The choice of evaluation metric depends
on how saliency is defined and how the ground truth is represented. Metrics
differ in how they rank saliency models, and this results from how false
positives and false negatives are treated, whether viewing biases are accounted
for, whether spatial deviations are factored in, and how the saliency maps are
pre-processed. In this paper, we provide an analysis of 8 different evaluation
metrics and their properties. With the help of systematic experiments and
visualizations of metric computations, we add interpretability to saliency
scores and more transparency to the evaluation of saliency models. Building off
the differences in metric properties and behaviors, we make recommendations for
metric selections under specific assumptions and for specific applications.
","Zoya Bylinskii|Tilke Judd|Aude Oliva|Antonio Torralba|Frédo Durand","","http://arxiv.org/abs/1604.03605v2","http://arxiv.org/pdf/1604.03605v2","","","","","cs.CV","cs.CV"
"137","1605.02288v1","2016-05-08 07:31:01","2016-05-08 07:31:01","Bayesian Overlapping Community Detection in Dynamic Networks","  Detecting community structures in social networks has gained considerable
attention in recent years. However, lack of prior knowledge about the number of
communities, and their overlapping nature have made community detection a
challenging problem. Moreover, many of the existing methods only consider
static networks, while most of real world networks are dynamic and evolve over
time. Hence, finding consistent overlapping communities in dynamic networks
without any prior knowledge about the number of communities is still an
interesting open research problem. In this paper, we present an overlapping
community detection method for dynamic networks called Dynamic Bayesian
Overlapping Community Detector (DBOCD). DBOCD assumes that in every snapshot of
network, overlapping parts of communities are dense areas and utilizes link
communities instead of common node communities. Using Recurrent Chinese
Restaurant Process and community structure of the network in the last snapshot,
DBOCD simultaneously extracts the number of communities and soft community
memberships of nodes while maintaining the consistency of communities over
time. We evaluated DBOCD on both synthetic and real dynamic data-sets to assess
its ability to find overlapping communities in different types of network
evolution. The results show that DBOCD outperforms the recent state of the art
dynamic community detection methods.
","Mahsa Ghorbani|Hamid R. Rabiee|Ali Khodadadi","","http://arxiv.org/abs/1605.02288v1","http://arxiv.org/pdf/1605.02288v1","","10 pages, Submitted to IEEE TNSE Journal","","","cs.SI","cs.SI|physics.soc-ph"
"138","1605.05822v2","2016-05-19 06:20:20","2016-07-23 23:53:25","Why Scientists Chase Big Problems: Individual Strategy and Social
  Optimality","  Scientists pursue collective knowledge, but they also seek personal
recognition from their peers. When scientists decide whether or not to work on
a big new problem, they weigh the potential rewards of a major discovery
against the costs of setting aside other projects. These self-interested
choices can potentially spread researchers across problems in an efficient
manner, but efficiency is not guaranteed. We use simple economic models to
understand such decisions and their collective consequences. Academic science
differs from industrial R&D in that academics often share partial solutions to
gain reputation. This convention of Open Science is thought to accelerate
collective discovery, but we find that it need not do so. The ability to share
partial results influences which scientists work on a particular problem;
consequently, Open Science can slow down the solution of a problem if it deters
entry by important actors.
","Carl T. Bergstrom|Jacob G. Foster|Yangbo Song","","http://arxiv.org/abs/1605.05822v2","http://arxiv.org/pdf/1605.05822v2","","","","","physics.soc-ph","physics.soc-ph"
"139","1605.06414v4","2016-05-19 13:33:40","2016-09-12 06:13:44","Recent reproducibility estimates indicate that negative evidence is
  observed over 30 times before publication","  The Open Science Collaboration recently reported that 36% of published
findings from psychological studies were reproducible by independent
researchers. We can use this information together with Bayes theorem to
estimate the statistical power needed to produce these findings under various
assumptions and calculate the expected distribution of positive and negative
evidence for a range of prior probabilities of the tested hypotheses; and by
comparing this distribution to other findings indicating that >90% of
publications in the psychological literature are statistically significant in
support of the authors hypothesis, we can estimate the magnitude of publication
bias. The results indicate that negative evidence was observed 30--200 times
before one was published.
","Michael Ingre","","http://arxiv.org/abs/1605.06414v4","http://arxiv.org/pdf/1605.06414v4","","","","","physics.soc-ph","physics.soc-ph"
"140","1605.07006v1","2016-05-23 13:19:33","2016-05-23 13:19:33","Extremes and Recurrence in Dynamical Systems","  This book provides a comprehensive introduction for the study of extreme
events in the context of dynamical systems. The introduction provides a broad
overview of the interdisciplinary research area of extreme events, underlining
its relevance for mathematics, natural sciences, engineering, and social
sciences. After exploring the basics of the classical theory of extreme events,
the book presents a careful examination of how a dynamical system can serve as
a generator of stochastic processes, and explores in detail the relationship
between the hitting and return time statistics of a dynamical system and the
possibility of constructing extreme value laws for given observables. Explicit
derivation of extreme value laws are then provided for selected dynamical
systems. The book then discusses how extreme events can be used as probes for
inferring fundamental dynamical and geometrical properties of a dynamical
system and for providing a novel point of view in problems of physical and
geophysical relevance. A final summary of the main results is then presented
along with a discussion of open research questions. Finally, an appendix with
software in Matlab programming language allows the readers to develop further
understanding of the presented concepts.
","Valerio Lucarini|Davide Faranda|Ana Cristina Moreira Freitas|Jorge Milhazes Freitas|Tobias Kuna|Mark Holland|Matthew Nicol|Mike Todd|Sandro Vaienti","","http://arxiv.org/abs/1605.07006v1","http://arxiv.org/pdf/1605.07006v1","","305 pages book, V. Lucarini, D. Faranda, A. C. M. Freitas, J. M.
  Freitas, T. Kuna, M. Holland, M. Nicol, M. Todd, S. Vaienti, Extremes and
  Recurrence in Dynamical Systems, Wiley, New York, 2016, ISBN:
  978-1-118-63219-2","","","math.DS","math.DS|cond-mat.stat-mech|math-ph|math.MP|math.PR|nlin.CD|60G70, 37A60, 37A25, 62M10, 82C05, 86A04"
"141","1605.09351v2","2016-05-30 18:45:06","2016-09-16 21:17:24","Review of Fall Detection Techniques: A Data Availability Perspective","  A fall is an abnormal activity that occurs rarely; however, missing to
identify falls can have serious health and safety implications on an
individual. Due to the rarity of occurrence of falls, there may be insufficient
or no training data available for them. Therefore, standard supervised machine
learning methods may not be directly applied to handle this problem. In this
paper, we present a taxonomy for the study of fall detection from the
perspective of availability of fall data. The proposed taxonomy is independent
of the type of sensors used and specific feature extraction/selection methods.
The taxonomy identifies different categories of classification methods for the
study of fall detection based on the availability of their data during training
the classifiers. Then, we present a comprehensive literature review within
those categories and identify the approach of treating a fall as an abnormal
activity to be a plausible research direction. We conclude our paper by
discussing several open research problems in the field and pointers for future
research.
","Shehroz S. Khan|Jesse Hoey","","http://arxiv.org/abs/1605.09351v2","http://arxiv.org/pdf/1605.09351v2","http://dx.doi.org/10.1016/j.medengphy.2016.10.014","30 pages, 1 figure, 3 Tables","Medical Engineering and Physics, Volume 39, 2017","10.1016/j.medengphy.2016.10.014","cs.LG","cs.LG"
"142","1606.05675v1","2016-06-17 21:03:19","2016-06-17 21:03:19","DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided
  Dietary Assessment","  Worldwide, in 2014, more than 1.9 billion adults, 18 years and older, were
overweight. Of these, over 600 million were obese. Accurately documenting
dietary caloric intake is crucial to manage weight loss, but also presents
challenges because most of the current methods for dietary assessment must rely
on memory to recall foods eaten. The ultimate goal of our research is to
develop computer-aided technical solutions to enhance and improve the accuracy
of current measurements of dietary intake. Our proposed system in this paper
aims to improve the accuracy of dietary assessment by analyzing the food images
captured by mobile devices (e.g., smartphone). The key technique innovation in
this paper is the deep learning-based food image recognition algorithms.
Substantial research has demonstrated that digital imaging accurately estimates
dietary intake in many environments and it has many advantages over other
methods. However, how to derive the food information (e.g., food type and
portion size) from food image effectively and efficiently remains a challenging
and open research problem. We propose a new Convolutional Neural Network
(CNN)-based food image recognition algorithm to address this problem. We
applied our proposed approach to two real-world food image data sets (UEC-256
and Food-101) and achieved impressive results. To the best of our knowledge,
these results outperformed all other reported work using these two data sets.
Our experiments have demonstrated that the proposed approach is a promising
solution for addressing the food image recognition problem. Our future work
includes further improving the performance of the algorithms and integrating
our system into a real-world mobile and cloud computing-based system to enhance
the accuracy of current measurements of dietary intake.
","Chang Liu|Yu Cao|Yan Luo|Guanling Chen|Vinod Vokkarane|Yunsheng Ma","","http://arxiv.org/abs/1606.05675v1","http://arxiv.org/pdf/1606.05675v1","","12 pages, 2 figures, 6 tables, ICOST 2016","","","cs.CV","cs.CV"
"143","1606.06808v5","2016-06-22 02:45:39","2017-03-06 21:42:17","SMCQL: Secure Querying for Federated Databases","  People and machines are collecting data at an unprecedented rate. Despite
this newfound abundance of data, progress has been slow in sharing it for open
science, business, and other data-intensive endeavors. Many such efforts are
stymied by privacy concerns and regulatory compliance issues. For example, many
hospitals are interested in pooling their medical records for research, but
none may disclose arbitrary patient records to researchers or other healthcare
providers. In this context we propose the Private Data Network (PDN), a
federated database for querying over the collective data of mutually
distrustful parties. In a PDN, each member database does not reveal its tuples
to its peers nor to the query writer. Instead, the user submits a query to an
honest broker that plans and coordinates its execution over multiple private
databases using secure multiparty computation (SMC). Here, each database's
query execution is oblivious, and its program counters and memory traces are
agnostic to the inputs of others. We introduce a framework for executing PDN
queries named SMCQL. This system translates SQL statements into SMC primitives
to compute query results over the union of its source databases without
revealing sensitive information about individual tuples to peer data providers
or the honest broker. Only the honest broker and the querier receive the
results of a PDN query. For fast, secure query evaluation, we explore a
heuristics-driven optimizer that minimizes the PDN's use of secure computation
and partitions its query evaluation into scalable slices.
","Johes Bater|Gregory Elliott|Craig Eggen|Satyender Goel|Abel Kho|Jennie Rogers","","http://arxiv.org/abs/1606.06808v5","http://arxiv.org/pdf/1606.06808v5","","","","","cs.DB","cs.DB|cs.CR"
"144","1606.07080v1","2016-06-22 20:04:16","2016-06-22 20:04:16","Domain Name System Security and Privacy: Old Problems and New Challenges","  The domain name system (DNS) is an important protocol in today's Internet
operation, and is the standard naming convention between domain names, names
that are easy to read, understand, and remember by humans, to IP address of
Internet resources. The wealth of research activities on DNS in general and
security and privacy in particular suggest that all problems in this domain are
solved. Reality however is that despite the large body of literature on various
aspects of DNS, there are still many challenges that need to be addressed. In
this paper, we review the various activities in the research community on DNS
operation, security, and privacy, and outline various challenges and open
research directions that need to be tackled.
","Ah Reum Kang|Jeffrey Spaulding|Aziz Mohaisen","","http://arxiv.org/abs/1606.07080v1","http://arxiv.org/pdf/1606.07080v1","","","","","cs.CR","cs.CR"
"145","1607.02646v1","2016-07-09 18:54:46","2016-07-09 18:54:46","High-Level Programming Abstractions for Distributed Graph Processing","  Efficient processing of large-scale graphs in distributed environments has
been an increasingly popular topic of research in recent years. Inter-connected
data that can be modeled as graphs arise in application domains such as machine
learning, recommendation, web search, and social network analysis. Writing
distributed graph applications is inherently hard and requires programming
models that can cover a diverse set of problem domains, including iterative
refinement algorithms, graph transformations, graph aggregations, pattern
matching, ego-network analysis, and graph traversals. Several high-level
programming abstractions have been proposed and adopted by distributed graph
processing systems and big data platforms. Even though significant work has
been done to experimentally compare distributed graph processing frameworks, no
qualitative study and comparison of graph programming abstractions has been
conducted yet. In this survey, we review and analyze the most prevalent
high-level programming models for distributed graph processing, in terms of
their semantics and applicability. We identify the classes of graph
applications that can be naturally expressed by each abstraction and we also
give examples of applications that are hard or impossible to express. We review
34 distributed graph processing systems with respect to their programming
abstractions, execution models, and communication mechanisms. Finally, we
discuss trends and open research questions in the area of distributed graph
processing.
","Vasiliki Kalavri|Vladimir Vlassov|Seif Haridi","","http://arxiv.org/abs/1607.02646v1","http://arxiv.org/pdf/1607.02646v1","http://dx.doi.org/10.1109/TKDE.2017.2762294","","","10.1109/TKDE.2017.2762294","cs.DC","cs.DC"
"146","1607.03443v1","2016-07-12 17:28:47","2016-07-12 17:28:47","A Survey about Prediction-Based Data Reduction in Wireless Sensor
  Networks","  One of the main characteristics of Wireless Sensor Networks (WSNs) is the
constrained energy resources of their wireless sensor nodes. Although this
issue has been addressed in several works and got a lot of attention within the
years, the most recent advances pointed out that the energy harvesting and
wireless charging techniques may offer means to overcome such a limitation.
Consequently, an issue that had been put in second place, now emerges: the low
availability of spectrum resources. Because of it, the incorporation of the
WSNs into the Internet of Things and the exponential growth of the latter may
be hindered if no control over the data generation is taken. Alternatively,
part of the sensed data can be predicted without triggering transmissions and
congesting the wireless medium. In this work, we analyze and categorize
existing prediction-based data reduction mechanisms that have been designed for
WSNs. Our main contribution is a systematic procedure for selecting a scheme to
make predictions in WSNs, based on WSNs' constraints, characteristics of
prediction methods and monitored data. Finally, we conclude the paper with a
discussion about future challenges and open research directions in the use of
prediction methods to support the WSNs' growth.
","Gabriel Martins Dias|Boris Bellalta|Simon Oechsner","","http://arxiv.org/abs/1607.03443v1","http://arxiv.org/pdf/1607.03443v1","","37 pages, 6 figures, 3 tables. Submitted to ACM Computing Surveys","","","cs.NI","cs.NI|C.2.4; I.2; A.1"
"147","1607.06884v1","2016-07-23 03:31:31","2016-07-23 03:31:31","Searching for the Internet of Things on the Web: Where It Is and What It
  Looks Like","  The Internet of Things (IoT), in general, is a compelling paradigm that aims
to connect everyday objects to the Internet. Nowadays, IoT is considered as one
of the main technologies which contribute towards reshaping our daily lives in
the next decade. IoT unlocks many exciting new opportunities in a variety of
applications in research and industry domains. However, many have complained
about the absence of the real-world IoT data. Unsurprisingly, a common question
that arises regularly nowadays is ""Does the IoT already exist?"". So far, little
has been known about the real-world situation on IoT, its attributes, the
presentation of data and user interests. To answer this question, in this work,
we conduct an in-depth analytical investigation on real IoT data. More
specifically, we identify IoT data sources over the Web and develop a crawler
engine to collect large-scale real-world IoT data for the first time. We make
the results of our work available to the public in order to assist the
community in the future research. In particular, we collect the data of nearly
two million Internet connected objects and study trends in IoT using a
real-world query set from an IoT search engine. Based on the collected data and
our analysis, we identify the typical characteristics of IoT data. The most
intriguing finding of our study is that IoT data is mainly disseminated using
Web Mapping while the emerging IoT solutions such as the Web of Things, are
currently not well adopted. On top of our findings, we further discuss future
challenges and open research problems in the IoT area.
","Ali Shemshadi|Quan Z. Sheng|Wei Emma Zhang|Aixin Sun|Yongrui Qin|Lina Yao","","http://arxiv.org/abs/1607.06884v1","http://arxiv.org/pdf/1607.06884v1","","","","","cs.IR","cs.IR|cs.NI"
"148","1608.01137v2","2016-08-03 10:17:22","2016-08-06 21:03:34","Cascaded Continuous Regression for Real-time Incremental Face Tracking","  This paper introduces a novel real-time algorithm for facial landmark
tracking. Compared to detection, tracking has both additional challenges and
opportunities. Arguably the most important aspect in this domain is updating a
tracker's models as tracking progresses, also known as incremental (face)
tracking. While this should result in more accurate localisation, how to do
this online and in real time without causing a tracker to drift is still an
important open research question. We address this question in the cascaded
regression framework, the state-of-the-art approach for facial landmark
localisation. Because incremental learning for cascaded regression is costly,
we propose a much more efficient yet equally accurate alternative using
continuous regression. More specifically, we first propose cascaded continuous
regression (CCR) and show its accuracy is equivalent to the Supervised Descent
Method. We then derive the incremental learning updates for CCR (iCCR) and show
that it is an order of magnitude faster than standard incremental learning for
cascaded regression, bringing the time required for the update from seconds
down to a fraction of a second, thus enabling real-time tracking. Finally, we
evaluate iCCR and show the importance of incremental learning in achieving
state-of-the-art performance. Code for our iCCR is available from
http://www.cs.nott.ac.uk/~psxes1
","Enrique Sánchez-Lozano|Brais Martinez|Georgios Tzimiropoulos|Michel Valstar","","http://arxiv.org/abs/1608.01137v2","http://arxiv.org/pdf/1608.01137v2","","ECCV 2016 accepted paper, with supplementary material included as
  appendices. References to Equations fixed","","","cs.CV","cs.CV"
"149","1608.03475v1","2016-08-11 14:19:54","2016-08-11 14:19:54","Data Collection and Wireless Communication in Internet of Things (IoT)
  Using Economic Analysis and Pricing Models: A Survey","  This paper provides a state-of-the-art literature review on economic analysis
and pricing models for data collection and wireless communication in Internet
of Things (IoT). Wireless Sensor Networks (WSNs) are the main component of IoT
which collect data from the environment and transmit the data to the sink
nodes. For long service time and low maintenance cost, WSNs require adaptive
and robust designs to address many issues, e.g., data collection, topology
formation, packet forwarding, resource and power optimization, coverage
optimization, efficient task allocation, and security. For these issues,
sensors have to make optimal decisions from current capabilities and available
strategies to achieve desirable goals. This paper reviews numerous applications
of the economic and pricing models, known as intelligent rational
decision-making methods, to develop adaptive algorithms and protocols for WSNs.
Besides, we survey a variety of pricing strategies in providing incentives for
phone users in crowdsensing applications to contribute their sensing data.
Furthermore, we consider the use of some pricing models in Machine-to-Machine
(M2M) communication. Finally, we highlight some important open research issues
as well as future research directions of applying economic and pricing models
to IoT.
","Nguyen Cong Luong|Dinh Thai Hoang|Ping Wang|Dusit Niyato|Dong In Kim|Zhu Han","","http://arxiv.org/abs/1608.03475v1","http://arxiv.org/pdf/1608.03475v1","","","","","cs.GT","cs.GT|cs.CY"
"150","1609.06874v2","2016-09-22 09:02:01","2017-01-04 20:56:38","EEG reconstruction and skull conductivity estimation using a Bayesian
  model promoting structured sparsity","  M/EEG source localization is an open research issue. To solve it, it is
important to have good knowledge of several physical parameters to build a
reliable head operator. Amongst them, the value of the conductivity of the
human skull has remained controversial. This report introduces a novel
hierarchical Bayesian framework to estimate the skull conductivity jointly with
the brain activity from the M/EEG measurements to improve the reconstruction
quality. A partially collapsed Gibbs sampler is used to draw samples
asymptotically distributed according to the associated posterior. The generated
samples are then used to estimate the brain activity and the model
hyperparameters jointly in a completely unsupervised framework. We use
synthetic and real data to illustrate the improvement of the reconstruction.
The performance of our method is also compared with two optimization algorithms
introduced by Vallagh\'e \textit{et al.} and Gutierrez \textit{et al.}
respectively, showing that our method is able to provide results of similar or
better quality while remaining applicable in a wider array of situations.
","Facundo Costa|Hadj Batatia|Thomas Oberlin|Jean-Yves Tourneret","","http://arxiv.org/abs/1609.06874v2","http://arxiv.org/pdf/1609.06874v2","","Technical report","","","stat.ME","stat.ME|stat.AP"
"151","1609.08082v2","2016-09-26 17:16:54","2017-03-10 13:58:27","An Ontology of Preference-Based Multiobjective Metaheuristics","  User preference integration is of great importance in multi-objective
optimization, in particular in many objective optimization. Preferences have
long been considered in traditional multicriteria decision making (MCDM) which
is based on mathematical programming. Recently, it is integrated in
multi-objective metaheuristics (MOMH), resulting in focus on preferred parts of
the Pareto front instead of the whole Pareto front. The number of publications
on preference-based multi-objective metaheuristics has increased rapidly over
the past decades. There already exist various preference handling methods and
MOMH methods, which have been combined in diverse ways. This article proposes
to use the Web Ontology Language (OWL) to model and systematize the results
developed in this field. A review of the existing work is provided, based on
which an ontology is built and instantiated with state-of-the-art results. The
OWL ontology is made public and open to future extension. Moreover, the usage
of the ontology is exemplified for different use-cases, including querying for
methods that match an engineering application, bibliometric analysis, checking
existence of combinations of preference models and MOMH techniques, and
discovering opportunities for new research and open research questions.
","Longmei Li|Iryna Yevseyeva|Vitor Basto-Fernandes|Heike Trautmann|Ning Jing|Michael Emmerich","","http://arxiv.org/abs/1609.08082v2","http://arxiv.org/pdf/1609.08082v2","","submitted to European Journal of Operational Research","","","cs.NE","cs.NE|cs.AI"
"152","1609.08089v3","2016-09-26 17:26:16","2017-07-24 00:35:37","Software Platforms for Smart Cities: Concepts, Requirements, Challenges,
  and a Unified Reference Architecture","  Making cities smarter help improve city services and increase citizens'
quality of life. Information and communication technologies (ICT) are
fundamental for progressing towards smarter city environments. Smart City
software platforms potentially support the development and integration of Smart
City applications. However, the ICT community must overcome current significant
technological and scientific challenges before these platforms can be widely
used. This paper surveys the state-of-the-art in software platforms for Smart
Cities. We analyzed 23 projects with respect to the most used enabling
technologies, as well as functional and non-functional requirements,
classifying them into four categories: Cyber-Physical Systems, Internet of
Things, Big Data, and Cloud Computing. Based on these results, we derived a
reference architecture to guide the development of next-generation software
platforms for Smart Cities. Finally, we enumerated the most frequently cited
open research challenges, and discussed future opportunities. This survey gives
important references for helping application developers, city managers, system
operators, end-users, and Smart City researchers to make project, investment,
and research decisions.
","Eduardo Felipe Zambom Santana|Ana Paula Chaves|Marco Aurelio Gerosa|Fabio Kon|Dejan Milojicic","","http://arxiv.org/abs/1609.08089v3","http://arxiv.org/pdf/1609.08089v3","http://dx.doi.org/10.1145/3124391","Accepted for publication in ACM Computing Surveys","","10.1145/3124391","cs.CY","cs.CY|cs.SE"
"153","1610.00873v1","2016-10-04 07:15:10","2016-10-04 07:15:10","Code Design for Short Blocks: A Survey","  The design of block codes for short information blocks (e.g., a thousand or
less information bits) is an open research problem which is gaining relevance
thanks to emerging applications in wireless communication networks. In this
work, we review some of the most recent code constructions targeting the short
block regime, and we compare then with both finite-length performance bounds
and classical error correction coding schemes. We will see how it is possible
to effectively approach the theoretical bounds, with different performance vs.
decoding complexity trade-offs.
","Gianluigi Liva|Lorenzo Gaudio|Tudor Ninacs|Thomas Jerkovits","","http://arxiv.org/abs/1610.00873v1","http://arxiv.org/pdf/1610.00873v1","","A preliminary version of this work was presented at the 25th Edition
  of the European Conference on Networks and Communications (EuCNC), June 2016.
  This version includes the performance of polar codes with list decoding and
  CRC","","","cs.IT","cs.IT|math.IT"
"154","1610.09465v2","2016-10-29 06:41:15","2017-02-14 14:19:09","Resource Management in Non-orthogonal Multiple Access Networks for 5G
  and Beyond","  Non-orthogonal multiple access (NOMA) schemes have been proposed for the next
generation of mobile communication systems to improve the access efficiency by
allowing multiple users to share the same spectrum in a non-orthogonal way. Due
to the strong co-channel interference among mobile users introduced by NOMA, it
poses significant challenges for system design and resource management. This
article reviews resource management issues in NOMA systems. The main taxonomy
of NOMA is presented by focusing on the following two categories: power-domain
NOMA and code-domain NOMA. Then a novel radio resource management framework is
presented based on game-theoretic models for uplink and downlink transmissions.
Finally, potential applications and open research directions in the area of
resource management for NOMA are provided.
","Lingyang Song|Yonghui Li|Zhiguo Ding|H. Vincent Poor","","http://arxiv.org/abs/1610.09465v2","http://arxiv.org/pdf/1610.09465v2","","15 pages, 3 figures, IEEE Network, 2017","","","cs.IT","cs.IT|math.IT"
"155","1701.03507v1","2016-11-11 15:56:58","2016-11-11 15:56:58","Beyond NGS data sharing and towards open science","  Biosciences have been revolutionized by next generation sequencing (NGS)
technologies in last years, leading to new perspectives in medical, industrial
and environmental applications. And although our motivation comes from
biosciences, the following is true for many areas of science: published results
are usually hard to reproduce either because data is not available or tools are
not readily available, which delays the adoption of new methodologies and
hinders innovation. Our focus is on tool readiness and pipelines availability.
Even though most tools are freely available, pipelines for data analysis are in
general barely described and their configuration is far from trivial, with many
parameters to be tuned.
  In this paper we discuss how to effectively build and use pipelines, relying
on state of the art computing technologies to execute them without users need
to configure, install and manage tools, servers and complex workflow management
systems. We perform an in depth comparative analysis of state of the art
frameworks and systems. The NGSPipes framework is proposed showing that we can
have public pipelines ready to process and analyse experimental data, produced
for instance by high-throughput technologies, but without relying on
centralized servers or Web services.
  The NGSPipes framework and underlying architecture provides a major step
towards open science and true collaboration in what concerns tools and
pipelines among computational biology researchers and practitioners. We show
that it is possible to execute data analysis pipelines in a decentralized and
platform independent way. Approaches like the one proposed are crucial for
archiving and reusing data analysis pipelines at medium/long-term. NGSPipes
framework is freely available at http://ngspipes.github.io/.
","Bruno Dantas|Calmenelias Fleitas|Alexandre P. Francisco|José Simão|Cátia Vaz","","http://arxiv.org/abs/1701.03507v1","http://arxiv.org/pdf/1701.03507v1","","19 pages, 10 figures","","","cs.DC","cs.DC|cs.SE"
"156","1611.04740v1","2016-11-15 08:45:24","2016-11-15 08:45:24","A Modal Logic of Supervenience","  Supervenience is an important philosophical concept. In this paper, inspired
by the supervenience-determined consequence relation and the semantics of
agreement operator, we introduce a modal logic of supervenience, which has a
dyadic operator of supervenience as a sole modality. The semantics of
supervenience modality is very natural to correspond to the
supervenience-determined consequence relation, in a quite similar way that the
strict implication corresponds to the inference-determined consequence
relation. We show that this new logic is more expressive than the modal logic
of agreement, by proposing a notion of bisimulation for the latter logic. We
provide a sound proof system for our new logic. We also lift on to more general
logics of supervenience. Related to this, we compare propositional logic of
determinacy and non-contingency in expressive powers, and give axiomatizations
of propositional logic of determinacy over various classes of frames, thereby
resolving an open research direction listed
in~\cite[Sec.~8.2]{Gorankoetal:2016}. As a corollary, we also present an
alternative axiomatization for propositional logic of determinacy over
universal models. We conclude with a lot of future work.
","Jie Fan","","http://arxiv.org/abs/1611.04740v1","http://arxiv.org/pdf/1611.04740v1","http://dx.doi.org/10.1215/00294527-2019-0006","29 pages","Notre Dame J. Formal Logic 60, no. 2 (2019), 283-309","10.1215/00294527-2019-0006","math.LO","math.LO|03B45"
"157","1611.05626v1","2016-11-17 10:23:44","2016-11-17 10:23:44","Towards Adaptive Compliance","  Mission critical software is often required to comply with multiple
regulations, standards or policies. Recent paradigms, such as cloud computing,
also require software to operate in heterogeneous, highly distributed, and
changing environments. In these environments, compliance requirements can vary
at runtime and traditional compliance management techniques, which are normally
applied at design time, may no longer be sufficient. In this paper, we motivate
the need for adaptive compliance by illustrating possible compliance concerns
determined by runtime variability. We further motivate our work by means of a
cloud computing scenario, and present two main contributions. First, we propose
and justify a process to support adaptive compliance that ex- tends the
traditional compliance management lifecycle with the activities of the
Monitor-Analyse-Plan-Execute (MAPE) loop, and enacts adaptation through
re-configuration. Second, we explore the literature on software compliance and
classify existing work in terms of the activities and concerns of adaptive
compliance. In this way, we determine how the literature can support our
proposal and what are the open research challenges that need to be addressed in
order to fully support adaptive compliance.
","Jesús García-Galán|Liliana Pasquale|George Grispos|Bashar Nuseibeh","","http://arxiv.org/abs/1611.05626v1","http://arxiv.org/pdf/1611.05626v1","http://dx.doi.org/10.1145/2897053.2897070","Position paper at SEAMS'16","","10.1145/2897053.2897070","cs.SE","cs.SE"
"158","1611.05910v1","2016-11-17 21:47:58","2016-11-17 21:47:58","Wirelessly Powered Urban Crowd Sensing over Wearables: Trading Energy
  for Data","  In this article, we put forward the mobile crowd sensing paradigm based on
ubiquitous wearable devices carried by human users. The key challenge for mass
user involvement into prospective urban crowd sending applications, such as
monitoring of large-scale phenomena (e.g., traffic congestion and air pollution
levels), is the appropriate sources of motivation. We thus advocate for the use
of wireless power transfer provided in exchange for sensed data to incentivize
the owners of wearables to participate in collaborative data collection. Based
on this construction, we develop the novel concept of wirelessly powered crowd
sensing and offer the corresponding network architecture considerations
together with a systematic review of wireless charging techniques to implement
it. Further, we contribute a detailed system-level feasibility study that
reports on the achievable performance levels for the envisioned setup. Finally,
the underlying energy-data trading mechanisms are discussed, and the work is
concluded with outlining open research opportunities.
","Olga Galinina|Konstantin Mikhaylov|Kaibin Huang|Sergey Andreev|Yevgeni Koucheryavy","","http://arxiv.org/abs/1611.05910v1","http://arxiv.org/pdf/1611.05910v1","","8 pages, 5 figures","","","cs.NI","cs.NI"
"159","1611.06203v2","2016-11-18 19:32:03","2019-02-01 09:08:25","Ear Recognition: More Than a Survey","  Automatic identity recognition from ear images represents an active field of
research within the biometric community. The ability to capture ear images from
a distance and in a covert manner makes the technology an appealing choice for
surveillance and security applications as well as other application domains.
Significant contributions have been made in the field over recent years, but
open research problems still remain and hinder a wider (commercial) deployment
of the technology. This paper presents an overview of the field of automatic
ear recognition (from 2D images) and focuses specifically on the most recent,
descriptor-based methods proposed in this area. Open challenges are discussed
and potential research directions are outlined with the goal of providing the
reader with a point of reference for issues worth examining in the future. In
addition to a comprehensive review on ear recognition technology, the paper
also introduces a new, fully unconstrained dataset of ear images gathered from
the web and a toolbox implementing several state-of-the-art techniques for ear
recognition. The dataset and toolbox are meant to address some of the open
issues in the field and are made publicly available to the research community.
","Žiga Emeršič|Vitomir Štruc|Peter Peer","","http://arxiv.org/abs/1611.06203v2","http://arxiv.org/pdf/1611.06203v2","","17 pages, paper accepted to Neurocomputing","","","cs.CV","cs.CV"
"160","1611.07245v2","2016-11-22 10:51:43","2017-06-27 09:37:04","Single-View and Multi-View Depth Fusion","  Dense and accurate 3D mapping from a monocular sequence is a key technology
for several applications and still an open research area. This paper leverages
recent results on single-view CNN-based depth estimation and fuses them with
multi-view depth estimation. Both approaches present complementary strengths.
Multi-view depth is highly accurate but only in high-texture areas and
high-parallax cases. Single-view depth captures the local structure of
mid-level regions, including texture-less areas, but the estimated depth lacks
global coherence. The single and multi-view fusion we propose is challenging in
several aspects. First, both depths are related by a deformation that depends
on the image content. Second, the selection of multi-view points of high
accuracy might be difficult for low-parallax configurations. We present
contributions for both problems. Our results in the public datasets of NYUv2
and TUM shows that our algorithm outperforms the individual single and
multi-view approaches. A video showing the key aspects of mapping in our Single
and Multi-view depth proposal is available at https://youtu.be/ipc5HukTb4k
","José M. Fácil|Alejo Concha|Luis Montesano|Javier Civera","","http://arxiv.org/abs/1611.07245v2","http://arxiv.org/pdf/1611.07245v2","http://dx.doi.org/10.1109/LRA.2017.2715400","Accepted for publication in IEEE Robotics and Automation Letters","","10.1109/LRA.2017.2715400","cs.CV","cs.CV|cs.RO"
"161","1612.01835v4","2016-12-06 14:53:06","2019-10-17 17:36:02","Sub-Linear Privacy-Preserving Near-Neighbor Search","  In Near-Neighbor Search (NNS), a new client queries a database (held by a
server) for the most similar data (near-neighbors) given a certain similarity
metric. The Privacy-Preserving variant (PP-NNS) requires that neither server
nor the client shall learn information about the other party's data except what
can be inferred from the outcome of NNS. The overwhelming growth in the size of
current datasets and the lack of a truly secure server in the online world
render the existing solutions impractical; either due to their high
computational requirements or non-realistic assumptions which potentially
compromise privacy. PP-NNS having query time {\it sub-linear} in the size of
the database has been suggested as an open research direction by Li et al.
(CCSW'15). In this paper, we provide the first such algorithm, called Secure
Locality Sensitive Indexing (SLSI) which has a sub-linear query time and the
ability to handle honest-but-curious parties. At the heart of our proposal lies
a secure binary embedding scheme generated from a novel probabilistic
transformation over locality sensitive hashing family. We provide information
theoretic bound for the privacy guarantees and support our theoretical claims
using substantial empirical evidence on real-world datasets.
","M. Sadegh Riazi|Beidi Chen|Anshumali Shrivastava|Dan Wallach|Farinaz Koushanfar","","http://arxiv.org/abs/1612.01835v4","http://arxiv.org/pdf/1612.01835v4","","","","","cs.CR","cs.CR|cs.DB|cs.IR"
"162","1612.03184v2","2016-12-09 21:22:21","2017-04-11 01:08:38","Collaborative Mobile Edge Computing in 5G Networks: New Paradigms,
  Scenarios, and Challenges","  Mobile Edge Computing (MEC) is an emerging paradigm that provides computing,
storage, and networking resources within the edge of the mobile Radio Access
Network (RAN). MEC servers are deployed on generic computing platform within
the RAN and allow for delay-sensitive and context-aware applications to be
executed in close proximity to the end users. This approach alleviates the
backhaul and core network and is crucial for enabling low-latency,
high-bandwidth, and agile mobile services. This article envisages a real-time,
context-aware collaboration framework that lies at the edge of the RAN,
constituted of MEC servers and mobile devices, and that amalgamates the
heterogeneous resources at the edge. Specifically, we introduce and study three
strong use cases ranging from mobile-edge orchestration, collaborative caching
and processing and multi-layer interference cancellation. We demonstrate the
promising benefits of these approaches in facilitating the evolution to 5G
networks. Finally, we discuss the key technical challenges and open-research
issues that need to be addressed in order to make an efficient integration of
MEC into 5G ecosystem.
","Tuyen X. Tran|Abolfazl Hajisami|Parul Pandey|Dario Pompili","","http://arxiv.org/abs/1612.03184v2","http://arxiv.org/pdf/1612.03184v2","","Accepted for publication on IEEE Communications Magazine, Special
  Issue on Fog Computing and Networking, April 2017","","","cs.NI","cs.NI"
"163","1612.03744v1","2016-12-12 15:24:45","2016-12-12 15:24:45","Fault Attacks on Encrypted General Purpose Compute Platforms","  Adversaries with physical access to a target platform can perform cold boot
or DMA attacks to extract sensitive data from the RAM. In response, several
main-memory encryption schemes have been proposed to prevent such attacks. Also
hardware vendors have acknowledged the threat and already announced respective
hardware extensions. Intel's SGX and AMD's SME will provide means to encrypt
parts of the RAM to protect security-relevant assets that reside there.
Encrypting the RAM will protect the user's content against passive
eavesdropping. However, the level of protection it provides in scenarios that
involve an adversary who is not only able to read from RAM but can also change
content in RAM is less clear. Obviously, encryption offers some protection
against such an ""active"" adversary: from the ciphertext the adversary cannot
see what value is changed in the plaintext, nor predict the system behaviour
based on the changes. But is this enough to prevent an active adversary from
performing malicious tasks? This paper addresses the open research question
whether encryption alone is a dependable protection mechanism in practice when
considering an active adversary. To this end, we first build a software based
memory encryption solution on a desktop system which mimics AMD's SME.
Subsequently, we demonstrate a proof-of-concept fault attack on this system, by
which we are able to extract the private RSA key of a GnuPG user. Our work
suggests that transparent memory encryption is not enough to prevent active
attacks.
","Robert Buhren|Shay Gueron|Jan Nordholz|Jean-Pierre Seifert|Julian Vetter","","http://arxiv.org/abs/1612.03744v1","http://arxiv.org/pdf/1612.03744v1","","","","","cs.CR","cs.CR"
"164","1612.07947v1","2016-12-23 12:03:29","2016-12-23 12:03:29","TCP SIAD: Congestion Control supporting High Speed and Low Latency","  Congestion control has been an open research issue for more than two decades.
More and more applications with narrow latency requirements are emerging which
are not well addressed by existing proposals. In this paper we present TCP
Scalable Increase Adaptive Decrease (SIAD), a new congestion control scheme
supporting both high speed and low latency. More precisely, our algorithm aims
to provide high utilization under various networking conditions, and therefore
would allow operators to configure small buffers for low latency support. To
provide full scalability with high speed networks, we designed TCP SIAD based
on a new approach that aims for a fixed feedback rate independent of the
available bandwidth. Further, our approach provides a configuration knob for
the feedback rate. This can be used by a higher layer control loop to impact
the capacity share, potentially at the cost of higher congestion, e.g. for
applications that need a minimum rate.
  We evaluated TCP SIAD against well-known high-speed congestion control
schemes, such as Scalable TCP and High Speed TCP, as well as H-TCP that among
other goals targets small buffers. We show that only SIAD is able to utilize
the bottleneck with arbitrary buffer sizes while avoiding a standing queue.
Moreover, we demonstrate the capacity sharing of SIAD depending on the
configured feedback rate and a high robustness of TCP SIAD to non-congestion
related loss.
","Mirja Kuehlewind","","http://arxiv.org/abs/1612.07947v1","http://arxiv.org/pdf/1612.07947v1","","","","","cs.NI","cs.NI"
"165","1701.03904v1","2017-01-14 11:23:12","2017-01-14 11:23:12","The Passive Eavesdropper Affects my Channel: Secret-Key Rates under
  Real-World Conditions (Extended Version)","  Channel-reciprocity based key generation (CRKG) has gained significant
importance as it has recently been proposed as a potential lightweight security
solution for IoT devices. However, the impact of the attacker's position in
close range has only rarely been evaluated in practice, posing an open research
problem about the security of real-world realizations. Furthermore, this would
further bridge the gap between theoretical channel models and their
practice-oriented realizations. For security metrics, we utilize
cross-correlation, mutual information, and a lower bound on secret-key
capacity. We design a practical setup of three parties such that the channel
statistics, although based on joint randomness, are always reproducible. We run
experiments to obtain channel states and evaluate the aforementioned metrics
for the impact of an attacker depending on his position. It turns out the
attacker himself affects the outcome, which has not been adequately regarded
yet in standard channel models.
","Christan Zenger|Hendrik Vogt|Jan Zimmer|Aydin Sezgin|Christof Paar","","http://arxiv.org/abs/1701.03904v1","http://arxiv.org/pdf/1701.03904v1","","Full measurement in Appendix","","","cs.IT","cs.IT|cs.CR|math.IT"
"166","1701.07179v3","2017-01-25 06:46:14","2019-08-21 10:38:24","Malicious URL Detection using Machine Learning: A Survey","  Malicious URL, a.k.a. malicious website, is a common and serious threat to
cybersecurity. Malicious URLs host unsolicited content (spam, phishing,
drive-by exploits, etc.) and lure unsuspecting users to become victims of scams
(monetary loss, theft of private information, and malware installation), and
cause losses of billions of dollars every year. It is imperative to detect and
act on such threats in a timely manner. Traditionally, this detection is done
mostly through the usage of blacklists. However, blacklists cannot be
exhaustive, and lack the ability to detect newly generated malicious URLs. To
improve the generality of malicious URL detectors, machine learning techniques
have been explored with increasing attention in recent years. This article aims
to provide a comprehensive survey and a structural understanding of Malicious
URL Detection techniques using machine learning. We present the formal
formulation of Malicious URL Detection as a machine learning task, and
categorize and review the contributions of literature studies that addresses
different dimensions of this problem (feature representation, algorithm design,
etc.). Further, this article provides a timely and comprehensive survey for a
range of different audiences, not only for machine learning researchers and
engineers in academia, but also for professionals and practitioners in
cybersecurity industry, to help them understand the state of the art and
facilitate their own research and practical applications. We also discuss
practical issues in system design, open research challenges, and point out some
important directions for future research.
","Doyen Sahoo|Chenghao Liu|Steven C. H. Hoi","","http://arxiv.org/abs/1701.07179v3","http://arxiv.org/pdf/1701.07179v3","","","","","cs.LG","cs.LG|cs.CR"
"167","1702.00187v1","2017-02-01 10:15:13","2017-02-01 10:15:13","ImageNet MPEG-7 Visual Descriptors - Technical Report","  ImageNet is a large scale and publicly available image database. It currently
offers more than 14 millions of images, organised according to the WordNet
hierarchy. One of the main objective of the creators is to provide to the
research community a relevant database for visual recognition applications such
as object recognition, image classification or object localisation. However,
only a few visual descriptors of the images are available to be used by the
researchers. Only SIFT-based features have been extracted from a subset of the
collection. This technical report presents the extraction of some MPEG-7 visual
descriptors from the ImageNet database. These descriptors are made publicly
available in an effort towards open research.
","Frédéric Rayar","","http://arxiv.org/abs/1702.00187v1","http://arxiv.org/pdf/1702.00187v1","","","","","cs.CV","cs.CV|cs.IR"
"168","1702.01444v1","2017-02-05 19:23:59","2017-02-05 19:23:59","Printed Arabic Text Recognition using Linear and Nonlinear Regression","  Arabic language is one of the most popular languages in the world. Hundreds
of millions of people in many countries around the world speak Arabic as their
native speaking. However, due to complexity of Arabic language, recognition of
printed and handwritten Arabic text remained untouched for a very long time
compared with English and Chinese. Although, in the last few years, significant
number of researches has been done in recognizing printed and handwritten
Arabic text, it stills an open research field due to cursive nature of Arabic
script. This paper proposes automatic printed Arabic text recognition technique
based on linear and ellipse regression techniques. After collecting all
possible forms of each character, unique code is generated to represent each
character form. Each code contains a sequence of lines and ellipses. To
recognize fonts, a unique list of codes is identified to be used as a
fingerprint of font. The proposed technique has been evaluated using over 14000
different Arabic words with different fonts and experimental results show that
average recognition rate of the proposed technique is 86%.
","Ashraf A. Shahin","","http://arxiv.org/abs/1702.01444v1","http://arxiv.org/pdf/1702.01444v1","http://dx.doi.org/10.14569/IJACSA.2017.080129","http://thesai.org/Downloads/Volume8No1/Paper_29-Printed_Arabic_Text_Recognition_using_Linear.pdf","International Journal of Advanced Computer Science and
  Applications(IJACSA), 8(1), 2017","10.14569/IJACSA.2017.080129","cs.CV","cs.CV"
"169","1702.04565v1","2017-02-15 11:57:57","2017-02-15 11:57:57","The Accuracy-Privacy Tradeoff of Mobile Crowdsensing","  Mobile crowdsensing has emerged as an efficient sensing paradigm which
combines the crowd intelligence and the sensing power of mobile devices,
e.g.,~mobile phones and Internet of Things (IoT) gadgets. This article
addresses the contradicting incentives of privacy preservation by crowdsensing
users and accuracy maximization and collection of true data by service
providers. We firstly define the individual contributions of crowdsensing users
based on the accuracy in data analytics achieved by the service provider from
buying their data. We then propose a truthful mechanism for achieving high
service accuracy while protecting the privacy based on the user preferences.
The users are incentivized to provide true data by being paid based on their
individual contribution to the overall service accuracy. Moreover, we propose a
coalition strategy which allows users to cooperate in providing their data
under one identity, increasing their anonymity privacy protection, and sharing
the resulting payoff. Finally, we outline important open research directions in
mobile and people-centric crowdsensing.
","Mohammad Abu Alsheikh|Yutao Jiao|Dusit Niyato|Ping Wang|Derek Leong|Zhu Han","","http://arxiv.org/abs/1702.04565v1","http://arxiv.org/pdf/1702.04565v1","","8 pages, 5 figures","","","cs.NI","cs.NI"
"170","1702.04855v1","2017-02-16 04:20:31","2017-02-16 04:20:31","Open Science, Public Engagement and the University","  Contemporary debates on ""open science"" mostly focus on the pub- lic
accessibility of the products of scientific and academic work. In contrast,
this paper presents arguments for ""opening"" the ongoing work of science. That
is, this paper is an invitation to rethink the university with an eye toward
engaging the public in the dynamic, conceptual and representational work
involved in creating scientific knowledge. To this end, we posit that public
computing spaces, a genre of open- ended, public learning environment where
visitors interact with open source computing platforms to directly access,
modify and create complex and authentic scientific work, can serve as a
possible model of ""open science"" in the university.
","Pratim Sengupta|Marie-Claire Shanahan","","http://arxiv.org/abs/1702.04855v1","http://arxiv.org/pdf/1702.04855v1","","This is a white paper commissioned by the NSF and NIH funded
  conference: http: //www.ncsa.illinois.edu/Conferences/ImagineU/","","","physics.ed-ph","physics.ed-ph"
"171","1702.05309v2","2017-02-17 11:50:38","2017-03-13 12:27:34","Mobile Edge Computing: A Survey on Architecture and Computation
  Offloading","  Technological evolution of mobile user equipments (UEs), such as smartphones
or laptops, goes hand-in-hand with evolution of new mobile applications.
However, running computationally demanding applications at the UEs is
constrained by limited battery capacity and energy consumption of the UEs.
Suitable solution extending the battery life-time of the UEs is to offload the
applications demanding huge processing to a conventional centralized cloud
(CC). Nevertheless, this option introduces significant execution delay
consisting in delivery of the offloaded applications to the cloud and back plus
time of the computation at the cloud. Such delay is inconvenient and make the
offloading unsuitable for real-time applications. To cope with the delay
problem, a new emerging concept, known as mobile edge computing (MEC), has been
introduced. The MEC brings computation and storage resources to the edge of
mobile network enabling to run the highly demanding applications at the UE
while meeting strict delay requirements. The MEC computing resources can be
exploited also by operators and third parties for specific purposes. In this
paper, we first describe major use cases and reference scenarios where the MEC
is applicable. After that we survey existing concepts integrating MEC
functionalities to the mobile networks and discuss current advancement in
standardization of the MEC. The core of this survey is, then, focused on
user-oriented use case in the MEC, i.e., computation offloading. In this
regard, we divide the research on computation offloading to three key areas: i)
decision on computation offloading, ii) allocation of computing resource within
the MEC, and iii) mobility management. Finally, we highlight lessons learned in
area of the MEC and we discuss open research challenges yet to be addressed in
order to fully enjoy potentials offered by the MEC.
","Pavel Mach|Zdenek Becvar","","http://arxiv.org/abs/1702.05309v2","http://arxiv.org/pdf/1702.05309v2","http://dx.doi.org/10.1109/COMST.2017.2682318","28 pages, 21 figures, Accepted for publication in IEEE Communications
  Surveys and Tutorials","","10.1109/COMST.2017.2682318","cs.IT","cs.IT|cs.NI|math.IT"
"172","1702.07560v1","2017-02-24 12:49:29","2017-02-24 12:49:29","RNN Decoding of Linear Block Codes","  Designing a practical, low complexity, close to optimal, channel decoder for
powerful algebraic codes with short to moderate block length is an open
research problem. Recently it has been shown that a feed-forward neural network
architecture can improve on standard belief propagation decoding, despite the
large example space. In this paper we introduce a recurrent neural network
architecture for decoding linear block codes. Our method shows comparable bit
error rate results compared to the feed-forward neural network with
significantly less parameters. We also demonstrate improved performance over
belief propagation on sparser Tanner graph representations of the codes.
Furthermore, we demonstrate that the RNN decoder can be used to improve the
performance or alternatively reduce the computational complexity of the mRRD
algorithm for low complexity, close to optimal, decoding of short BCH codes.
","Eliya Nachmani|Elad Marciano|David Burshtein|Yair Be'ery","","http://arxiv.org/abs/1702.07560v1","http://arxiv.org/pdf/1702.07560v1","","","","","cs.IT","cs.IT|cs.LG|cs.NE|math.IT"
"173","1702.07680v1","2017-02-24 17:40:28","2017-02-24 17:40:28","Consistent Alignment of Word Embedding Models","  Word embedding models offer continuous vector representations that can
capture rich contextual semantics based on their word co-occurrence patterns.
While these word vectors can provide very effective features used in many NLP
tasks such as clustering similar words and inferring learning relationships,
many challenges and open research questions remain. In this paper, we propose a
solution that aligns variations of the same model (or different models) in a
joint low-dimensional latent space leveraging carefully generated synthetic
data points. This generative process is inspired by the observation that a
variety of linguistic relationships is captured by simple linear operations in
embedded space. We demonstrate that our approach can lead to substantial
improvements in recovering embeddings of local neighborhoods.
","Cem Safak Sahin|Rajmonda S. Caceres|Brandon Oselio|William M. Campbell","","http://arxiv.org/abs/1702.07680v1","http://arxiv.org/pdf/1702.07680v1","","4 pages, 2 figures","","","cs.CL","cs.CL|cs.IR|stat.ML"
"174","1703.02664v2","2017-03-08 01:48:58","2017-05-15 02:03:59","Software Defined Space-Air-Ground Integrated Vehicular Networks:
  Challenges and Solutions","  This article proposes a software defined space-air-ground integrated network
architecture for supporting diverse vehicular services in a seamless,
efficient, and cost-effective manner. Firstly, the motivations and challenges
for integration of space-air-ground networks are reviewed. Secondly, a software
defined network architecture with a layered structure is presented. To protect
the legacy services in satellite, aerial, and territorial segments, resources
in each segment are sliced through network slicing to achieve service
isolation. Then, available resources are put into a common and dynamic
space-air-ground resource pool, which is managed by hierarchical controllers to
accommodate vehicular services. Finally, a case study is carried out, followed
by discussion on some open research topics.
","Ning Zhang|Shan Zhang|Peng Yang|Omar Alhussein|Weihua Zhuang|Xuemin Shen","","http://arxiv.org/abs/1703.02664v2","http://arxiv.org/pdf/1703.02664v2","","to appear in IEEE Communications Magazine","","","cs.NI","cs.NI"
"175","1703.03187v1","2017-03-09 09:17:47","2017-03-09 09:17:47","The unexpected resurgence of Weyl geometry in late 20-th century physics","  Weyl's original scale geometry of 1918 (""purely infinitesimal geometry"") was
withdrawn by its author from physical theorizing in the early 1920s. It had a
comeback in the last third of the 20th century in different contexts: scalar
tensor theories of gravity, foundations of gravity, foundations of quantum
mechanics, elementary particle physics, and cosmology. It seems that Weyl
geometry continues to offer an open research potential for the foundations of
physics even after the turn to the new millennium.
","Erhard Scholz","","http://arxiv.org/abs/1703.03187v1","http://arxiv.org/pdf/1703.03187v1","","Completely rewritten conference paper 'Beyond Einstein', Mainz Sep
  2008. Preprint ELHC (Epistemology of the LHC) 2017-02, 92 pages, 1 figure","","","math.HO","math.HO|gr-qc|physics.hist-ph"
"176","1703.03861v1","2017-03-10 22:41:51","2017-03-10 22:41:51","Building automated vandalism detection tools for Wikidata","  Wikidata, like Wikipedia, is a knowledge base that anyone can edit. This open
collaboration model is powerful in that it reduces barriers to participation
and allows a large number of people to contribute. However, it exposes the
knowledge base to the risk of vandalism and low-quality contributions. In this
work, we build on past work detecting vandalism in Wikipedia to detect
vandalism in Wikidata. This work is novel in that identifying damaging changes
in a structured knowledge-base requires substantially different feature
engineering work than in a text-based wiki like Wikipedia. We also discuss the
utility of these classifiers for reducing the overall workload of vandalism
patrollers in Wikidata. We describe a machine classification strategy that is
able to catch 89% of vandalism while reducing patrollers' workload by 98%, by
drawing lightly from contextual features of an edit and heavily from the
characteristics of the user making the edit.
","Amir Sarabadani|Aaron Halfaker|Dario Taraborelli","","http://arxiv.org/abs/1703.03861v1","http://arxiv.org/pdf/1703.03861v1","http://dx.doi.org/10.1145/3041021.3053366","","","10.1145/3041021.3053366","cs.IR","cs.IR|cs.CY"
"177","1703.04676v2","2017-03-14 19:10:32","2017-05-01 20:44:49","Network Slicing for 5G with SDN/NFV: Concepts, Architectures and
  Challenges","  The fifth generation of mobile communications is anticipated to open up
innovation opportunities for new industries such as vertical markets. However,
these verticals originate myriad use cases with diverging requirements that
future 5G networks have to efficiently support. Network slicing may be a
natural solution to simultaneously accommodate over a common network
infrastructure the wide range of services that vertical-specific use cases will
demand. In this article, we present the network slicing concept, with a
particular focus on its application to 5G systems. We start by summarizing the
key aspects that enable the realization of so-called network slices. Then, we
give a brief overview on the SDN architecture proposed by the ONF and show that
it provides tools to support slicing. We argue that although such architecture
paves the way for network slicing implementation, it lacks some essential
capabilities that can be supplied by NFV. Hence, we analyze a proposal from the
ETSI to incorporate the capabilities of SDN into the NFV architecture.
Additionally, we present an example scenario that combines SDN and NFV
technologies to address the realization of network slices. Finally, we
summarize the open research issues with the purpose of motivating new advances
in this field.
","Jose Ordonez-Lucena|Pablo Ameigeiras|Diego Lopez|Juan J. Ramos-Munoz|Javier Lorca|Jesus Folgueira","","http://arxiv.org/abs/1703.04676v2","http://arxiv.org/pdf/1703.04676v2","http://dx.doi.org/10.1109/MCOM.2017.1600935","","","10.1109/MCOM.2017.1600935","cs.NI","cs.NI"
"178","1703.09343v1","2017-03-27 23:36:02","2017-03-27 23:36:02","Discovering Scholarly Orphans Using ORCID","  Archival efforts such as (C)LOCKSS and Portico are in place to ensure the
longevity of traditional scholarly resources like journal articles. At the same
time, researchers are depositing a broad variety of other scholarly artifacts
into emerging online portals that are designed to support web-based
scholarship. These web-native scholarly objects are largely neglected by
current archival practices and hence they become scholarly orphans. We
therefore argue for a novel paradigm that is tailored towards archiving these
scholarly orphans. We are investigating the feasibility of using Open
Researcher and Contributor ID (ORCID) as a supporting infrastructure for the
process of discovery of web identities and scholarly orphans for active
researchers. We analyze ORCID in terms of coverage of researchers, subjects,
and location and assess the richness of its profiles in terms of web identities
and scholarly artifacts. We find that ORCID currently lacks in all considered
aspects and hence can only be considered in conjunction with other discovery
sources. However, ORCID is growing fast so there is potential that it could
achieve a satisfactory level of coverage and richness in the near future.
","Martin Klein|Herbert Van de Sompel","","http://arxiv.org/abs/1703.09343v1","http://arxiv.org/pdf/1703.09343v1","","10 pages, 5 figures, 5 tables accepted for publication at JCDL 2017","","","cs.DL","cs.DL"
"179","1703.09809v1","2017-03-28 21:22:02","2017-03-28 21:22:02","Understanding IoT Security Through the Data Crystal Ball: Where We Are
  Now and Where We Are Going to Be","  Inspired by the boom of the consumer IoT market, many device manufacturers,
start-up companies and technology giants have jumped into the space.
Unfortunately, the exciting utility and rapid marketization of IoT, come at the
expense of privacy and security. Industry reports and academic work have
revealed many attacks on IoT systems, resulting in privacy leakage, property
loss and large-scale availability problems. To mitigate such threats, a few
solutions have been proposed. However, it is still less clear what are the
impacts they can have on the IoT ecosystem. In this work, we aim to perform a
comprehensive study on reported attacks and defenses in the realm of IoT aiming
to find out what we know, where the current studies fall short and how to move
forward. To this end, we first build a toolkit that searches through massive
amount of online data using semantic analysis to identify over 3000 IoT-related
articles. Further, by clustering such collected data using machine learning
technologies, we are able to compare academic views with the findings from
industry and other sources, in an attempt to understand the gaps between them,
the trend of the IoT security risks and new problems that need further
attention. We systemize this process, by proposing a taxonomy for the IoT
ecosystem and organizing IoT security into five problem areas. We use this
taxonomy as a beacon to assess each IoT work across a number of properties we
define. Our assessment reveals that relevant security and privacy problems are
far from solved. We discuss how each proposed solution can be applied to a
problem area and highlight their strengths, assumptions and constraints. We
stress the need for a security framework for IoT vendors and discuss the trend
of shifting security liability to external or centralized entities. We also
identify open research problems and provide suggestions towards a secure IoT
ecosystem.
","Nan Zhang|Soteris Demetriou|Xianghang Mi|Wenrui Diao|Kan Yuan|Peiyuan Zong|Feng Qian|XiaoFeng Wang|Kai Chen|Yuan Tian|Carl A. Gunter|Kehuan Zhang|Patrick Tague|Yue-Hsun Lin","","http://arxiv.org/abs/1703.09809v1","http://arxiv.org/pdf/1703.09809v1","","","","","cs.CR","cs.CR"
"180","1703.09875v2","2017-03-29 03:45:26","2017-05-15 01:59:11","Base Station ON-OFF Switching in 5G Wireless Networks: Approaches and
  Challenges","  To achieve the expected 1000x data rates under the exponential growth of
traffic demand, a large number of base stations (BS) or access points (AP) will
be deployed in the fifth generation (5G) wireless systems, to support high data
rate services and to provide seamless coverage. Although such BSs are expected
to be small-scale with lower power, the aggregated energy consumption of all
BSs would be remarkable, resulting in increased environmental and economic
concerns. In existing cellular networks, turning off the under-utilized BSs is
an efficient approach to conserve energy while preserving the quality of
service (QoS) of mobile users. However, in 5G systems with new physical layer
techniques and the highly heterogeneous network architecture, new challenges
arise in the design of BS ON-OFF switching strategies. In this article, we
begin with a discussion on the inherent technical challenges of BS ON-OFF
switching. We then provide a comprehensive review of recent advances on
switching mechanisms in different application scenarios. Finally, we present
open research problems and conclude the paper.
","Mingjie Feng|Shiwen Mao|Tao Jiang","","http://arxiv.org/abs/1703.09875v2","http://arxiv.org/pdf/1703.09875v2","http://dx.doi.org/10.1109/MWC.2017.1600353","Appear to IEEE Wireless Communications, 2017","","10.1109/MWC.2017.1600353","cs.NI","cs.NI"
"181","1703.10750v1","2017-03-31 03:55:30","2017-03-31 03:55:30","A Survey on Mobile Edge Networks: Convergence of Computing, Caching and
  Communications","  As the explosive growth of smart devices and the advent of many new
applications, traffic volume has been growing exponentially. The traditional
centralized network architecture cannot accommodate such user demands due to
heavy burden on the backhaul links and long latency. Therefore, new
architectures which bring network functions and contents to the network edge
are proposed, i.e., mobile edge computing and caching. Mobile edge networks
provide cloud computing and caching capabilities at the edge of cellular
networks. In this survey, we make an exhaustive review on the state-of-the-art
research efforts on mobile edge networks. We first give an overview of mobile
edge networks including definition, architecture and advantages. Next, a
comprehensive survey of issues on computing, caching and communication
techniques at the network edge is presented respectively. The applications and
use cases of mobile edge networks are discussed. Subsequently, the key enablers
of mobile edge networks such as cloud technology, SDN/NFV and smart devices are
discussed. Finally, open research challenges and future directions are
presented as well.
","Shuo Wang|Xing Zhang|Yan Zhang|Lin Wang|Juwo Yang|Wenbo Wang","","http://arxiv.org/abs/1703.10750v1","http://arxiv.org/pdf/1703.10750v1","http://dx.doi.org/10.1109/ACCESS.2017.2685434","","IEEE Access , vol.PP, no.99, pp.1-1, 2017","10.1109/ACCESS.2017.2685434","cs.NI","cs.NI"
"182","1704.01247v1","2017-04-05 02:44:59","2017-04-05 02:44:59","Software Defined Networking Enabled Wireless Network Virtualization:
  Challenges and Solutions","  Next generation (5G) wireless networks are expected to support the massive
data and accommodate a wide range of services/use cases with distinct
requirements in a cost-effective, flexible, and agile manner. As a promising
solution, wireless network virtualization (WNV), or network slicing, enables
multiple virtual networks to share the common infrastructure on demand, and to
be customized for different services/use cases. This article focuses on
network-wide resource allocation for realizing WNV. Specifically, the
motivations, the enabling platforms, and the benefits of WNV, are first
reviewed. Then, resource allocation for WNV along with the technical challenges
is discussed. Afterwards, a software defined networking (SDN) enabled resource
allocation framework is proposed to facilitate WNV, including the key
procedures and the corresponding modeling approaches. Furthermore, a case study
is provided as an example of resource allocation in WNV. Finally, some open
research topics essential to WNV are discussed.
","Ning Zhang|Peng Yang|Shan Zhang|Dajiang Chen|Weihua Zhuang|Ben Liang| Xuemin| Shen","Sherman|Sherman|Sherman|Sherman|Sherman|Sherman|Sherman|","http://arxiv.org/abs/1704.01247v1","http://arxiv.org/pdf/1704.01247v1","","16 pages, 5 figures. To appear in IEEE Network Magazine","","","cs.NI","cs.NI"
"183","1704.05432v1","2017-04-18 17:21:39","2017-04-18 17:21:39","Reverse Engineering of Communications Networks: Evolution and Challenges","  Reverse engineering of a communications network is the process of identifying
the communications protocol used in the network. This problem arises in various
situations such as eavesdropping, intelligent jamming, cognitive radio, and
adaptive coding and modulation (ACM). According to the Open Systems
Interconnection (OSI) reference model, the first step in reverse engineering of
communications networks is recognition of physical layer which consists of
recognition of digital modulations and identification of physical layer
transmission techniques. The next step is recognition of data link layer
(consisting of frame synchronization, recognition of channel codes,
reconstruction of interleavers, reconstruction of scramblers, etc.) and also
recognition of network and transport layers. The final step in reverse
engineering of communications networks is recognition of upper layers which
essentially can be seen as identification of source encoders. The objective of
this paper is to provide a comprehensive overview on the current methods for
reverse engineering of communications networks. Furthermore, challenges and
open research issues in this field are introduced.
","Mehdi Teimouri|Hamidreza Kakaei Motlagh","","http://arxiv.org/abs/1704.05432v1","http://arxiv.org/pdf/1704.05432v1","","18 pages, 9 figures","","","cs.IT","cs.IT|math.IT"
"184","1704.06825v1","2017-04-22 17:49:04","2017-04-22 17:49:04","Deep Learning for Medical Image Processing: Overview, Challenges and
  Future","  Healthcare sector is totally different from other industry. It is on high
priority sector and people expect highest level of care and services regardless
of cost. It did not achieve social expectation even though it consume huge
percentage of budget. Mostly the interpretations of medical data is being done
by medical expert. In terms of image interpretation by human expert, it is
quite limited due to its subjectivity, the complexity of the image, extensive
variations exist across different interpreters, and fatigue. After the success
of deep learning in other real world application, it is also providing exciting
solutions with good accuracy for medical imaging and is seen as a key method
for future applications in health secotr. In this chapter, we discussed state
of the art deep learning architecture and its optimization used for medical
image segmentation and classification. In the last section, we have discussed
the challenges deep learning based methods for medical imaging and open
research issue.
","Muhammad Imran Razzak|Saeeda Naz|Ahmad Zaib","","http://arxiv.org/abs/1704.06825v1","http://arxiv.org/pdf/1704.06825v1","","","","","cs.CV","cs.CV"
"185","1704.07621v1","2017-04-25 10:38:14","2017-04-25 10:38:14","Optical Non-Orthogonal Multiple Access for Visible Light Communication","  The proliferation of mobile Internet and connected devices, offering a
variety of services at different levels of performance, represents a major
challenge for the fifth generation wireless networks and beyond. This requires
a paradigm shift towards the development of key enabling techniques for the
next generation wireless networks. In this respect, visible light communication
(VLC) has recently emerged as a new communication paradigm that is capable of
providing ubiquitous connectivity by complementing radio frequency
communications. One of the main challenges of VLC systems, however, is the low
modulation bandwidth of the light-emitting-diodes, which is in the megahertz
range. This article presents a promising technology, referred to as ""optical-
non-orthogonal multiple access (O-NOMA)"", which is envisioned to address the
key challenges in the next generation of wireless networks. We provide a
detailed overview and analysis of the state-of-the-art integration of O-NOMA in
VLC networks. Furthermore, we provide insights on the potential opportunities
and challenges as well as some open research problems that are envisioned to
pave the way for the future design and implementation of O-NOMA in VLC systems.
","Hanaa Marshoud|Sami Muhaidat|Paschalis C. Sofotasios|Sajjad Hussain|Muhammad Ali Imran|Bayan S. Sharif","","http://arxiv.org/abs/1704.07621v1","http://arxiv.org/pdf/1704.07621v1","","","","","cs.IT","cs.IT|math.IT"
"186","1705.03666v1","2017-05-10 08:55:55","2017-05-10 08:55:55","Hybrid PDE solver for data-driven problems and modern branching","  The numerical solution of large-scale PDEs, such as those occurring in
data-driven applications, unavoidably require powerful parallel computers and
tailored parallel algorithms to make the best possible use of them. In fact,
considerations about the parallelization and scalability of realistic problems
are often critical enough to warrant acknowledgement in the modelling phase.
The purpose of this paper is to spread awareness of the Probabilistic Domain
Decomposition (PDD) method, a fresh approach to the parallelization of PDEs
with excellent scalability properties. The idea exploits the stochastic
representation of the PDE and its approximation via Monte Carlo in combination
with deterministic high-performance PDE solvers. We describe the ingredients of
PDD and its applicability in the scope of data science. In particular, we
highlight recent advances in stochastic representations for nonlinear PDEs
using branching diffusions, which have significantly broadened the scope of
PDD.
  We envision this work as a dictionary giving large-scale PDE practitioners
references on the very latest algorithms and techniques of a non-standard, yet
highly parallelizable, methodology at the interface of deterministic and
probabilistic numerical methods. We close this work with an invitation to the
fully nonlinear case and open research questions.
","Francisco Bernal|Gonçalo dos Reis|Greig Smith","","http://arxiv.org/abs/1705.03666v1","http://arxiv.org/pdf/1705.03666v1","","23 pages, 7 figures; Final SMUR version; To appear in the European
  Journal of Applied Mathematics (EJAM)","","","math.NA","math.NA|math.PR|q-fin.CP|Primary 65C05, 65C30, Secondary: 65N55, 60H35, 91-XX, 35CXX"
"187","1705.04069v1","2017-05-11 08:34:06","2017-05-11 08:34:06","Survey on Data-Centric based Routing Protocols for Wireless Sensor
  Networks","  The great concern for energy that grew with the technological advances in the
field of networks and especially in sensor network has triggered various
approaches and protocols that relate to sensor networks. In this context, the
routing protocols were of great interest. The aim of the present paper is to
discuss routing protocols for sensor networks. This paper will focus mainly on
the discussion of the data-centric approach (COUGAR, rumor, SPIN, flooding and
Gossiping), while shedding light on the other approaches occasionally. The
functions of the nodes will be discussed as well. The methodology selected for
this paper is based on a close description and discussion of the protocol. As a
conclusion, open research questions and limitations are proposed to the reader
at the end of this paper.
","Khalid Al Rasbi|Hothefa Shaker|Zeyad Sharef","MCBS|MCBS|College of Engineering","http://arxiv.org/abs/1705.04069v1","http://arxiv.org/pdf/1705.04069v1","http://dx.doi.org/10.24001/eec.2.2.3","","International Journal of Electrical, Electronics and Computers
  (EEC Journal), 2017, 2, pp.9 - 16","10.24001/eec.2.2.3","cs.NI","cs.NI|cs.DC"
"188","1705.06202v1","2017-05-17 15:14:00","2017-05-17 15:14:00","Data Access for LIGO on the OSG","  During 2015 and 2016, the Laser Interferometer Gravitational-Wave Observatory
(LIGO) conducted a three-month observing campaign. These observations delivered
the first direct detection of gravitational waves from binary black hole
mergers. To search for these signals, the LIGO Scientific Collaboration uses
the PyCBC search pipeline. To deliver science results in a timely manner, LIGO
collaborated with the Open Science Grid (OSG) to distribute the required
computation across a series of dedicated, opportunistic, and allocated
resources. To deliver the petabytes necessary for such a large-scale
computation, our team deployed a distributed data access infrastructure based
on the XRootD server suite and the CernVM File System (CVMFS). This data access
strategy grew from simply accessing remote storage to a POSIX-based interface
underpinned by distributed, secure caches across the OSG.
","Derek Weitzel|Brian Bockelman|Duncan A. Brown|Peter Couvares|Frank Würthwein|Edgar Fajardo Hernandez","","http://arxiv.org/abs/1705.06202v1","http://arxiv.org/pdf/1705.06202v1","","6 pages, 3 figures, submitted to PEARC17","","","cs.DC","cs.DC|astro-ph.IM"
"189","1706.00904v1","2017-06-03 07:15:34","2017-06-03 07:15:34","X-TCP: A Cross Layer Approach for TCP Uplink Flows in mmWave Networks","  Millimeter wave frequencies will likely be part of the fifth generation of
mobile networks and of the 3GPP New Radio (NR) standard. MmWave communication
indeed provides a very large bandwidth, thus an increased cell throughput, but
how to exploit these resources at the higher layers is still an open research
question. A very relevant issue is the high variability of the channel, caused
by the blockage from obstacles and the human body. This affects the design of
congestion control mechanisms at the transport layer, and state-of-the-art TCP
schemes such as TCP CUBIC present suboptimal performance. In this paper, we
present a cross layer approach for uplink flows that adjusts the congestion
window of TCP at the mobile equipment side using an estimation of the available
data rate at the mmWave physical layer, based on the actual resource allocation
and on the Signal to Interference plus Noise Ratio. We show that this approach
reduces the latency, avoiding to fill the buffers in the cellular stack, and
has a quicker recovery time after RTO events than several other TCP congestion
control algorithms.
","Tommy Azzino|Matteo Drago|Michele Polese|Andrea Zanella|Michele Zorzi","","http://arxiv.org/abs/1706.00904v1","http://arxiv.org/pdf/1706.00904v1","http://dx.doi.org/10.1109/MedHocNet.2017.8001650","6 pages, 5 figures, accepted for presentation at the 2017 16th Annual
  Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET)","","10.1109/MedHocNet.2017.8001650","cs.NI","cs.NI|cs.IT|math.IT"
"190","1706.08628v1","2017-06-26 23:52:52","2017-06-26 23:52:52","Self-Sustaining Caching Stations: Towards Cost-Effective 5G-Enabled
  Vehicular Networks","  In this article, we investigate the cost-effective 5G-enabled vehicular
networks to support emerging vehicular applications, such as autonomous
driving, in-car infotainment and location-based road services. To this end,
self-sustaining caching stations (SCSs) are introduced to liberate on-road base
stations from the constraints of power lines and wired backhauls. Specifically,
the cache-enabled SCSs are powered by renewable energy and connected to core
networks through wireless backhauls, which can realize ""drop-and-play""
deployment, green operation, and low-latency services. With SCSs integrated, a
5G-enabled heterogeneous vehicular networking architecture is further proposed,
where SCSs are deployed along roadside for traffic offloading while
conventional macro base stations (MBSs) provide ubiquitous coverage to
vehicles. In addition, a hierarchical network management framework is designed
to deal with high dynamics in vehicular traffic and renewable energy, where
content caching, energy management and traffic steering are jointly
investigated to optimize the service capability of SCSs with balanced power
demand and supply in different time scales. Case studies are provided to
illustrate SCS deployment and operation designs, and some open research issues
are also discussed.
","Shan Zhang|Ning Zhang|Xiaojie Fang|Peng Yang| Xuemin| Shen","Sherman|Sherman|Sherman|Sherman|Sherman|","http://arxiv.org/abs/1706.08628v1","http://arxiv.org/pdf/1706.08628v1","http://dx.doi.org/10.1109/MCOM.2017.1700129","IEEE Communications Magazine, to appear","","10.1109/MCOM.2017.1700129","cs.NI","cs.NI|cs.IT|math.IT"
"191","1707.00852v1","2017-07-04 08:44:51","2017-07-04 08:44:51","Network Slicing in 5G Mobile Communication Architecture, Profit
  Modeling, and Challenges","  Efficient flexibility and higher system scalability call for enhanced network
performance, better energy consumption, lower infrastructure cost, and
effective resource utilization. To accomplish this, an architectural
optimization and reconstruction of existing cellular network is required.
Network slicing is considered to be one of the key enablers and an
architectural answer of communication system of 2020 and beyond. Traditional
mobile operators provide all types of services to various kinds of customers
through a single network, however, with the deployment of network slicing
operators are now able to divide entire network into different slices each with
its own configuration and specific Quality of Service (QoS) requirements. In a
slice-based network, each slice will be considered as a separate logical
network. In this way, the infrastructure utilization and resource allocation
will be much more energy and cost efficient in comparison to traditional
network. In this paper, we provided a comprehensive discussion on concept and
system architecture of network slicing with particular focus on its business
aspect and profit modeling. We throughly discussed two different dimensions of
profit modeling, so called Own-Slice Implementation and Resource Leasing for
Outsourced Slices. We further addressed open research directions and existing
challenges with the purpose of motivating new advances and adding realistic
solutions to this emerging technology.
","Mohammad Asif Habibi|Bin Han|Hans D. Schotten","","http://arxiv.org/abs/1707.00852v1","http://arxiv.org/pdf/1707.00852v1","","","","","cs.NI","cs.NI"
"192","1707.05101v2","2017-07-17 11:29:14","2018-02-08 01:15:57","On consistency of optimal pricing algorithms in repeated posted-price
  auctions with strategic buyer","  We study revenue optimization learning algorithms for repeated posted-price
auctions where a seller interacts with a single strategic buyer that holds a
fixed private valuation for a good and seeks to maximize his cumulative
discounted surplus. For this setting, first, we propose a novel algorithm that
never decreases offered prices and has a tight strategic regret bound in
$\Theta(\log\log T)$ under some mild assumptions on the buyer surplus
discounting. This result closes the open research question on the existence of
a no-regret horizon-independent weakly consistent pricing. The proposed
algorithm is inspired by our observation that a double decrease of offered
prices in a weakly consistent algorithm is enough to cause a linear regret.
This motivates us to construct a novel transformation that maps a
right-consistent algorithm to a weakly consistent one that never decreases
offered prices.
  Second, we outperform the previously known strategic regret upper bound of
the algorithm PRRFES, where the improvement is achieved by means of a finer
constant factor $C$ of the principal term $C\log\log T$ in this upper bound.
Finally, we generalize results on strategic regret previously known for
geometric discounting of the buyer's surplus to discounting of other types,
namely: the optimality of the pricing PRRFES to the case of geometrically
concave decreasing discounting; and linear lower bound on the strategic regret
of a wide range of horizon-independent weakly consistent algorithms to the case
of arbitrary discounts.
","Alexey Drutsa","","http://arxiv.org/abs/1707.05101v2","http://arxiv.org/pdf/1707.05101v2","","25 pages; 1 figure","","","cs.GT","cs.GT|cs.AI|cs.LG|stat.ML|91A20 (Primary), 68T05 (Secondary), 68W27 (Secondary), 91A05
  (Secondary), 91A26 (Secondary)|I.2.6; F.2.2"
"193","1707.06070v1","2017-07-19 13:14:44","2017-07-19 13:14:44","DataCite as a novel bibliometric source: Coverage, strengths and
  limitations","  This paper explores the characteristics of DataCite to determine its
possibilities and potential as a new bibliometric data source to analyze the
scholarly production of open data. Open science and the increasing data sharing
requirements from governments, funding bodies, institutions and scientific
journals has led to a pressing demand for the development of data metrics. As a
very first step towards reliable data metrics, we need to better comprehend the
limitations and caveats of the information provided by sources of open data. In
this paper, we critically examine records downloaded from the DataCite's OAI
API and elaborate a series of recommendations regarding the use of this source
for bibliometric analyses of open data. We highlight issues related to metadata
incompleteness, lack of standardization, and ambiguous definitions of several
fields. Despite these limitations, we emphasize DataCite's value and potential
to become one of the main sources for data metrics development.
","Nicolas Robinson-Garcia|Philippe Mongeon|Wei Jeng|Rodrigo Costas","","http://arxiv.org/abs/1707.06070v1","http://arxiv.org/pdf/1707.06070v1","http://dx.doi.org/10.1016/j.joi.2017.07.003","Paper accepted for publication in Journal of Informetrics","Journal of Informetrics, 11(3), 841-854 (2017)","10.1016/j.joi.2017.07.003","cs.DL","cs.DL"
"194","1707.07380v1","2017-07-24 02:22:12","2017-07-24 02:22:12","Speeding up finite-time consensus via minimal polynomial of a weighted
  graph - a numerical approach","  Reaching consensus among states of a multi-agent system is a key requirement
for many distributed control/optimization problems. Such a consensus is often
achieved using the standard Laplacian matrix (for continuous system) or Perron
matrix (for discrete-time system). Recent interest in speeding up consensus
sees the development of finite-time consensus algorithms. This work proposes an
approach to speed up finite-time consensus algorithm using the weights of a
weighted Laplacian matrix. The approach is an iterative procedure that finds a
low-order minimal polynomial that is consistent with the topology of the
underlying graph. In general, the lowest-order minimal polynomial achievable
for a network system is an open research problem. This work proposes a
numerical approach that searches for the lowest order minimal polynomial via a
rank minimization problem using a two-step approach: the first being an
optimization problem involving the nuclear norm and the second a correction
step. Several examples are provided to illustrate the effectiveness of the
approach.
","Zheming Wang|Chong Jin Ong","","http://arxiv.org/abs/1707.07380v1","http://arxiv.org/pdf/1707.07380v1","","","","","cs.SY","cs.SY"
"195","1707.08147v1","2017-07-25 18:34:51","2017-07-25 18:34:51","Human-in-the-loop optimisation: mixed initiative grasping for optimally
  facilitating post-grasp manipulative actions","  This paper addresses the problem of mixed initiative, shared control for
master-slave grasping and manipulation. We propose a novel system, in which an
autonomous agent assists a human in teleoperating a remote slave arm/gripper,
using a haptic master device. Our system is designed to exploit the human
operator's expertise in selecting stable grasps (still an open research topic
in autonomous robotics). Meanwhile, a-priori knowledge of: i) the slave robot
kinematics, and ii) the desired post-grasp manipulative trajectory, are fed to
an autonomous agent which transmits force cues to the human, to encourage
maximally manipulable grasp pose selections. Specifically, the autonomous agent
provides force cues to the human, during the reach-to-grasp phase, which
encourage the human to select grasp poses which maximise manipulation
capability during the post-grasp object manipulation phase. We introduce a
task-relevant velocity manipulability cost function (TOV), which is used to
identify the maximum kinematic capability of a manipulator during post-grasp
motions, and feed this back as force cues to the human during the pre-grasp
phase. We show that grasps which minimise TOV result in significantly reduced
control effort of the manipulator, compared to other feasible grasps. We
demonstrate the effectiveness of our approach by experiments with both real and
simulated robots.
","Amir M. Ghalamzan Esfahani|Firas Abi-Farraj|Paolo Robuffo Giordano|Rustam Stolkin","","http://arxiv.org/abs/1707.08147v1","http://arxiv.org/pdf/1707.08147v1","","To be appeared in IEEE/RAS IROS 2017","","","cs.RO","cs.RO"
"196","1708.03053v1","2017-08-10 02:04:08","2017-08-10 02:04:08","Application Level High Speed Transfer Optimization Based on Historical
  Analysis and Real-time Tuning","  Data-intensive scientific and commercial applications increasingly require
frequent movement of large datasets from one site to the other(s). Despite
growing network capacities, these data movements rarely achieve the promised
data transfer rates of the underlying physical network due to poorly tuned data
transfer protocols. Accurately and efficiently tuning the data transfer
protocol parameters in a dynamically changing network environment is a major
challenge and remains as an open research problem. In this paper, we present
predictive end-to-end data transfer optimization algorithms based on historical
data analysis and real-time background traffic probing, dubbed HARP. Most of
the previous work in this area are solely based on real time network probing
which results either in an excessive sampling overhead or fails to accurately
predict the optimal transfer parameters. Combining historical data analysis
with real time sampling enables our algorithms to tune the application level
data transfer parameters accurately and efficiently to achieve close-to-optimal
end-to-end data transfer throughput with very low overhead. Our experimental
analysis over a variety of network settings shows that HARP outperforms
existing solutions by up to 50% in terms of the achieved throughput.
","Engin Arslan|Tevfik Kosar","","http://arxiv.org/abs/1708.03053v1","http://arxiv.org/pdf/1708.03053v1","","","","","cs.DC","cs.DC"
"197","1709.01142v1","2017-08-26 21:33:02","2017-08-26 21:33:02","Implementation and Evaluation of a Framework to calculate Impact
  Measures for Wikipedia Authors","  Wikipedia, an open collaborative website, can be edited by anyone, even
anonymously, thus becoming victim to ill-intentioned changes. Therefore,
ranking Wikipedia authors by calculating impact measures based on the edit
history can help to identify reputational users or harmful activity such as
vandalism \cite{Adler:2008:MAC:1822258.1822279}. However, processing millions
of edits on one system can take a long time. The author implements an open
source framework to calculate such rankings in a distributed way (MapReduce)
and evaluates its performance on various sized datasets. A reimplementation of
the contribution measures by \citeauthor{Adler:2008:MAC:1822258.1822279}
demonstrates its extensibility and usability, as well as problems of handling
huge datasets and their possible resolutions. The results put different
performance optimizations into perspective and show that horizontal scaling can
decrease the total processing time.
","Sebastian Neef","","http://arxiv.org/abs/1709.01142v1","http://arxiv.org/pdf/1709.01142v1","","","","","cs.DL","cs.DL|cs.DB|cs.DC|cs.SI"
"198","1708.08416v1","2017-08-28 16:53:41","2017-08-28 16:53:41","Real-Time Area Coverage and Target Localization using Receding-Horizon
  Ergodic Exploration","  Although a number of solutions exist for the problems of coverage, search and
target localization---commonly addressed separately---whether there exists a
unified strategy that addresses these objectives in a coherent manner without
being application-specific remains a largely open research question. In this
paper, we develop a receding-horizon ergodic control approach, based on hybrid
systems theory, that has the potential to fill this gap. The nonlinear model
predictive control algorithm plans real-time motions that optimally improve
ergodicity with respect to a distribution defined by the expected information
density across the sensing domain. We establish a theoretical framework for
global stability guarantees with respect to a distribution. Moreover, the
approach is distributable across multiple agents, so that each agent can
independently compute its own control while sharing statistics of its coverage
across a communication network. We demonstrate the method in both simulation
and in experiment in the context of target localization, illustrating that the
algorithm is independent of the number of targets being tracked and can be run
in real-time on computationally limited hardware platforms.
","Anastasia Mavrommati|Emmanouil Tzorakoleftherakis|Ian Abraham|Todd D. Murphey","","http://arxiv.org/abs/1708.08416v1","http://arxiv.org/pdf/1708.08416v1","","18 pages","","","cs.RO","cs.RO"
"199","1709.05707v2","2017-09-17 19:13:59","2018-06-30 06:44:04","Nonparametric Shape-restricted Regression","  We consider the problem of nonparametric regression under shape constraints.
The main examples include isotonic regression (with respect to any partial
order), unimodal/convex regression, additive shape-restricted regression, and
constrained single index model. We review some of the theoretical properties of
the least squares estimator (LSE) in these problems, emphasizing on the
adaptive nature of the LSE. In particular, we study the behavior of the risk of
the LSE, and its pointwise limiting distribution theory, with special emphasis
to isotonic regression. We survey various methods for constructing pointwise
confidence intervals around these shape-restricted functions. We also briefly
discuss the computation of the LSE and indicate some open research problems and
future directions.
","Adityanand Guntuboyina|Bodhisattva Sen","","http://arxiv.org/abs/1709.05707v2","http://arxiv.org/pdf/1709.05707v2","","This is a survey paper","","","math.ST","math.ST|stat.ML|stat.TH"
"200","1709.06599v1","2017-09-19 18:37:42","2017-09-19 18:37:42","Unsupervised Machine Learning for Networking: Techniques, Applications
  and Research Challenges","  While machine learning and artificial intelligence have long been applied in
networking research, the bulk of such works has focused on supervised learning.
Recently there has been a rising trend of employing unsupervised machine
learning using unstructured raw network data to improve network performance and
provide services such as traffic engineering, anomaly detection, Internet
traffic classification, and quality of service optimization. The interest in
applying unsupervised learning techniques in networking emerges from their
great success in other fields such as computer vision, natural language
processing, speech recognition, and optimal control (e.g., for developing
autonomous self-driving cars). Unsupervised learning is interesting since it
can unconstrain us from the need of labeled data and manual handcrafted feature
engineering thereby facilitating flexible, general, and automated methods of
machine learning. The focus of this survey paper is to provide an overview of
the applications of unsupervised learning in the domain of networking. We
provide a comprehensive survey highlighting the recent advancements in
unsupervised learning techniques and describe their applications for various
learning tasks in the context of networking. We also provide a discussion on
future directions and open research issues, while also identifying potential
pitfalls. While a few survey papers focusing on the applications of machine
learning in networking have previously been published, a survey of similar
scope and breadth is missing in literature. Through this paper, we advance the
state of knowledge by carefully synthesizing the insights from these survey
papers while also providing contemporary coverage of recent advances.
","Muhammad Usama|Junaid Qadir|Aunn Raza|Hunain Arif|Kok-Lim Alvin Yau|Yehia Elkhatib|Amir Hussain|Ala Al-Fuqaha","","http://arxiv.org/abs/1709.06599v1","http://arxiv.org/pdf/1709.06599v1","","","","","cs.NI","cs.NI|cs.LG"
